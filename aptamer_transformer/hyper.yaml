log: True
save_path: '/glade/u/home/mlsample/work/aptamer_transformer/echo_opt_runs/x_trans_seq_struct_aptamer_bert_0'

pbs:
  jobs: 16
  tasks_per_worker: 1
  gpus_per_node: 1
  bash: ["source ~/.bashrc", "module load conda", "conda activate guess"]
  batch:
    N: "apt_hyper"
    l: ["select=1:ncpus=8:ngpus=1:mem=128GB", "walltime=12:00:00", "gpu_type=a100"]
    A: "NAML0001"
    q: "casper"
    o: "/out"
    e: /"out"
    
optuna:
  storage: "apt_hyper.db"
  study_name: "apt_hyper"
  storage_type: "nfs"
  objective: "/glade/u/home/mlsample/work/aptamer_transformer/aptamer_transformer/echo_hyperparam_opt.py"
  direction: "minimize"
  metric: "val_loss"
  n_trials: 1000
  gpu: True
  sampler:
    type: "TPESampler"
    n_startup_trials: 100
  parameters:
    batch_size:
      type: "int"
      settings:
        name: "batch_size"
        low: 10
        high: 2048
    learning_rate:
      type: "loguniform"
      settings:
        name: "learning_rate"
        low: 1.0e-06
        high: 1.0e-02
    num_layers:
      type: "int"
      settings:
        name: "num_layers"
        low: 1
        high: 24
    d_model:
      type: "int"
      settings:
        name: "d_model"
        low: 8
        high: 256
        step: 8
    mlm_probability:
      type: "float"
      settings:
        name: "mlm_probability"
        low: 0.0
        high: 0.9
    attn_num_mem_kv:
      type: "int"
      settings:
        name: "attn_num_mem_kv"
        low: 0
        high: 16
    num_memory_tokens:
      type: "int"
      settings:
        name: "num_memory_tokens"
        low: 0
        high: 16
    emb_dropout:
      type: "float"
      settings:
        name: "emb_dropout"
        low: 0.0
        high: 0.9
    layer_dropout:
      type: "float"
      settings:
        name: "layer_dropout"
        low: 0.0
        high: 0.9
    attn_dropout:
      type: "float"
      settings:
        name: "attn_dropout"
        low: 0.0
        high: 0.9
    ff_dropout:
      type: "float"
      settings:
        name: "ff_dropout"
        low: 0.0
        high: 0.9
    l2norm_embed:
      type: "categorical"
      settings:
        name: "l2norm_embed"
        choices: [True, False]
    use_scalenorm:
      type: "categorical"
      settings:
        name: "use_scalenorm"
        choices: [True, False]
    attn_flash:
      type: "categorical"
      settings:
        name: "attn_flash"
        choices: [True, False]
    ff_glu:
      type: "categorical"
      settings:
        name: "ff_glu"
        choices: [True, False]
    ff_swish:
      type: "categorical"
      settings:
        name: "ff_swish"
        choices: [True, False]
    ff_no_bias:
      type: "categorical"
      settings:
        name: "ff_no_bias"
        choices: [True, False]
    attn_talking_heads:
      type: "categorical"
      settings:
        name: "attn_talking_heads"
        choices: [True, False]
    attn_gate_values:
      type: "categorical"
      settings:
        name: "attn_gate_values"
        choices: [True, False]
    macaron:
      type: "categorical"
      settings:
        name: "macaron"
        choices: [True, False]
    rel_pos_bias:
      type: "categorical"
      settings:
        name: "rel_pos_bias"
        choices: [True, False]
    rotary_pos_emb:
      type: "categorical"
      settings:
        name: "rotary_pos_emb"
        choices: [True, False]
    rotary_xpos:
      type: "categorical"
      settings:
        name: "rotary_xpos"
        choices: [True, False]
    alibi_pos_bias:
      type: "categorical"
      settings:
        name: "alibi_pos_bias"
        choices: [True, False]
    residual_attn:
      type: "categorical"
      settings:
        name: "residual_attn"
        choices: [True, False]
    pre_norm:
      type: "categorical"
      settings:
        name: "pre_norm"
        choices: [True, False]
    attn_qk_norm:
      type: "categorical"
      settings:
        name: "attn_qk_norm"
        choices: [True, False]
    attn_qk_norm_dim_scale:
      type: "categorical"
      settings:
        name: "attn_qk_norm_dim_scale"
        choices: [True, False]
