{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4d80798e-20bd-401f-a156-9577573273fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-11 21:29:14.891018: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-03-11 21:29:16.102792: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import optim\n",
    "\n",
    "import yaml\n",
    "import xgboost as xgb\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "# import cupy as cp\n",
    "\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score, explained_variance_score, median_absolute_error\n",
    "from sklearn.preprocessing import quantile_transform, StandardScaler, MinMaxScaler, OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score, learning_curve\n",
    "# from skopt import BayesSearchCV\n",
    "# from skopt.space import Real, Categorical, Integer\n",
    "\n",
    "from x_transformers import XTransformer, TransformerWrapper, Decoder, Encoder, ViTransformerWrapper\n",
    "\n",
    "from aptamer_transformer.model import *\n",
    "from aptamer_transformer.factories_model_loss import *\n",
    "from aptamer_transformer.data_utils import *\n",
    "from aptamer_transformer.dataset import *\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "45ac6345-11c5-44bb-8ffc-56c3186c09b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = read_cfg('../aptamer_transformer/config.yaml')\n",
    "df = load_df(cfg)\n",
    "# dfs = read_data_files(cfg)\n",
    "# counter_set = normalized_counters(dfs)\n",
    "# enrichment_scores = all_enrichments(counter_set)\n",
    "# unique_sequences = log_normalize_enrichment_scores(enrichment_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "98a4a0b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = log_normed_load_and_preprocess_enrichment_data(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "01da1fc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/nupack_strucutre_data/all_mfe.pickle', 'rb') as f:\n",
    "    mfe = pickle.load(f)\n",
    "    \n",
    "energy = {k: v[0].energy for k, v in mfe.items()}\n",
    "dot_bracket = {k: v[0].structure.dotparensplus() for k, v in mfe.items()}\n",
    "strucutre_matrix = {k: v[0].structure.structure_matrix() for k, v in mfe.items()}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "560fa638",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_sequences['energy'] = unique_sequences['Sequence'].map(energy)\n",
    "unique_sequences['dot_bracket'] = unique_sequences['Sequence'].map(dot_bracket)\n",
    "unique_sequences['strucutre_matrix'] = unique_sequences['Sequence'].map(strucutre_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6b3c014d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = unique_sequences.copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d39a1cf9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sequence</th>\n",
       "      <th>Normalized_Frequency</th>\n",
       "      <th>sum</th>\n",
       "      <th>max</th>\n",
       "      <th>min</th>\n",
       "      <th>count</th>\n",
       "      <th>energy</th>\n",
       "      <th>dot_bracket</th>\n",
       "      <th>strucutre_matrix</th>\n",
       "      <th>Discretized_Frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AAAAAAAATGGGGGGGGGGGGGGGGGGGGTCTGTTTATTT</td>\n",
       "      <td>0.218865</td>\n",
       "      <td>0.293243</td>\n",
       "      <td>0.071264</td>\n",
       "      <td>0.533216</td>\n",
       "      <td>3</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>........................................</td>\n",
       "      <td>[[1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AAAAAAACGGCATCGCTAGGCATCAGGTCCCATCCGGTTA</td>\n",
       "      <td>0.465646</td>\n",
       "      <td>0.307381</td>\n",
       "      <td>0.289093</td>\n",
       "      <td>0.621446</td>\n",
       "      <td>3</td>\n",
       "      <td>0.919390</td>\n",
       "      <td>....((.(((.......................))).)).</td>\n",
       "      <td>[[1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AAAAAAATTGGGGGGGGGGGGGGGGGGGGTCTGTTTATTT</td>\n",
       "      <td>0.301842</td>\n",
       "      <td>0.297997</td>\n",
       "      <td>0.166499</td>\n",
       "      <td>0.597775</td>\n",
       "      <td>3</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>........................................</td>\n",
       "      <td>[[1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AAAAACAAACCATACAACCCAGACGGCCCGCTGATTTACA</td>\n",
       "      <td>0.398200</td>\n",
       "      <td>0.303517</td>\n",
       "      <td>0.166499</td>\n",
       "      <td>0.712720</td>\n",
       "      <td>3</td>\n",
       "      <td>0.931937</td>\n",
       "      <td>...................(((.((...))))).......</td>\n",
       "      <td>[[1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AAAAACGCAGCAAACAAGGACCCACGTACGCCCGCATTAT</td>\n",
       "      <td>0.540360</td>\n",
       "      <td>0.316853</td>\n",
       "      <td>0.278974</td>\n",
       "      <td>0.763822</td>\n",
       "      <td>6</td>\n",
       "      <td>0.954282</td>\n",
       "      <td>....(((.................))).............</td>\n",
       "      <td>[[1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>513690</th>\n",
       "      <td>TTTTTTTTTTTTTTGGGGGGGGGGGGGGGGGGGGGGTCCC</td>\n",
       "      <td>0.458486</td>\n",
       "      <td>0.309976</td>\n",
       "      <td>0.294501</td>\n",
       "      <td>0.658055</td>\n",
       "      <td>21</td>\n",
       "      <td>0.921781</td>\n",
       "      <td>.............................(((.....)))</td>\n",
       "      <td>[[1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>513691</th>\n",
       "      <td>TTTTTTTTTTTTTTGGGGGGGGGGGGGGGGGGGGGTTTCT</td>\n",
       "      <td>0.513825</td>\n",
       "      <td>0.310141</td>\n",
       "      <td>0.196496</td>\n",
       "      <td>0.843051</td>\n",
       "      <td>3</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>........................................</td>\n",
       "      <td>[[1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>513692</th>\n",
       "      <td>TTTTTTTTTTTTTTGGGGGGGGGGGTGGCCGGGGGGTCCC</td>\n",
       "      <td>0.519663</td>\n",
       "      <td>0.314481</td>\n",
       "      <td>0.278974</td>\n",
       "      <td>0.706349</td>\n",
       "      <td>6</td>\n",
       "      <td>0.922903</td>\n",
       "      <td>.....................((.....))(((....)))</td>\n",
       "      <td>[[1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>513693</th>\n",
       "      <td>TTTTTTTTTTTTTTGGGGGGGGGGGTGGGCGGGGGGTCCC</td>\n",
       "      <td>0.442661</td>\n",
       "      <td>0.306064</td>\n",
       "      <td>0.187988</td>\n",
       "      <td>0.735655</td>\n",
       "      <td>3</td>\n",
       "      <td>0.934520</td>\n",
       "      <td>..............................(((....)))</td>\n",
       "      <td>[[1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>513694</th>\n",
       "      <td>TTTTTTTTTTTTTTGGGGGGGGGGTGGGGCGGGGGGTCCC</td>\n",
       "      <td>0.420927</td>\n",
       "      <td>0.304819</td>\n",
       "      <td>0.188445</td>\n",
       "      <td>0.709089</td>\n",
       "      <td>3</td>\n",
       "      <td>0.934520</td>\n",
       "      <td>..............................(((....)))</td>\n",
       "      <td>[[1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>513695 rows Ã— 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        Sequence  Normalized_Frequency  \\\n",
       "0       AAAAAAAATGGGGGGGGGGGGGGGGGGGGTCTGTTTATTT              0.218865   \n",
       "1       AAAAAAACGGCATCGCTAGGCATCAGGTCCCATCCGGTTA              0.465646   \n",
       "2       AAAAAAATTGGGGGGGGGGGGGGGGGGGGTCTGTTTATTT              0.301842   \n",
       "3       AAAAACAAACCATACAACCCAGACGGCCCGCTGATTTACA              0.398200   \n",
       "4       AAAAACGCAGCAAACAAGGACCCACGTACGCCCGCATTAT              0.540360   \n",
       "...                                          ...                   ...   \n",
       "513690  TTTTTTTTTTTTTTGGGGGGGGGGGGGGGGGGGGGGTCCC              0.458486   \n",
       "513691  TTTTTTTTTTTTTTGGGGGGGGGGGGGGGGGGGGGTTTCT              0.513825   \n",
       "513692  TTTTTTTTTTTTTTGGGGGGGGGGGTGGCCGGGGGGTCCC              0.519663   \n",
       "513693  TTTTTTTTTTTTTTGGGGGGGGGGGTGGGCGGGGGGTCCC              0.442661   \n",
       "513694  TTTTTTTTTTTTTTGGGGGGGGGGTGGGGCGGGGGGTCCC              0.420927   \n",
       "\n",
       "             sum       max       min  count    energy  \\\n",
       "0       0.293243  0.071264  0.533216      3  1.000000   \n",
       "1       0.307381  0.289093  0.621446      3  0.919390   \n",
       "2       0.297997  0.166499  0.597775      3  1.000000   \n",
       "3       0.303517  0.166499  0.712720      3  0.931937   \n",
       "4       0.316853  0.278974  0.763822      6  0.954282   \n",
       "...          ...       ...       ...    ...       ...   \n",
       "513690  0.309976  0.294501  0.658055     21  0.921781   \n",
       "513691  0.310141  0.196496  0.843051      3  1.000000   \n",
       "513692  0.314481  0.278974  0.706349      6  0.922903   \n",
       "513693  0.306064  0.187988  0.735655      3  0.934520   \n",
       "513694  0.304819  0.188445  0.709089      3  0.934520   \n",
       "\n",
       "                                     dot_bracket  \\\n",
       "0       ........................................   \n",
       "1       ....((.(((.......................))).)).   \n",
       "2       ........................................   \n",
       "3       ...................(((.((...))))).......   \n",
       "4       ....(((.................))).............   \n",
       "...                                          ...   \n",
       "513690  .............................(((.....)))   \n",
       "513691  ........................................   \n",
       "513692  .....................((.....))(((....)))   \n",
       "513693  ..............................(((....)))   \n",
       "513694  ..............................(((....)))   \n",
       "\n",
       "                                         strucutre_matrix  \\\n",
       "0       [[1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...   \n",
       "1       [[1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...   \n",
       "2       [[1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...   \n",
       "3       [[1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...   \n",
       "4       [[1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...   \n",
       "...                                                   ...   \n",
       "513690  [[1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...   \n",
       "513691  [[1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...   \n",
       "513692  [[1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...   \n",
       "513693  [[1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...   \n",
       "513694  [[1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...   \n",
       "\n",
       "        Discretized_Frequency  \n",
       "0                           0  \n",
       "1                           1  \n",
       "2                           0  \n",
       "3                           0  \n",
       "4                           1  \n",
       "...                       ...  \n",
       "513690                      1  \n",
       "513691                      1  \n",
       "513692                      1  \n",
       "513693                      1  \n",
       "513694                      1  \n",
       "\n",
       "[513695 rows x 10 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "75b9922d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[<Axes: title={'center': 'Normalized_Frequency'}>]], dtype=object)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df.hist(column='Normalized_Frequency', bins=70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8b6bef45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[<Axes: title={'center': 'Discretized_Frequency'}>]], dtype=object)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "df.hist(column='Discretized_Frequency', bins=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bd6f00ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sequence</th>\n",
       "      <th>mean</th>\n",
       "      <th>sum</th>\n",
       "      <th>max</th>\n",
       "      <th>min</th>\n",
       "      <th>count</th>\n",
       "      <th>energy</th>\n",
       "      <th>dot_bracket</th>\n",
       "      <th>strucutre_matrix</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>560539</th>\n",
       "      <td>GGGCGGGAGGGAGGGGGGCCACACCAAAACACGTTCAACT</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.736840</td>\n",
       "      <td>66</td>\n",
       "      <td>0.911054</td>\n",
       "      <td>.(((.............)))....................</td>\n",
       "      <td>[[1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175157</th>\n",
       "      <td>CCCATGGTAGGTATTGCTTGGTAGGGATAGTGGGCTTGATG</td>\n",
       "      <td>0.994638</td>\n",
       "      <td>0.878780</td>\n",
       "      <td>0.917585</td>\n",
       "      <td>0.756909</td>\n",
       "      <td>55</td>\n",
       "      <td>0.930711</td>\n",
       "      <td>.(((.(..........).)))((....))............</td>\n",
       "      <td>[[1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1086387</th>\n",
       "      <td>TCGCGGGGGGCGGGTCGGGTGCTCGTTCGAGGGGTCGCAG</td>\n",
       "      <td>0.981617</td>\n",
       "      <td>0.865104</td>\n",
       "      <td>0.810912</td>\n",
       "      <td>0.839269</td>\n",
       "      <td>55</td>\n",
       "      <td>0.820253</td>\n",
       "      <td>.(.((.....)).)(((..........)))..........</td>\n",
       "      <td>[[1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57001</th>\n",
       "      <td>AGGAGGGTAGGTAGTGCTTGGTAGGGAAACTCCGTCGATT</td>\n",
       "      <td>0.971929</td>\n",
       "      <td>0.755209</td>\n",
       "      <td>0.830588</td>\n",
       "      <td>0.843051</td>\n",
       "      <td>45</td>\n",
       "      <td>0.950861</td>\n",
       "      <td>......................(.((.....)).).....</td>\n",
       "      <td>[[1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1155409</th>\n",
       "      <td>TGGGGGGGAGGGTAGGGTATGGGGTCGTACAGTGGGTTTCG</td>\n",
       "      <td>0.967657</td>\n",
       "      <td>0.850441</td>\n",
       "      <td>0.808411</td>\n",
       "      <td>0.804341</td>\n",
       "      <td>55</td>\n",
       "      <td>0.967572</td>\n",
       "      <td>...........(((.(.........).)))...........</td>\n",
       "      <td>[[1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1105430</th>\n",
       "      <td>TGAGGGGCGGGGTGGTGGGGGGTTTTGTCTGCCACAAGTG</td>\n",
       "      <td>0.087888</td>\n",
       "      <td>0.285739</td>\n",
       "      <td>0.073459</td>\n",
       "      <td>0.376974</td>\n",
       "      <td>3</td>\n",
       "      <td>0.879711</td>\n",
       "      <td>..............((((.............)))).....</td>\n",
       "      <td>[[1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>965299</th>\n",
       "      <td>GTCATACACACGCTCACGCACCCGGCGCAGGGTTGAGCGA</td>\n",
       "      <td>0.063676</td>\n",
       "      <td>0.195882</td>\n",
       "      <td>0.069590</td>\n",
       "      <td>0.149619</td>\n",
       "      <td>15</td>\n",
       "      <td>0.630090</td>\n",
       "      <td>..........((((((...((((......)))))))))).</td>\n",
       "      <td>[[1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19559</th>\n",
       "      <td>ACAGGCGCCGCTGGTCGACGCAGACCCGCCTAAGTTGTTA</td>\n",
       "      <td>0.061320</td>\n",
       "      <td>0.232295</td>\n",
       "      <td>0.062711</td>\n",
       "      <td>0.186865</td>\n",
       "      <td>10</td>\n",
       "      <td>0.721737</td>\n",
       "      <td>..(((((.....((((......))))))))).........</td>\n",
       "      <td>[[1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1143027</th>\n",
       "      <td>TGGGCCATGGAATCGGTACGCACCGGTCGCAGGTTAACGA</td>\n",
       "      <td>0.055909</td>\n",
       "      <td>0.193657</td>\n",
       "      <td>0.076944</td>\n",
       "      <td>0.172180</td>\n",
       "      <td>15</td>\n",
       "      <td>0.821094</td>\n",
       "      <td>......((...))((((....))))..((........)).</td>\n",
       "      <td>[[1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149893</th>\n",
       "      <td>CAAGCAAGTGCCGCTGTACGACGCAGTACCACTTGAGAGG</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.177642</td>\n",
       "      <td>0.063315</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>15</td>\n",
       "      <td>0.725956</td>\n",
       "      <td>....((((((.((.....))((...))..)))))).....</td>\n",
       "      <td>[[1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>513695 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          Sequence      mean       sum  \\\n",
       "560539    GGGCGGGAGGGAGGGGGGCCACACCAAAACACGTTCAACT  1.000000  1.000000   \n",
       "175157   CCCATGGTAGGTATTGCTTGGTAGGGATAGTGGGCTTGATG  0.994638  0.878780   \n",
       "1086387   TCGCGGGGGGCGGGTCGGGTGCTCGTTCGAGGGGTCGCAG  0.981617  0.865104   \n",
       "57001     AGGAGGGTAGGTAGTGCTTGGTAGGGAAACTCCGTCGATT  0.971929  0.755209   \n",
       "1155409  TGGGGGGGAGGGTAGGGTATGGGGTCGTACAGTGGGTTTCG  0.967657  0.850441   \n",
       "...                                            ...       ...       ...   \n",
       "1105430   TGAGGGGCGGGGTGGTGGGGGGTTTTGTCTGCCACAAGTG  0.087888  0.285739   \n",
       "965299    GTCATACACACGCTCACGCACCCGGCGCAGGGTTGAGCGA  0.063676  0.195882   \n",
       "19559     ACAGGCGCCGCTGGTCGACGCAGACCCGCCTAAGTTGTTA  0.061320  0.232295   \n",
       "1143027   TGGGCCATGGAATCGGTACGCACCGGTCGCAGGTTAACGA  0.055909  0.193657   \n",
       "149893    CAAGCAAGTGCCGCTGTACGACGCAGTACCACTTGAGAGG  0.000000  0.177642   \n",
       "\n",
       "              max       min  count    energy  \\\n",
       "560539   1.000000  0.736840     66  0.911054   \n",
       "175157   0.917585  0.756909     55  0.930711   \n",
       "1086387  0.810912  0.839269     55  0.820253   \n",
       "57001    0.830588  0.843051     45  0.950861   \n",
       "1155409  0.808411  0.804341     55  0.967572   \n",
       "...           ...       ...    ...       ...   \n",
       "1105430  0.073459  0.376974      3  0.879711   \n",
       "965299   0.069590  0.149619     15  0.630090   \n",
       "19559    0.062711  0.186865     10  0.721737   \n",
       "1143027  0.076944  0.172180     15  0.821094   \n",
       "149893   0.063315  0.000000     15  0.725956   \n",
       "\n",
       "                                       dot_bracket  \\\n",
       "560539    .(((.............)))....................   \n",
       "175157   .(((.(..........).)))((....))............   \n",
       "1086387   .(.((.....)).)(((..........)))..........   \n",
       "57001     ......................(.((.....)).).....   \n",
       "1155409  ...........(((.(.........).)))...........   \n",
       "...                                            ...   \n",
       "1105430   ..............((((.............)))).....   \n",
       "965299    ..........((((((...((((......)))))))))).   \n",
       "19559     ..(((((.....((((......))))))))).........   \n",
       "1143027   ......((...))((((....))))..((........)).   \n",
       "149893    ....((((((.((.....))((...))..)))))).....   \n",
       "\n",
       "                                          strucutre_matrix  \n",
       "560539   [[1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...  \n",
       "175157   [[1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...  \n",
       "1086387  [[1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...  \n",
       "57001    [[1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...  \n",
       "1155409  [[1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...  \n",
       "...                                                    ...  \n",
       "1105430  [[1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...  \n",
       "965299   [[1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...  \n",
       "19559    [[1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...  \n",
       "1143027  [[1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...  \n",
       "149893   [[1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...  \n",
       "\n",
       "[513695 rows x 9 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def is_nucleotide_dominant(sequence):\n",
    "    for nucleotide in ['A', 'T', 'C', 'G']:\n",
    "        if sequence.count(nucleotide) / len(sequence) > 0.66:\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "def contains_poly_n(sequence):\n",
    "    for nucleotide in ['A', 'T', 'C', 'G']:\n",
    "        if nucleotide * 10 in sequence:\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "# Apply the function to filter out sequences\n",
    "df_filtered = df[~df['Sequence'].apply(is_nucleotide_dominant)]\n",
    "# df_filtered = df_filtered[~df_filtered['Sequence'].apply(contains_poly_n)]\n",
    "df_filtered = df_filtered[df_filtered['count'] > 1]\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "columns_to_scale = ['mean', 'min', 'max', 'sum', 'energy']\n",
    "\n",
    "# Apply scaler to each column separately\n",
    "for col in columns_to_scale:\n",
    "    df_filtered[col] = scaler.fit_transform(df_filtered[[col]])\n",
    "\n",
    "df_filtered = df_filtered.dropna(subset=columns_to_scale)\n",
    "\n",
    "\n",
    "df_filtered.sort_values(by='mean', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "0b39b7d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[<Axes: title={'center': 'mean'}>]], dtype=object)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_filtered.hist(column='mean', bins=70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "81a29792",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Are there any NaN values in the DataFrame? False\n",
      "Number of NaN values in each column:\n",
      " Sequence            0\n",
      "mean                0\n",
      "sum                 0\n",
      "max                 0\n",
      "min                 0\n",
      "count               0\n",
      "energy              0\n",
      "dot_bracket         0\n",
      "strucutre_matrix    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "has_nan = df_filtered.isna().values.any()\n",
    "print(\"Are there any NaN values in the DataFrame?\", has_nan)\n",
    "\n",
    "nan_counts = df_filtered.isna().sum()\n",
    "print(\"Number of NaN values in each column:\\n\", nan_counts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "155ae09a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_filtered['mean'].values.reshape(-1, 1)\n",
    "y = df_filtered['energy'].values\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "18d9dad2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression - MSE: 0.018463567046175692, R2: 0.06550173132459414\n",
      "Ridge Regression - MSE: 0.01846357030123839, R2: 0.0655015665757972\n",
      "Lasso Regression - MSE: 0.01975778506867407, R2: -2.64809941064037e-06\n",
      "Random Forest - MSE: 0.017313955470146514, R2: 0.1236871309692954\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "models = {\n",
    "    \"Linear Regression\": LinearRegression(),\n",
    "    \"Ridge Regression\": Ridge(),\n",
    "    \"Lasso Regression\": Lasso(),\n",
    "    \"Random Forest\": RandomForestRegressor(),\n",
    "    \"Support Vector Regression\": SVR()\n",
    "}\n",
    "\n",
    "# Train and evaluate each model\n",
    "for name, model in models.items():\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    print(f\"{name} - MSE: {mse}, R2: {r2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1317cc27",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filtered = df.copy()\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "columns_to_scale = ['mean', 'min', 'max', 'sum', 'energy']\n",
    "\n",
    "# Apply scaler to each column separately\n",
    "for col in columns_to_scale:\n",
    "    df_filtered[col] = scaler.fit_transform(df_filtered[[col]])\n",
    "\n",
    "df_filtered = df_filtered.dropna(subset=columns_to_scale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "206b186a",
   "metadata": {},
   "outputs": [],
   "source": [
    "d_model = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "8ea08064",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(cfg['seq_tokenizer_path'])\n",
    "tokenized_data = tokenizer(df_filtered['Sequence'].tolist(), padding=True, return_tensors=\"pt\")\n",
    "tokenized_seqs = tokenized_data.input_ids\n",
    "seq_attn_mask = tokenized_data.attention_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "3c4ae349",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([513695, 42])"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq_attn_mask.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "90269de1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([513695, 42, 8])"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings = nn.Embedding(tokenizer.vocab_size, d_model, padding_idx=tokenizer.pad_token_id)\n",
    "\n",
    "seqs_embedded = embeddings(tokenized_seqs)\n",
    "seqs_embedded.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "16a5655e",
   "metadata": {},
   "outputs": [],
   "source": [
    "struc_tokenizer = AutoTokenizer.from_pretrained(cfg['dot_bracket_tokenizer_path'])\n",
    "tokenized_dot_bracket_data = tokenizer(df_filtered['dot_bracket'].tolist(), padding=True, return_tensors=\"pt\")\n",
    "tokenized_dot_bracket = tokenized_dot_bracket_data.input_ids\n",
    "dot_bracket_attn_mask = tokenized_dot_bracket_data.attention_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "e336c10d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([513695, 42])"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dot_bracket_attn_mask.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "aa519ed0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([513695, 42, 8])"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dot_bracket_embeddings = nn.Embedding(struc_tokenizer.vocab_size, d_model, padding_idx=struc_tokenizer.pad_token_id)\n",
    "\n",
    "dot_bracket_embedded = dot_bracket_embeddings(tokenized_dot_bracket)\n",
    "dot_bracket_embedded.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "35dddd7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([513695, 1])"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "energy = torch.Tensor(df_filtered['energy'].values.reshape(-1, 1)).unsqueeze(-1)\n",
    "energy_attn = torch.ones(energy.shape[0], 1, dtype=torch.long)\n",
    "\n",
    "energy_linear = nn.Linear(1, d_model)\n",
    "\n",
    "energy_embedded = energy_linear(energy)\n",
    "\n",
    "energy_attn.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "55391cae",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_matrix_size = max(df_filtered['strucutre_matrix'].apply(lambda x: len(x)))\n",
    "padded_structure_matrix = df_filtered['strucutre_matrix'].apply(\n",
    "    lambda matrix: np.pad(matrix, (0, max_matrix_size - len(matrix)), mode='constant')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "845e254a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([513695, 41, 41])"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "structure_matrix = torch.Tensor(padded_structure_matrix)\n",
    "structure_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "db6f8b72",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_features = torch.concat([seqs_embedded, dot_bracket_embedded, energy_embedded], dim=1)\n",
    "combined_attn_mask = torch.concat([seq_attn_mask, dot_bracket_attn_mask, energy_attn], dim=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "53849f18",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_sequence(seq):\n",
    "    return list(seq)\n",
    "\n",
    "def tokenize_sequence(seq, max_length, padding_char='N'):\n",
    "    seq += padding_char * (max_length - len(seq))  # Pad the sequence\n",
    "    return list(seq)\n",
    "\n",
    "\n",
    "max_seq_length = max(df_filtered['Sequence'].apply(len))\n",
    "max_dot_bracket_length = max(df_filtered['dot_bracket'].apply(len))\n",
    "\n",
    "sequence_tokenized = np.array([tokenize_sequence(seq, max_seq_length) for seq in df_filtered['Sequence']])\n",
    "dot_bracket_tokenized = np.array([tokenize_sequence(seq, max_dot_bracket_length, '.') for seq in df_filtered['dot_bracket']])\n",
    "\n",
    "# One-hot encoding the tokenized sequences\n",
    "onehot_encoder = OneHotEncoder(handle_unknown='ignore', sparse_output=False)\n",
    "sequence_encoded = onehot_encoder.fit_transform(sequence_tokenized)\n",
    "dot_bracket_encoded = onehot_encoder.fit_transform(dot_bracket_tokenized)\n",
    "\n",
    "# Flatten the encoded arrays\n",
    "sequence_flattened = sequence_encoded.reshape(df_filtered.shape[0], -1)\n",
    "dot_bracket_flattened = dot_bracket_encoded.reshape(df_filtered.shape[0], -1)\n",
    "\n",
    "# Feature 2 - energy\n",
    "energy = df_filtered['energy'].values.reshape(-1, 1)\n",
    "\n",
    "# Feature 4 - structure_matrix\n",
    "max_matrix_size = max(df_filtered['strucutre_matrix'].apply(lambda x: len(x)))\n",
    "padded_structure_matrix = df_filtered['strucutre_matrix'].apply(\n",
    "    lambda matrix: np.pad(matrix, (0, max_matrix_size - len(matrix)), mode='constant')\n",
    ")\n",
    "structure_matrix = np.array(padded_structure_matrix.tolist())\n",
    "flattened_structure_matrix = np.array([matrix.flatten() for matrix in structure_matrix])\n",
    "\n",
    "# Concatenate all features\n",
    "X = np.hstack((sequence_flattened, dot_bracket_flattened, energy, flattened_structure_matrix))\n",
    "\n",
    "\n",
    "# Target variable\n",
    "y = df_filtered['Normalized_Frequency'].values\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59c5b5a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_gpu = cp.array(X_train)\n",
    "y_train_gpu = cp.array(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "15c8fc20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((513695, 175),\n",
       " (513695, 114),\n",
       " (513695, 1),\n",
       " (513695, 1681),\n",
       " (513695, 1971),\n",
       " (513695,))"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequence_flattened.shape, dot_bracket_flattened.shape, energy.shape, flattened_structure_matrix.shape, X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "9c07f3b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.237831  ,  0.64329611,  0.33786096, ..., -1.15670226,\n",
       "        0.0103423 ,  0.22809622])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb0df130",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7b5b1e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the parameter grid\n",
    "param_grid = {\n",
    "    'colsample_bytree': [0.3, 0.7],\n",
    "    'learning_rate': [0.1, 0.01, 0.05],\n",
    "    'max_depth': [5, 10, 20],\n",
    "    'alpha': [5, 10, 15],\n",
    "    'n_estimators': [10, 50, 100]\n",
    "}\n",
    "\n",
    "# Initialize the XGBRegressor\n",
    "xgb_model = xgb.XGBRegressor(objective='reg:squarederror', tree_method='hist', device='gpu')\n",
    "\n",
    "# Initialize Grid Search\n",
    "grid_search = GridSearchCV(estimator=xgb_model, param_grid=param_grid, cv=3, n_jobs=-1, verbose=2)\n",
    "\n",
    "# Fit Grid Search to the data\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Best parameters\n",
    "print(\"Best parameters found: \", grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f783ee54",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_space = {\n",
    "    'max_depth': Integer(1, 20),\n",
    "    'min_child_weight': Integer(0, 20),\n",
    "    'gamma': Real(0.01, 10, 'log-uniform'),  # Adjusted lower bound\n",
    "    'subsample': Real(0.1, 1.0),\n",
    "    'colsample_bytree': Real(0.01, 1.0),\n",
    "    }\n",
    "\n",
    "\n",
    "# Initialize the XGBoost model\n",
    "xgb_model = xgb.XGBRegressor(objective='reg:squarederror', tree_method='hist', device='gpu')\n",
    "\n",
    "# Initialize the BayesSearchCV object\n",
    "bayes_cv = BayesSearchCV(\n",
    "    estimator=xgb_model,\n",
    "    search_spaces=search_space,\n",
    "    scoring='neg_mean_squared_error',\n",
    "    cv=3,\n",
    "    n_iter=32,\n",
    "    n_jobs=-1,\n",
    "    return_train_score=True,\n",
    "    random_state=42,\n",
    "    verbose=5\n",
    ")\n",
    "\n",
    "# X_train_numpy = X_train_gpu.get() if isinstance(X_train_gpu, cp.ndarray) else X_train_gpu\n",
    "# y_train_numpy = y_train_gpu.get() if isinstance(y_train_gpu, cp.ndarray) else y_train_gpu\n",
    "\n",
    "bayes_cv.fit(X_train, y_train)\n",
    "# Perform the search\n",
    "\n",
    "# Print the best parameters and best score\n",
    "print(\"Best parameters found: \", bayes_cv.best_params_)\n",
    "print(\"Best RMSE found: \", np.sqrt(-bayes_cv.best_score_))\n",
    "\n",
    "# Evaluate the model with the best parameters\n",
    "best_model = bayes_cv.best_estimator_\n",
    "y_pred = best_model.predict(X_test)\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "print(\"RMSE on Test Set: %f\" % (rmse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "90539b63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R-squared: 0.492642\n"
     ]
    }
   ],
   "source": [
    "model = xgb.XGBRegressor(\n",
    "    objective='reg:tweedie',\n",
    "    colsample_bytree=0.7,  # Updated\n",
    "    learning_rate=0.1,     # Updated\n",
    "    max_depth=10,          # Updated\n",
    "    alpha=5,               # Updated\n",
    "    n_estimators=100,      # Updated\n",
    "    tree_method='hist',    # Assuming you're still using GPU acceleration\n",
    "    device='gpu'           # Assuming you're still using GPU acceleration\n",
    ")\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# R-squared\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "print(\"R-squared: %f\" % r2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4026737f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filtered = df_filtered.rename(columns={'mean': 'Normalized_Frequency'})\n",
    "df_filtered = df_filtered.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7b7c4430",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = read_cfg('../aptamer_transformer/config.yaml')\n",
    "\n",
    "device = torch.device(\"cpu\")  \n",
    "cfg.update({\n",
    "    'device': device,\n",
    "})\n",
    "\n",
    "dna_dataset = load_dataset(cfg)\n",
    "\n",
    "model = get_model(cfg)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "eacd88d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SeqStructXAptamerBertClassifier(\n",
       "  (aptamer_bert_encoding): SeqStructXAptamerBert(\n",
       "    (x_transformer_encoder): XTransformerEncoder(\n",
       "      (x_transformer_encoder): TransformerWrapper(\n",
       "        (token_emb): TokenEmbedding(\n",
       "          (emb): Embedding(12, 120)\n",
       "        )\n",
       "        (post_emb_norm): Identity()\n",
       "        (emb_dropout): Dropout(p=0.4, inplace=False)\n",
       "        (project_emb): Identity()\n",
       "        (attn_layers): Encoder(\n",
       "          (layers): ModuleList(\n",
       "            (0): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): Attention(\n",
       "                (to_q): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_k): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_v): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (attend): Attend(\n",
       "                  (attn_dropout): Dropout(p=0.4, inplace=False)\n",
       "                )\n",
       "                (to_out): Linear(in_features=128, out_features=120, bias=False)\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (1): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): FeedForward(\n",
       "                (ff): Sequential(\n",
       "                  (0): GLU(\n",
       "                    (act): GELU(approximate='none')\n",
       "                    (proj): Linear(in_features=120, out_features=960, bias=True)\n",
       "                  )\n",
       "                  (1): Dropout(p=0.4, inplace=False)\n",
       "                  (2): Linear(in_features=480, out_features=120, bias=True)\n",
       "                )\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (2): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): Attention(\n",
       "                (to_q): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_k): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_v): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (attend): Attend(\n",
       "                  (attn_dropout): Dropout(p=0.4, inplace=False)\n",
       "                )\n",
       "                (to_out): Linear(in_features=128, out_features=120, bias=False)\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (3): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): FeedForward(\n",
       "                (ff): Sequential(\n",
       "                  (0): GLU(\n",
       "                    (act): GELU(approximate='none')\n",
       "                    (proj): Linear(in_features=120, out_features=960, bias=True)\n",
       "                  )\n",
       "                  (1): Dropout(p=0.4, inplace=False)\n",
       "                  (2): Linear(in_features=480, out_features=120, bias=True)\n",
       "                )\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (4): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): Attention(\n",
       "                (to_q): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_k): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_v): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (attend): Attend(\n",
       "                  (attn_dropout): Dropout(p=0.4, inplace=False)\n",
       "                )\n",
       "                (to_out): Linear(in_features=128, out_features=120, bias=False)\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (5): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): FeedForward(\n",
       "                (ff): Sequential(\n",
       "                  (0): GLU(\n",
       "                    (act): GELU(approximate='none')\n",
       "                    (proj): Linear(in_features=120, out_features=960, bias=True)\n",
       "                  )\n",
       "                  (1): Dropout(p=0.4, inplace=False)\n",
       "                  (2): Linear(in_features=480, out_features=120, bias=True)\n",
       "                )\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (6): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): Attention(\n",
       "                (to_q): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_k): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_v): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (attend): Attend(\n",
       "                  (attn_dropout): Dropout(p=0.4, inplace=False)\n",
       "                )\n",
       "                (to_out): Linear(in_features=128, out_features=120, bias=False)\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (7): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): FeedForward(\n",
       "                (ff): Sequential(\n",
       "                  (0): GLU(\n",
       "                    (act): GELU(approximate='none')\n",
       "                    (proj): Linear(in_features=120, out_features=960, bias=True)\n",
       "                  )\n",
       "                  (1): Dropout(p=0.4, inplace=False)\n",
       "                  (2): Linear(in_features=480, out_features=120, bias=True)\n",
       "                )\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (8): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): Attention(\n",
       "                (to_q): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_k): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_v): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (attend): Attend(\n",
       "                  (attn_dropout): Dropout(p=0.4, inplace=False)\n",
       "                )\n",
       "                (to_out): Linear(in_features=128, out_features=120, bias=False)\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (9): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): FeedForward(\n",
       "                (ff): Sequential(\n",
       "                  (0): GLU(\n",
       "                    (act): GELU(approximate='none')\n",
       "                    (proj): Linear(in_features=120, out_features=960, bias=True)\n",
       "                  )\n",
       "                  (1): Dropout(p=0.4, inplace=False)\n",
       "                  (2): Linear(in_features=480, out_features=120, bias=True)\n",
       "                )\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (10): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): Attention(\n",
       "                (to_q): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_k): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_v): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (attend): Attend(\n",
       "                  (attn_dropout): Dropout(p=0.4, inplace=False)\n",
       "                )\n",
       "                (to_out): Linear(in_features=128, out_features=120, bias=False)\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (11): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): FeedForward(\n",
       "                (ff): Sequential(\n",
       "                  (0): GLU(\n",
       "                    (act): GELU(approximate='none')\n",
       "                    (proj): Linear(in_features=120, out_features=960, bias=True)\n",
       "                  )\n",
       "                  (1): Dropout(p=0.4, inplace=False)\n",
       "                  (2): Linear(in_features=480, out_features=120, bias=True)\n",
       "                )\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (12): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): Attention(\n",
       "                (to_q): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_k): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_v): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (attend): Attend(\n",
       "                  (attn_dropout): Dropout(p=0.4, inplace=False)\n",
       "                )\n",
       "                (to_out): Linear(in_features=128, out_features=120, bias=False)\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (13): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): FeedForward(\n",
       "                (ff): Sequential(\n",
       "                  (0): GLU(\n",
       "                    (act): GELU(approximate='none')\n",
       "                    (proj): Linear(in_features=120, out_features=960, bias=True)\n",
       "                  )\n",
       "                  (1): Dropout(p=0.4, inplace=False)\n",
       "                  (2): Linear(in_features=480, out_features=120, bias=True)\n",
       "                )\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (14): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): Attention(\n",
       "                (to_q): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_k): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_v): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (attend): Attend(\n",
       "                  (attn_dropout): Dropout(p=0.4, inplace=False)\n",
       "                )\n",
       "                (to_out): Linear(in_features=128, out_features=120, bias=False)\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (15): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): FeedForward(\n",
       "                (ff): Sequential(\n",
       "                  (0): GLU(\n",
       "                    (act): GELU(approximate='none')\n",
       "                    (proj): Linear(in_features=120, out_features=960, bias=True)\n",
       "                  )\n",
       "                  (1): Dropout(p=0.4, inplace=False)\n",
       "                  (2): Linear(in_features=480, out_features=120, bias=True)\n",
       "                )\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (16): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): Attention(\n",
       "                (to_q): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_k): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_v): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (attend): Attend(\n",
       "                  (attn_dropout): Dropout(p=0.4, inplace=False)\n",
       "                )\n",
       "                (to_out): Linear(in_features=128, out_features=120, bias=False)\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (17): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): FeedForward(\n",
       "                (ff): Sequential(\n",
       "                  (0): GLU(\n",
       "                    (act): GELU(approximate='none')\n",
       "                    (proj): Linear(in_features=120, out_features=960, bias=True)\n",
       "                  )\n",
       "                  (1): Dropout(p=0.4, inplace=False)\n",
       "                  (2): Linear(in_features=480, out_features=120, bias=True)\n",
       "                )\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (18): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): Attention(\n",
       "                (to_q): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_k): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_v): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (attend): Attend(\n",
       "                  (attn_dropout): Dropout(p=0.4, inplace=False)\n",
       "                )\n",
       "                (to_out): Linear(in_features=128, out_features=120, bias=False)\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (19): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): FeedForward(\n",
       "                (ff): Sequential(\n",
       "                  (0): GLU(\n",
       "                    (act): GELU(approximate='none')\n",
       "                    (proj): Linear(in_features=120, out_features=960, bias=True)\n",
       "                  )\n",
       "                  (1): Dropout(p=0.4, inplace=False)\n",
       "                  (2): Linear(in_features=480, out_features=120, bias=True)\n",
       "                )\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (20): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): Attention(\n",
       "                (to_q): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_k): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_v): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (attend): Attend(\n",
       "                  (attn_dropout): Dropout(p=0.4, inplace=False)\n",
       "                )\n",
       "                (to_out): Linear(in_features=128, out_features=120, bias=False)\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (21): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): FeedForward(\n",
       "                (ff): Sequential(\n",
       "                  (0): GLU(\n",
       "                    (act): GELU(approximate='none')\n",
       "                    (proj): Linear(in_features=120, out_features=960, bias=True)\n",
       "                  )\n",
       "                  (1): Dropout(p=0.4, inplace=False)\n",
       "                  (2): Linear(in_features=480, out_features=120, bias=True)\n",
       "                )\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (22): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): Attention(\n",
       "                (to_q): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_k): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_v): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (attend): Attend(\n",
       "                  (attn_dropout): Dropout(p=0.4, inplace=False)\n",
       "                )\n",
       "                (to_out): Linear(in_features=128, out_features=120, bias=False)\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (23): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): FeedForward(\n",
       "                (ff): Sequential(\n",
       "                  (0): GLU(\n",
       "                    (act): GELU(approximate='none')\n",
       "                    (proj): Linear(in_features=120, out_features=960, bias=True)\n",
       "                  )\n",
       "                  (1): Dropout(p=0.4, inplace=False)\n",
       "                  (2): Linear(in_features=480, out_features=120, bias=True)\n",
       "                )\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (24): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): Attention(\n",
       "                (to_q): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_k): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_v): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (attend): Attend(\n",
       "                  (attn_dropout): Dropout(p=0.4, inplace=False)\n",
       "                )\n",
       "                (to_out): Linear(in_features=128, out_features=120, bias=False)\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (25): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): FeedForward(\n",
       "                (ff): Sequential(\n",
       "                  (0): GLU(\n",
       "                    (act): GELU(approximate='none')\n",
       "                    (proj): Linear(in_features=120, out_features=960, bias=True)\n",
       "                  )\n",
       "                  (1): Dropout(p=0.4, inplace=False)\n",
       "                  (2): Linear(in_features=480, out_features=120, bias=True)\n",
       "                )\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (26): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): Attention(\n",
       "                (to_q): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_k): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_v): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (attend): Attend(\n",
       "                  (attn_dropout): Dropout(p=0.4, inplace=False)\n",
       "                )\n",
       "                (to_out): Linear(in_features=128, out_features=120, bias=False)\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (27): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): FeedForward(\n",
       "                (ff): Sequential(\n",
       "                  (0): GLU(\n",
       "                    (act): GELU(approximate='none')\n",
       "                    (proj): Linear(in_features=120, out_features=960, bias=True)\n",
       "                  )\n",
       "                  (1): Dropout(p=0.4, inplace=False)\n",
       "                  (2): Linear(in_features=480, out_features=120, bias=True)\n",
       "                )\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (28): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): Attention(\n",
       "                (to_q): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_k): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_v): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (attend): Attend(\n",
       "                  (attn_dropout): Dropout(p=0.4, inplace=False)\n",
       "                )\n",
       "                (to_out): Linear(in_features=128, out_features=120, bias=False)\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (29): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): FeedForward(\n",
       "                (ff): Sequential(\n",
       "                  (0): GLU(\n",
       "                    (act): GELU(approximate='none')\n",
       "                    (proj): Linear(in_features=120, out_features=960, bias=True)\n",
       "                  )\n",
       "                  (1): Dropout(p=0.4, inplace=False)\n",
       "                  (2): Linear(in_features=480, out_features=120, bias=True)\n",
       "                )\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (30): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): Attention(\n",
       "                (to_q): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_k): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_v): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (attend): Attend(\n",
       "                  (attn_dropout): Dropout(p=0.4, inplace=False)\n",
       "                )\n",
       "                (to_out): Linear(in_features=128, out_features=120, bias=False)\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (31): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): FeedForward(\n",
       "                (ff): Sequential(\n",
       "                  (0): GLU(\n",
       "                    (act): GELU(approximate='none')\n",
       "                    (proj): Linear(in_features=120, out_features=960, bias=True)\n",
       "                  )\n",
       "                  (1): Dropout(p=0.4, inplace=False)\n",
       "                  (2): Linear(in_features=480, out_features=120, bias=True)\n",
       "                )\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (32): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): Attention(\n",
       "                (to_q): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_k): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_v): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (attend): Attend(\n",
       "                  (attn_dropout): Dropout(p=0.4, inplace=False)\n",
       "                )\n",
       "                (to_out): Linear(in_features=128, out_features=120, bias=False)\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (33): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): FeedForward(\n",
       "                (ff): Sequential(\n",
       "                  (0): GLU(\n",
       "                    (act): GELU(approximate='none')\n",
       "                    (proj): Linear(in_features=120, out_features=960, bias=True)\n",
       "                  )\n",
       "                  (1): Dropout(p=0.4, inplace=False)\n",
       "                  (2): Linear(in_features=480, out_features=120, bias=True)\n",
       "                )\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (34): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): Attention(\n",
       "                (to_q): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_k): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_v): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (attend): Attend(\n",
       "                  (attn_dropout): Dropout(p=0.4, inplace=False)\n",
       "                )\n",
       "                (to_out): Linear(in_features=128, out_features=120, bias=False)\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (35): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): FeedForward(\n",
       "                (ff): Sequential(\n",
       "                  (0): GLU(\n",
       "                    (act): GELU(approximate='none')\n",
       "                    (proj): Linear(in_features=120, out_features=960, bias=True)\n",
       "                  )\n",
       "                  (1): Dropout(p=0.4, inplace=False)\n",
       "                  (2): Linear(in_features=480, out_features=120, bias=True)\n",
       "                )\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (36): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): Attention(\n",
       "                (to_q): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_k): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_v): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (attend): Attend(\n",
       "                  (attn_dropout): Dropout(p=0.4, inplace=False)\n",
       "                )\n",
       "                (to_out): Linear(in_features=128, out_features=120, bias=False)\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (37): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): FeedForward(\n",
       "                (ff): Sequential(\n",
       "                  (0): GLU(\n",
       "                    (act): GELU(approximate='none')\n",
       "                    (proj): Linear(in_features=120, out_features=960, bias=True)\n",
       "                  )\n",
       "                  (1): Dropout(p=0.4, inplace=False)\n",
       "                  (2): Linear(in_features=480, out_features=120, bias=True)\n",
       "                )\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (38): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): Attention(\n",
       "                (to_q): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_k): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_v): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (attend): Attend(\n",
       "                  (attn_dropout): Dropout(p=0.4, inplace=False)\n",
       "                )\n",
       "                (to_out): Linear(in_features=128, out_features=120, bias=False)\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (39): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): FeedForward(\n",
       "                (ff): Sequential(\n",
       "                  (0): GLU(\n",
       "                    (act): GELU(approximate='none')\n",
       "                    (proj): Linear(in_features=120, out_features=960, bias=True)\n",
       "                  )\n",
       "                  (1): Dropout(p=0.4, inplace=False)\n",
       "                  (2): Linear(in_features=480, out_features=120, bias=True)\n",
       "                )\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (40): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): Attention(\n",
       "                (to_q): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_k): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_v): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (attend): Attend(\n",
       "                  (attn_dropout): Dropout(p=0.4, inplace=False)\n",
       "                )\n",
       "                (to_out): Linear(in_features=128, out_features=120, bias=False)\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (41): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): FeedForward(\n",
       "                (ff): Sequential(\n",
       "                  (0): GLU(\n",
       "                    (act): GELU(approximate='none')\n",
       "                    (proj): Linear(in_features=120, out_features=960, bias=True)\n",
       "                  )\n",
       "                  (1): Dropout(p=0.4, inplace=False)\n",
       "                  (2): Linear(in_features=480, out_features=120, bias=True)\n",
       "                )\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (42): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): Attention(\n",
       "                (to_q): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_k): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_v): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (attend): Attend(\n",
       "                  (attn_dropout): Dropout(p=0.4, inplace=False)\n",
       "                )\n",
       "                (to_out): Linear(in_features=128, out_features=120, bias=False)\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (43): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): FeedForward(\n",
       "                (ff): Sequential(\n",
       "                  (0): GLU(\n",
       "                    (act): GELU(approximate='none')\n",
       "                    (proj): Linear(in_features=120, out_features=960, bias=True)\n",
       "                  )\n",
       "                  (1): Dropout(p=0.4, inplace=False)\n",
       "                  (2): Linear(in_features=480, out_features=120, bias=True)\n",
       "                )\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (44): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): Attention(\n",
       "                (to_q): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_k): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_v): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (attend): Attend(\n",
       "                  (attn_dropout): Dropout(p=0.4, inplace=False)\n",
       "                )\n",
       "                (to_out): Linear(in_features=128, out_features=120, bias=False)\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (45): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): FeedForward(\n",
       "                (ff): Sequential(\n",
       "                  (0): GLU(\n",
       "                    (act): GELU(approximate='none')\n",
       "                    (proj): Linear(in_features=120, out_features=960, bias=True)\n",
       "                  )\n",
       "                  (1): Dropout(p=0.4, inplace=False)\n",
       "                  (2): Linear(in_features=480, out_features=120, bias=True)\n",
       "                )\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (46): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): Attention(\n",
       "                (to_q): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_k): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_v): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (attend): Attend(\n",
       "                  (attn_dropout): Dropout(p=0.4, inplace=False)\n",
       "                )\n",
       "                (to_out): Linear(in_features=128, out_features=120, bias=False)\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (47): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): FeedForward(\n",
       "                (ff): Sequential(\n",
       "                  (0): GLU(\n",
       "                    (act): GELU(approximate='none')\n",
       "                    (proj): Linear(in_features=120, out_features=960, bias=True)\n",
       "                  )\n",
       "                  (1): Dropout(p=0.4, inplace=False)\n",
       "                  (2): Linear(in_features=480, out_features=120, bias=True)\n",
       "                )\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (48): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): Attention(\n",
       "                (to_q): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_k): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_v): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (attend): Attend(\n",
       "                  (attn_dropout): Dropout(p=0.4, inplace=False)\n",
       "                )\n",
       "                (to_out): Linear(in_features=128, out_features=120, bias=False)\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (49): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): FeedForward(\n",
       "                (ff): Sequential(\n",
       "                  (0): GLU(\n",
       "                    (act): GELU(approximate='none')\n",
       "                    (proj): Linear(in_features=120, out_features=960, bias=True)\n",
       "                  )\n",
       "                  (1): Dropout(p=0.4, inplace=False)\n",
       "                  (2): Linear(in_features=480, out_features=120, bias=True)\n",
       "                )\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (50): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): Attention(\n",
       "                (to_q): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_k): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_v): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (attend): Attend(\n",
       "                  (attn_dropout): Dropout(p=0.4, inplace=False)\n",
       "                )\n",
       "                (to_out): Linear(in_features=128, out_features=120, bias=False)\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (51): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): FeedForward(\n",
       "                (ff): Sequential(\n",
       "                  (0): GLU(\n",
       "                    (act): GELU(approximate='none')\n",
       "                    (proj): Linear(in_features=120, out_features=960, bias=True)\n",
       "                  )\n",
       "                  (1): Dropout(p=0.4, inplace=False)\n",
       "                  (2): Linear(in_features=480, out_features=120, bias=True)\n",
       "                )\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (52): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): Attention(\n",
       "                (to_q): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_k): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_v): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (attend): Attend(\n",
       "                  (attn_dropout): Dropout(p=0.4, inplace=False)\n",
       "                )\n",
       "                (to_out): Linear(in_features=128, out_features=120, bias=False)\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (53): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): FeedForward(\n",
       "                (ff): Sequential(\n",
       "                  (0): GLU(\n",
       "                    (act): GELU(approximate='none')\n",
       "                    (proj): Linear(in_features=120, out_features=960, bias=True)\n",
       "                  )\n",
       "                  (1): Dropout(p=0.4, inplace=False)\n",
       "                  (2): Linear(in_features=480, out_features=120, bias=True)\n",
       "                )\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (54): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): Attention(\n",
       "                (to_q): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_k): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_v): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (attend): Attend(\n",
       "                  (attn_dropout): Dropout(p=0.4, inplace=False)\n",
       "                )\n",
       "                (to_out): Linear(in_features=128, out_features=120, bias=False)\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (55): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): FeedForward(\n",
       "                (ff): Sequential(\n",
       "                  (0): GLU(\n",
       "                    (act): GELU(approximate='none')\n",
       "                    (proj): Linear(in_features=120, out_features=960, bias=True)\n",
       "                  )\n",
       "                  (1): Dropout(p=0.4, inplace=False)\n",
       "                  (2): Linear(in_features=480, out_features=120, bias=True)\n",
       "                )\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (56): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): Attention(\n",
       "                (to_q): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_k): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_v): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (attend): Attend(\n",
       "                  (attn_dropout): Dropout(p=0.4, inplace=False)\n",
       "                )\n",
       "                (to_out): Linear(in_features=128, out_features=120, bias=False)\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (57): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): FeedForward(\n",
       "                (ff): Sequential(\n",
       "                  (0): GLU(\n",
       "                    (act): GELU(approximate='none')\n",
       "                    (proj): Linear(in_features=120, out_features=960, bias=True)\n",
       "                  )\n",
       "                  (1): Dropout(p=0.4, inplace=False)\n",
       "                  (2): Linear(in_features=480, out_features=120, bias=True)\n",
       "                )\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (58): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): Attention(\n",
       "                (to_q): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_k): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_v): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (attend): Attend(\n",
       "                  (attn_dropout): Dropout(p=0.4, inplace=False)\n",
       "                )\n",
       "                (to_out): Linear(in_features=128, out_features=120, bias=False)\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (59): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): FeedForward(\n",
       "                (ff): Sequential(\n",
       "                  (0): GLU(\n",
       "                    (act): GELU(approximate='none')\n",
       "                    (proj): Linear(in_features=120, out_features=960, bias=True)\n",
       "                  )\n",
       "                  (1): Dropout(p=0.4, inplace=False)\n",
       "                  (2): Linear(in_features=480, out_features=120, bias=True)\n",
       "                )\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (60): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): Attention(\n",
       "                (to_q): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_k): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_v): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (attend): Attend(\n",
       "                  (attn_dropout): Dropout(p=0.4, inplace=False)\n",
       "                )\n",
       "                (to_out): Linear(in_features=128, out_features=120, bias=False)\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (61): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): FeedForward(\n",
       "                (ff): Sequential(\n",
       "                  (0): GLU(\n",
       "                    (act): GELU(approximate='none')\n",
       "                    (proj): Linear(in_features=120, out_features=960, bias=True)\n",
       "                  )\n",
       "                  (1): Dropout(p=0.4, inplace=False)\n",
       "                  (2): Linear(in_features=480, out_features=120, bias=True)\n",
       "                )\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (62): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): Attention(\n",
       "                (to_q): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_k): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_v): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (attend): Attend(\n",
       "                  (attn_dropout): Dropout(p=0.4, inplace=False)\n",
       "                )\n",
       "                (to_out): Linear(in_features=128, out_features=120, bias=False)\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (63): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): FeedForward(\n",
       "                (ff): Sequential(\n",
       "                  (0): GLU(\n",
       "                    (act): GELU(approximate='none')\n",
       "                    (proj): Linear(in_features=120, out_features=960, bias=True)\n",
       "                  )\n",
       "                  (1): Dropout(p=0.4, inplace=False)\n",
       "                  (2): Linear(in_features=480, out_features=120, bias=True)\n",
       "                )\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (64): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): Attention(\n",
       "                (to_q): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_k): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_v): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (attend): Attend(\n",
       "                  (attn_dropout): Dropout(p=0.4, inplace=False)\n",
       "                )\n",
       "                (to_out): Linear(in_features=128, out_features=120, bias=False)\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (65): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): FeedForward(\n",
       "                (ff): Sequential(\n",
       "                  (0): GLU(\n",
       "                    (act): GELU(approximate='none')\n",
       "                    (proj): Linear(in_features=120, out_features=960, bias=True)\n",
       "                  )\n",
       "                  (1): Dropout(p=0.4, inplace=False)\n",
       "                  (2): Linear(in_features=480, out_features=120, bias=True)\n",
       "                )\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (66): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): Attention(\n",
       "                (to_q): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_k): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_v): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (attend): Attend(\n",
       "                  (attn_dropout): Dropout(p=0.4, inplace=False)\n",
       "                )\n",
       "                (to_out): Linear(in_features=128, out_features=120, bias=False)\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (67): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): FeedForward(\n",
       "                (ff): Sequential(\n",
       "                  (0): GLU(\n",
       "                    (act): GELU(approximate='none')\n",
       "                    (proj): Linear(in_features=120, out_features=960, bias=True)\n",
       "                  )\n",
       "                  (1): Dropout(p=0.4, inplace=False)\n",
       "                  (2): Linear(in_features=480, out_features=120, bias=True)\n",
       "                )\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (68): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): Attention(\n",
       "                (to_q): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_k): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_v): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (attend): Attend(\n",
       "                  (attn_dropout): Dropout(p=0.4, inplace=False)\n",
       "                )\n",
       "                (to_out): Linear(in_features=128, out_features=120, bias=False)\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (69): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): FeedForward(\n",
       "                (ff): Sequential(\n",
       "                  (0): GLU(\n",
       "                    (act): GELU(approximate='none')\n",
       "                    (proj): Linear(in_features=120, out_features=960, bias=True)\n",
       "                  )\n",
       "                  (1): Dropout(p=0.4, inplace=False)\n",
       "                  (2): Linear(in_features=480, out_features=120, bias=True)\n",
       "                )\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (70): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): Attention(\n",
       "                (to_q): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_k): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_v): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (attend): Attend(\n",
       "                  (attn_dropout): Dropout(p=0.4, inplace=False)\n",
       "                )\n",
       "                (to_out): Linear(in_features=128, out_features=120, bias=False)\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (71): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): FeedForward(\n",
       "                (ff): Sequential(\n",
       "                  (0): GLU(\n",
       "                    (act): GELU(approximate='none')\n",
       "                    (proj): Linear(in_features=120, out_features=960, bias=True)\n",
       "                  )\n",
       "                  (1): Dropout(p=0.4, inplace=False)\n",
       "                  (2): Linear(in_features=480, out_features=120, bias=True)\n",
       "                )\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (72): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): Attention(\n",
       "                (to_q): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_k): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_v): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (attend): Attend(\n",
       "                  (attn_dropout): Dropout(p=0.4, inplace=False)\n",
       "                )\n",
       "                (to_out): Linear(in_features=128, out_features=120, bias=False)\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (73): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): FeedForward(\n",
       "                (ff): Sequential(\n",
       "                  (0): GLU(\n",
       "                    (act): GELU(approximate='none')\n",
       "                    (proj): Linear(in_features=120, out_features=960, bias=True)\n",
       "                  )\n",
       "                  (1): Dropout(p=0.4, inplace=False)\n",
       "                  (2): Linear(in_features=480, out_features=120, bias=True)\n",
       "                )\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (74): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): Attention(\n",
       "                (to_q): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_k): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_v): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (attend): Attend(\n",
       "                  (attn_dropout): Dropout(p=0.4, inplace=False)\n",
       "                )\n",
       "                (to_out): Linear(in_features=128, out_features=120, bias=False)\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (75): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): FeedForward(\n",
       "                (ff): Sequential(\n",
       "                  (0): GLU(\n",
       "                    (act): GELU(approximate='none')\n",
       "                    (proj): Linear(in_features=120, out_features=960, bias=True)\n",
       "                  )\n",
       "                  (1): Dropout(p=0.4, inplace=False)\n",
       "                  (2): Linear(in_features=480, out_features=120, bias=True)\n",
       "                )\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (76): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): Attention(\n",
       "                (to_q): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_k): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_v): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (attend): Attend(\n",
       "                  (attn_dropout): Dropout(p=0.4, inplace=False)\n",
       "                )\n",
       "                (to_out): Linear(in_features=128, out_features=120, bias=False)\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (77): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): FeedForward(\n",
       "                (ff): Sequential(\n",
       "                  (0): GLU(\n",
       "                    (act): GELU(approximate='none')\n",
       "                    (proj): Linear(in_features=120, out_features=960, bias=True)\n",
       "                  )\n",
       "                  (1): Dropout(p=0.4, inplace=False)\n",
       "                  (2): Linear(in_features=480, out_features=120, bias=True)\n",
       "                )\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (78): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): Attention(\n",
       "                (to_q): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_k): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_v): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (attend): Attend(\n",
       "                  (attn_dropout): Dropout(p=0.4, inplace=False)\n",
       "                )\n",
       "                (to_out): Linear(in_features=128, out_features=120, bias=False)\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (79): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): FeedForward(\n",
       "                (ff): Sequential(\n",
       "                  (0): GLU(\n",
       "                    (act): GELU(approximate='none')\n",
       "                    (proj): Linear(in_features=120, out_features=960, bias=True)\n",
       "                  )\n",
       "                  (1): Dropout(p=0.4, inplace=False)\n",
       "                  (2): Linear(in_features=480, out_features=120, bias=True)\n",
       "                )\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (80): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): Attention(\n",
       "                (to_q): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_k): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_v): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (attend): Attend(\n",
       "                  (attn_dropout): Dropout(p=0.4, inplace=False)\n",
       "                )\n",
       "                (to_out): Linear(in_features=128, out_features=120, bias=False)\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (81): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): FeedForward(\n",
       "                (ff): Sequential(\n",
       "                  (0): GLU(\n",
       "                    (act): GELU(approximate='none')\n",
       "                    (proj): Linear(in_features=120, out_features=960, bias=True)\n",
       "                  )\n",
       "                  (1): Dropout(p=0.4, inplace=False)\n",
       "                  (2): Linear(in_features=480, out_features=120, bias=True)\n",
       "                )\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (82): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): Attention(\n",
       "                (to_q): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_k): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_v): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (attend): Attend(\n",
       "                  (attn_dropout): Dropout(p=0.4, inplace=False)\n",
       "                )\n",
       "                (to_out): Linear(in_features=128, out_features=120, bias=False)\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (83): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): FeedForward(\n",
       "                (ff): Sequential(\n",
       "                  (0): GLU(\n",
       "                    (act): GELU(approximate='none')\n",
       "                    (proj): Linear(in_features=120, out_features=960, bias=True)\n",
       "                  )\n",
       "                  (1): Dropout(p=0.4, inplace=False)\n",
       "                  (2): Linear(in_features=480, out_features=120, bias=True)\n",
       "                )\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (84): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): Attention(\n",
       "                (to_q): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_k): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_v): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (attend): Attend(\n",
       "                  (attn_dropout): Dropout(p=0.4, inplace=False)\n",
       "                )\n",
       "                (to_out): Linear(in_features=128, out_features=120, bias=False)\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (85): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): FeedForward(\n",
       "                (ff): Sequential(\n",
       "                  (0): GLU(\n",
       "                    (act): GELU(approximate='none')\n",
       "                    (proj): Linear(in_features=120, out_features=960, bias=True)\n",
       "                  )\n",
       "                  (1): Dropout(p=0.4, inplace=False)\n",
       "                  (2): Linear(in_features=480, out_features=120, bias=True)\n",
       "                )\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (86): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): Attention(\n",
       "                (to_q): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_k): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_v): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (attend): Attend(\n",
       "                  (attn_dropout): Dropout(p=0.4, inplace=False)\n",
       "                )\n",
       "                (to_out): Linear(in_features=128, out_features=120, bias=False)\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (87): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): FeedForward(\n",
       "                (ff): Sequential(\n",
       "                  (0): GLU(\n",
       "                    (act): GELU(approximate='none')\n",
       "                    (proj): Linear(in_features=120, out_features=960, bias=True)\n",
       "                  )\n",
       "                  (1): Dropout(p=0.4, inplace=False)\n",
       "                  (2): Linear(in_features=480, out_features=120, bias=True)\n",
       "                )\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (88): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): Attention(\n",
       "                (to_q): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_k): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_v): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (attend): Attend(\n",
       "                  (attn_dropout): Dropout(p=0.4, inplace=False)\n",
       "                )\n",
       "                (to_out): Linear(in_features=128, out_features=120, bias=False)\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (89): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): FeedForward(\n",
       "                (ff): Sequential(\n",
       "                  (0): GLU(\n",
       "                    (act): GELU(approximate='none')\n",
       "                    (proj): Linear(in_features=120, out_features=960, bias=True)\n",
       "                  )\n",
       "                  (1): Dropout(p=0.4, inplace=False)\n",
       "                  (2): Linear(in_features=480, out_features=120, bias=True)\n",
       "                )\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (90): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): Attention(\n",
       "                (to_q): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_k): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_v): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (attend): Attend(\n",
       "                  (attn_dropout): Dropout(p=0.4, inplace=False)\n",
       "                )\n",
       "                (to_out): Linear(in_features=128, out_features=120, bias=False)\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (91): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): FeedForward(\n",
       "                (ff): Sequential(\n",
       "                  (0): GLU(\n",
       "                    (act): GELU(approximate='none')\n",
       "                    (proj): Linear(in_features=120, out_features=960, bias=True)\n",
       "                  )\n",
       "                  (1): Dropout(p=0.4, inplace=False)\n",
       "                  (2): Linear(in_features=480, out_features=120, bias=True)\n",
       "                )\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (92): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): Attention(\n",
       "                (to_q): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_k): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_v): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (attend): Attend(\n",
       "                  (attn_dropout): Dropout(p=0.4, inplace=False)\n",
       "                )\n",
       "                (to_out): Linear(in_features=128, out_features=120, bias=False)\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (93): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): FeedForward(\n",
       "                (ff): Sequential(\n",
       "                  (0): GLU(\n",
       "                    (act): GELU(approximate='none')\n",
       "                    (proj): Linear(in_features=120, out_features=960, bias=True)\n",
       "                  )\n",
       "                  (1): Dropout(p=0.4, inplace=False)\n",
       "                  (2): Linear(in_features=480, out_features=120, bias=True)\n",
       "                )\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (94): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): Attention(\n",
       "                (to_q): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_k): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_v): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (attend): Attend(\n",
       "                  (attn_dropout): Dropout(p=0.4, inplace=False)\n",
       "                )\n",
       "                (to_out): Linear(in_features=128, out_features=120, bias=False)\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (95): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): FeedForward(\n",
       "                (ff): Sequential(\n",
       "                  (0): GLU(\n",
       "                    (act): GELU(approximate='none')\n",
       "                    (proj): Linear(in_features=120, out_features=960, bias=True)\n",
       "                  )\n",
       "                  (1): Dropout(p=0.4, inplace=False)\n",
       "                  (2): Linear(in_features=480, out_features=120, bias=True)\n",
       "                )\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (96): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): Attention(\n",
       "                (to_q): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_k): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_v): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (attend): Attend(\n",
       "                  (attn_dropout): Dropout(p=0.4, inplace=False)\n",
       "                )\n",
       "                (to_out): Linear(in_features=128, out_features=120, bias=False)\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (97): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): FeedForward(\n",
       "                (ff): Sequential(\n",
       "                  (0): GLU(\n",
       "                    (act): GELU(approximate='none')\n",
       "                    (proj): Linear(in_features=120, out_features=960, bias=True)\n",
       "                  )\n",
       "                  (1): Dropout(p=0.4, inplace=False)\n",
       "                  (2): Linear(in_features=480, out_features=120, bias=True)\n",
       "                )\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (98): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): Attention(\n",
       "                (to_q): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_k): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_v): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (attend): Attend(\n",
       "                  (attn_dropout): Dropout(p=0.4, inplace=False)\n",
       "                )\n",
       "                (to_out): Linear(in_features=128, out_features=120, bias=False)\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (99): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): FeedForward(\n",
       "                (ff): Sequential(\n",
       "                  (0): GLU(\n",
       "                    (act): GELU(approximate='none')\n",
       "                    (proj): Linear(in_features=120, out_features=960, bias=True)\n",
       "                  )\n",
       "                  (1): Dropout(p=0.4, inplace=False)\n",
       "                  (2): Linear(in_features=480, out_features=120, bias=True)\n",
       "                )\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (100): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): Attention(\n",
       "                (to_q): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_k): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_v): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (attend): Attend(\n",
       "                  (attn_dropout): Dropout(p=0.4, inplace=False)\n",
       "                )\n",
       "                (to_out): Linear(in_features=128, out_features=120, bias=False)\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (101): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): FeedForward(\n",
       "                (ff): Sequential(\n",
       "                  (0): GLU(\n",
       "                    (act): GELU(approximate='none')\n",
       "                    (proj): Linear(in_features=120, out_features=960, bias=True)\n",
       "                  )\n",
       "                  (1): Dropout(p=0.4, inplace=False)\n",
       "                  (2): Linear(in_features=480, out_features=120, bias=True)\n",
       "                )\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (102): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): Attention(\n",
       "                (to_q): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_k): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_v): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (attend): Attend(\n",
       "                  (attn_dropout): Dropout(p=0.4, inplace=False)\n",
       "                )\n",
       "                (to_out): Linear(in_features=128, out_features=120, bias=False)\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (103): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): FeedForward(\n",
       "                (ff): Sequential(\n",
       "                  (0): GLU(\n",
       "                    (act): GELU(approximate='none')\n",
       "                    (proj): Linear(in_features=120, out_features=960, bias=True)\n",
       "                  )\n",
       "                  (1): Dropout(p=0.4, inplace=False)\n",
       "                  (2): Linear(in_features=480, out_features=120, bias=True)\n",
       "                )\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (104): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): Attention(\n",
       "                (to_q): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_k): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_v): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (attend): Attend(\n",
       "                  (attn_dropout): Dropout(p=0.4, inplace=False)\n",
       "                )\n",
       "                (to_out): Linear(in_features=128, out_features=120, bias=False)\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (105): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): FeedForward(\n",
       "                (ff): Sequential(\n",
       "                  (0): GLU(\n",
       "                    (act): GELU(approximate='none')\n",
       "                    (proj): Linear(in_features=120, out_features=960, bias=True)\n",
       "                  )\n",
       "                  (1): Dropout(p=0.4, inplace=False)\n",
       "                  (2): Linear(in_features=480, out_features=120, bias=True)\n",
       "                )\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (106): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): Attention(\n",
       "                (to_q): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_k): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_v): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (attend): Attend(\n",
       "                  (attn_dropout): Dropout(p=0.4, inplace=False)\n",
       "                )\n",
       "                (to_out): Linear(in_features=128, out_features=120, bias=False)\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (107): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): FeedForward(\n",
       "                (ff): Sequential(\n",
       "                  (0): GLU(\n",
       "                    (act): GELU(approximate='none')\n",
       "                    (proj): Linear(in_features=120, out_features=960, bias=True)\n",
       "                  )\n",
       "                  (1): Dropout(p=0.4, inplace=False)\n",
       "                  (2): Linear(in_features=480, out_features=120, bias=True)\n",
       "                )\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (108): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): Attention(\n",
       "                (to_q): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_k): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_v): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (attend): Attend(\n",
       "                  (attn_dropout): Dropout(p=0.4, inplace=False)\n",
       "                )\n",
       "                (to_out): Linear(in_features=128, out_features=120, bias=False)\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (109): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): FeedForward(\n",
       "                (ff): Sequential(\n",
       "                  (0): GLU(\n",
       "                    (act): GELU(approximate='none')\n",
       "                    (proj): Linear(in_features=120, out_features=960, bias=True)\n",
       "                  )\n",
       "                  (1): Dropout(p=0.4, inplace=False)\n",
       "                  (2): Linear(in_features=480, out_features=120, bias=True)\n",
       "                )\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (110): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): Attention(\n",
       "                (to_q): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_k): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_v): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (attend): Attend(\n",
       "                  (attn_dropout): Dropout(p=0.4, inplace=False)\n",
       "                )\n",
       "                (to_out): Linear(in_features=128, out_features=120, bias=False)\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (111): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): FeedForward(\n",
       "                (ff): Sequential(\n",
       "                  (0): GLU(\n",
       "                    (act): GELU(approximate='none')\n",
       "                    (proj): Linear(in_features=120, out_features=960, bias=True)\n",
       "                  )\n",
       "                  (1): Dropout(p=0.4, inplace=False)\n",
       "                  (2): Linear(in_features=480, out_features=120, bias=True)\n",
       "                )\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (112): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): Attention(\n",
       "                (to_q): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_k): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_v): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (attend): Attend(\n",
       "                  (attn_dropout): Dropout(p=0.4, inplace=False)\n",
       "                )\n",
       "                (to_out): Linear(in_features=128, out_features=120, bias=False)\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (113): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): FeedForward(\n",
       "                (ff): Sequential(\n",
       "                  (0): GLU(\n",
       "                    (act): GELU(approximate='none')\n",
       "                    (proj): Linear(in_features=120, out_features=960, bias=True)\n",
       "                  )\n",
       "                  (1): Dropout(p=0.4, inplace=False)\n",
       "                  (2): Linear(in_features=480, out_features=120, bias=True)\n",
       "                )\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (114): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): Attention(\n",
       "                (to_q): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_k): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_v): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (attend): Attend(\n",
       "                  (attn_dropout): Dropout(p=0.4, inplace=False)\n",
       "                )\n",
       "                (to_out): Linear(in_features=128, out_features=120, bias=False)\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (115): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): FeedForward(\n",
       "                (ff): Sequential(\n",
       "                  (0): GLU(\n",
       "                    (act): GELU(approximate='none')\n",
       "                    (proj): Linear(in_features=120, out_features=960, bias=True)\n",
       "                  )\n",
       "                  (1): Dropout(p=0.4, inplace=False)\n",
       "                  (2): Linear(in_features=480, out_features=120, bias=True)\n",
       "                )\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (116): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): Attention(\n",
       "                (to_q): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_k): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_v): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (attend): Attend(\n",
       "                  (attn_dropout): Dropout(p=0.4, inplace=False)\n",
       "                )\n",
       "                (to_out): Linear(in_features=128, out_features=120, bias=False)\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (117): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): FeedForward(\n",
       "                (ff): Sequential(\n",
       "                  (0): GLU(\n",
       "                    (act): GELU(approximate='none')\n",
       "                    (proj): Linear(in_features=120, out_features=960, bias=True)\n",
       "                  )\n",
       "                  (1): Dropout(p=0.4, inplace=False)\n",
       "                  (2): Linear(in_features=480, out_features=120, bias=True)\n",
       "                )\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (118): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): Attention(\n",
       "                (to_q): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_k): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_v): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (attend): Attend(\n",
       "                  (attn_dropout): Dropout(p=0.4, inplace=False)\n",
       "                )\n",
       "                (to_out): Linear(in_features=128, out_features=120, bias=False)\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (119): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): FeedForward(\n",
       "                (ff): Sequential(\n",
       "                  (0): GLU(\n",
       "                    (act): GELU(approximate='none')\n",
       "                    (proj): Linear(in_features=120, out_features=960, bias=True)\n",
       "                  )\n",
       "                  (1): Dropout(p=0.4, inplace=False)\n",
       "                  (2): Linear(in_features=480, out_features=120, bias=True)\n",
       "                )\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (120): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): Attention(\n",
       "                (to_q): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_k): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_v): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (attend): Attend(\n",
       "                  (attn_dropout): Dropout(p=0.4, inplace=False)\n",
       "                )\n",
       "                (to_out): Linear(in_features=128, out_features=120, bias=False)\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (121): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): FeedForward(\n",
       "                (ff): Sequential(\n",
       "                  (0): GLU(\n",
       "                    (act): GELU(approximate='none')\n",
       "                    (proj): Linear(in_features=120, out_features=960, bias=True)\n",
       "                  )\n",
       "                  (1): Dropout(p=0.4, inplace=False)\n",
       "                  (2): Linear(in_features=480, out_features=120, bias=True)\n",
       "                )\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (122): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): Attention(\n",
       "                (to_q): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_k): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_v): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (attend): Attend(\n",
       "                  (attn_dropout): Dropout(p=0.4, inplace=False)\n",
       "                )\n",
       "                (to_out): Linear(in_features=128, out_features=120, bias=False)\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (123): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): FeedForward(\n",
       "                (ff): Sequential(\n",
       "                  (0): GLU(\n",
       "                    (act): GELU(approximate='none')\n",
       "                    (proj): Linear(in_features=120, out_features=960, bias=True)\n",
       "                  )\n",
       "                  (1): Dropout(p=0.4, inplace=False)\n",
       "                  (2): Linear(in_features=480, out_features=120, bias=True)\n",
       "                )\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (124): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): Attention(\n",
       "                (to_q): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_k): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_v): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (attend): Attend(\n",
       "                  (attn_dropout): Dropout(p=0.4, inplace=False)\n",
       "                )\n",
       "                (to_out): Linear(in_features=128, out_features=120, bias=False)\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (125): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): FeedForward(\n",
       "                (ff): Sequential(\n",
       "                  (0): GLU(\n",
       "                    (act): GELU(approximate='none')\n",
       "                    (proj): Linear(in_features=120, out_features=960, bias=True)\n",
       "                  )\n",
       "                  (1): Dropout(p=0.4, inplace=False)\n",
       "                  (2): Linear(in_features=480, out_features=120, bias=True)\n",
       "                )\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (126): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): Attention(\n",
       "                (to_q): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_k): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_v): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (attend): Attend(\n",
       "                  (attn_dropout): Dropout(p=0.4, inplace=False)\n",
       "                )\n",
       "                (to_out): Linear(in_features=128, out_features=120, bias=False)\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (127): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): FeedForward(\n",
       "                (ff): Sequential(\n",
       "                  (0): GLU(\n",
       "                    (act): GELU(approximate='none')\n",
       "                    (proj): Linear(in_features=120, out_features=960, bias=True)\n",
       "                  )\n",
       "                  (1): Dropout(p=0.4, inplace=False)\n",
       "                  (2): Linear(in_features=480, out_features=120, bias=True)\n",
       "                )\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (128): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): Attention(\n",
       "                (to_q): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_k): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_v): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (attend): Attend(\n",
       "                  (attn_dropout): Dropout(p=0.4, inplace=False)\n",
       "                )\n",
       "                (to_out): Linear(in_features=128, out_features=120, bias=False)\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (129): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): FeedForward(\n",
       "                (ff): Sequential(\n",
       "                  (0): GLU(\n",
       "                    (act): GELU(approximate='none')\n",
       "                    (proj): Linear(in_features=120, out_features=960, bias=True)\n",
       "                  )\n",
       "                  (1): Dropout(p=0.4, inplace=False)\n",
       "                  (2): Linear(in_features=480, out_features=120, bias=True)\n",
       "                )\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (130): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): Attention(\n",
       "                (to_q): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_k): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_v): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (attend): Attend(\n",
       "                  (attn_dropout): Dropout(p=0.4, inplace=False)\n",
       "                )\n",
       "                (to_out): Linear(in_features=128, out_features=120, bias=False)\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (131): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): FeedForward(\n",
       "                (ff): Sequential(\n",
       "                  (0): GLU(\n",
       "                    (act): GELU(approximate='none')\n",
       "                    (proj): Linear(in_features=120, out_features=960, bias=True)\n",
       "                  )\n",
       "                  (1): Dropout(p=0.4, inplace=False)\n",
       "                  (2): Linear(in_features=480, out_features=120, bias=True)\n",
       "                )\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (132): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): Attention(\n",
       "                (to_q): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_k): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_v): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (attend): Attend(\n",
       "                  (attn_dropout): Dropout(p=0.4, inplace=False)\n",
       "                )\n",
       "                (to_out): Linear(in_features=128, out_features=120, bias=False)\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (133): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): FeedForward(\n",
       "                (ff): Sequential(\n",
       "                  (0): GLU(\n",
       "                    (act): GELU(approximate='none')\n",
       "                    (proj): Linear(in_features=120, out_features=960, bias=True)\n",
       "                  )\n",
       "                  (1): Dropout(p=0.4, inplace=False)\n",
       "                  (2): Linear(in_features=480, out_features=120, bias=True)\n",
       "                )\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (134): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): Attention(\n",
       "                (to_q): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_k): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_v): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (attend): Attend(\n",
       "                  (attn_dropout): Dropout(p=0.4, inplace=False)\n",
       "                )\n",
       "                (to_out): Linear(in_features=128, out_features=120, bias=False)\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (135): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): FeedForward(\n",
       "                (ff): Sequential(\n",
       "                  (0): GLU(\n",
       "                    (act): GELU(approximate='none')\n",
       "                    (proj): Linear(in_features=120, out_features=960, bias=True)\n",
       "                  )\n",
       "                  (1): Dropout(p=0.4, inplace=False)\n",
       "                  (2): Linear(in_features=480, out_features=120, bias=True)\n",
       "                )\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (136): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): Attention(\n",
       "                (to_q): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_k): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_v): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (attend): Attend(\n",
       "                  (attn_dropout): Dropout(p=0.4, inplace=False)\n",
       "                )\n",
       "                (to_out): Linear(in_features=128, out_features=120, bias=False)\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (137): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): FeedForward(\n",
       "                (ff): Sequential(\n",
       "                  (0): GLU(\n",
       "                    (act): GELU(approximate='none')\n",
       "                    (proj): Linear(in_features=120, out_features=960, bias=True)\n",
       "                  )\n",
       "                  (1): Dropout(p=0.4, inplace=False)\n",
       "                  (2): Linear(in_features=480, out_features=120, bias=True)\n",
       "                )\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (138): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): Attention(\n",
       "                (to_q): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_k): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_v): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (attend): Attend(\n",
       "                  (attn_dropout): Dropout(p=0.4, inplace=False)\n",
       "                )\n",
       "                (to_out): Linear(in_features=128, out_features=120, bias=False)\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (139): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): FeedForward(\n",
       "                (ff): Sequential(\n",
       "                  (0): GLU(\n",
       "                    (act): GELU(approximate='none')\n",
       "                    (proj): Linear(in_features=120, out_features=960, bias=True)\n",
       "                  )\n",
       "                  (1): Dropout(p=0.4, inplace=False)\n",
       "                  (2): Linear(in_features=480, out_features=120, bias=True)\n",
       "                )\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (140): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): Attention(\n",
       "                (to_q): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_k): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_v): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (attend): Attend(\n",
       "                  (attn_dropout): Dropout(p=0.4, inplace=False)\n",
       "                )\n",
       "                (to_out): Linear(in_features=128, out_features=120, bias=False)\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (141): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): FeedForward(\n",
       "                (ff): Sequential(\n",
       "                  (0): GLU(\n",
       "                    (act): GELU(approximate='none')\n",
       "                    (proj): Linear(in_features=120, out_features=960, bias=True)\n",
       "                  )\n",
       "                  (1): Dropout(p=0.4, inplace=False)\n",
       "                  (2): Linear(in_features=480, out_features=120, bias=True)\n",
       "                )\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (142): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): Attention(\n",
       "                (to_q): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_k): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_v): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (attend): Attend(\n",
       "                  (attn_dropout): Dropout(p=0.4, inplace=False)\n",
       "                )\n",
       "                (to_out): Linear(in_features=128, out_features=120, bias=False)\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (143): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): FeedForward(\n",
       "                (ff): Sequential(\n",
       "                  (0): GLU(\n",
       "                    (act): GELU(approximate='none')\n",
       "                    (proj): Linear(in_features=120, out_features=960, bias=True)\n",
       "                  )\n",
       "                  (1): Dropout(p=0.4, inplace=False)\n",
       "                  (2): Linear(in_features=480, out_features=120, bias=True)\n",
       "                )\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (144): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): Attention(\n",
       "                (to_q): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_k): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_v): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (attend): Attend(\n",
       "                  (attn_dropout): Dropout(p=0.4, inplace=False)\n",
       "                )\n",
       "                (to_out): Linear(in_features=128, out_features=120, bias=False)\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (145): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): FeedForward(\n",
       "                (ff): Sequential(\n",
       "                  (0): GLU(\n",
       "                    (act): GELU(approximate='none')\n",
       "                    (proj): Linear(in_features=120, out_features=960, bias=True)\n",
       "                  )\n",
       "                  (1): Dropout(p=0.4, inplace=False)\n",
       "                  (2): Linear(in_features=480, out_features=120, bias=True)\n",
       "                )\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (146): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): Attention(\n",
       "                (to_q): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_k): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_v): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (attend): Attend(\n",
       "                  (attn_dropout): Dropout(p=0.4, inplace=False)\n",
       "                )\n",
       "                (to_out): Linear(in_features=128, out_features=120, bias=False)\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (147): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): FeedForward(\n",
       "                (ff): Sequential(\n",
       "                  (0): GLU(\n",
       "                    (act): GELU(approximate='none')\n",
       "                    (proj): Linear(in_features=120, out_features=960, bias=True)\n",
       "                  )\n",
       "                  (1): Dropout(p=0.4, inplace=False)\n",
       "                  (2): Linear(in_features=480, out_features=120, bias=True)\n",
       "                )\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (148): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): Attention(\n",
       "                (to_q): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_k): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_v): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (attend): Attend(\n",
       "                  (attn_dropout): Dropout(p=0.4, inplace=False)\n",
       "                )\n",
       "                (to_out): Linear(in_features=128, out_features=120, bias=False)\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (149): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): FeedForward(\n",
       "                (ff): Sequential(\n",
       "                  (0): GLU(\n",
       "                    (act): GELU(approximate='none')\n",
       "                    (proj): Linear(in_features=120, out_features=960, bias=True)\n",
       "                  )\n",
       "                  (1): Dropout(p=0.4, inplace=False)\n",
       "                  (2): Linear(in_features=480, out_features=120, bias=True)\n",
       "                )\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (150): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): Attention(\n",
       "                (to_q): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_k): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_v): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (attend): Attend(\n",
       "                  (attn_dropout): Dropout(p=0.4, inplace=False)\n",
       "                )\n",
       "                (to_out): Linear(in_features=128, out_features=120, bias=False)\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (151): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): FeedForward(\n",
       "                (ff): Sequential(\n",
       "                  (0): GLU(\n",
       "                    (act): GELU(approximate='none')\n",
       "                    (proj): Linear(in_features=120, out_features=960, bias=True)\n",
       "                  )\n",
       "                  (1): Dropout(p=0.4, inplace=False)\n",
       "                  (2): Linear(in_features=480, out_features=120, bias=True)\n",
       "                )\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (152): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): Attention(\n",
       "                (to_q): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_k): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_v): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (attend): Attend(\n",
       "                  (attn_dropout): Dropout(p=0.4, inplace=False)\n",
       "                )\n",
       "                (to_out): Linear(in_features=128, out_features=120, bias=False)\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (153): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): FeedForward(\n",
       "                (ff): Sequential(\n",
       "                  (0): GLU(\n",
       "                    (act): GELU(approximate='none')\n",
       "                    (proj): Linear(in_features=120, out_features=960, bias=True)\n",
       "                  )\n",
       "                  (1): Dropout(p=0.4, inplace=False)\n",
       "                  (2): Linear(in_features=480, out_features=120, bias=True)\n",
       "                )\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (154): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): Attention(\n",
       "                (to_q): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_k): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_v): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (attend): Attend(\n",
       "                  (attn_dropout): Dropout(p=0.4, inplace=False)\n",
       "                )\n",
       "                (to_out): Linear(in_features=128, out_features=120, bias=False)\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (155): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): FeedForward(\n",
       "                (ff): Sequential(\n",
       "                  (0): GLU(\n",
       "                    (act): GELU(approximate='none')\n",
       "                    (proj): Linear(in_features=120, out_features=960, bias=True)\n",
       "                  )\n",
       "                  (1): Dropout(p=0.4, inplace=False)\n",
       "                  (2): Linear(in_features=480, out_features=120, bias=True)\n",
       "                )\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (156): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): Attention(\n",
       "                (to_q): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_k): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_v): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (attend): Attend(\n",
       "                  (attn_dropout): Dropout(p=0.4, inplace=False)\n",
       "                )\n",
       "                (to_out): Linear(in_features=128, out_features=120, bias=False)\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (157): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): FeedForward(\n",
       "                (ff): Sequential(\n",
       "                  (0): GLU(\n",
       "                    (act): GELU(approximate='none')\n",
       "                    (proj): Linear(in_features=120, out_features=960, bias=True)\n",
       "                  )\n",
       "                  (1): Dropout(p=0.4, inplace=False)\n",
       "                  (2): Linear(in_features=480, out_features=120, bias=True)\n",
       "                )\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (158): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): Attention(\n",
       "                (to_q): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_k): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_v): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (attend): Attend(\n",
       "                  (attn_dropout): Dropout(p=0.4, inplace=False)\n",
       "                )\n",
       "                (to_out): Linear(in_features=128, out_features=120, bias=False)\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (159): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): FeedForward(\n",
       "                (ff): Sequential(\n",
       "                  (0): GLU(\n",
       "                    (act): GELU(approximate='none')\n",
       "                    (proj): Linear(in_features=120, out_features=960, bias=True)\n",
       "                  )\n",
       "                  (1): Dropout(p=0.4, inplace=False)\n",
       "                  (2): Linear(in_features=480, out_features=120, bias=True)\n",
       "                )\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (160): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): Attention(\n",
       "                (to_q): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_k): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_v): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (attend): Attend(\n",
       "                  (attn_dropout): Dropout(p=0.4, inplace=False)\n",
       "                )\n",
       "                (to_out): Linear(in_features=128, out_features=120, bias=False)\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (161): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): FeedForward(\n",
       "                (ff): Sequential(\n",
       "                  (0): GLU(\n",
       "                    (act): GELU(approximate='none')\n",
       "                    (proj): Linear(in_features=120, out_features=960, bias=True)\n",
       "                  )\n",
       "                  (1): Dropout(p=0.4, inplace=False)\n",
       "                  (2): Linear(in_features=480, out_features=120, bias=True)\n",
       "                )\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (162): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): Attention(\n",
       "                (to_q): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_k): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_v): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (attend): Attend(\n",
       "                  (attn_dropout): Dropout(p=0.4, inplace=False)\n",
       "                )\n",
       "                (to_out): Linear(in_features=128, out_features=120, bias=False)\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (163): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): FeedForward(\n",
       "                (ff): Sequential(\n",
       "                  (0): GLU(\n",
       "                    (act): GELU(approximate='none')\n",
       "                    (proj): Linear(in_features=120, out_features=960, bias=True)\n",
       "                  )\n",
       "                  (1): Dropout(p=0.4, inplace=False)\n",
       "                  (2): Linear(in_features=480, out_features=120, bias=True)\n",
       "                )\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (164): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): Attention(\n",
       "                (to_q): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_k): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_v): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (attend): Attend(\n",
       "                  (attn_dropout): Dropout(p=0.4, inplace=False)\n",
       "                )\n",
       "                (to_out): Linear(in_features=128, out_features=120, bias=False)\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (165): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): FeedForward(\n",
       "                (ff): Sequential(\n",
       "                  (0): GLU(\n",
       "                    (act): GELU(approximate='none')\n",
       "                    (proj): Linear(in_features=120, out_features=960, bias=True)\n",
       "                  )\n",
       "                  (1): Dropout(p=0.4, inplace=False)\n",
       "                  (2): Linear(in_features=480, out_features=120, bias=True)\n",
       "                )\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (166): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): Attention(\n",
       "                (to_q): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_k): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_v): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (attend): Attend(\n",
       "                  (attn_dropout): Dropout(p=0.4, inplace=False)\n",
       "                )\n",
       "                (to_out): Linear(in_features=128, out_features=120, bias=False)\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (167): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): FeedForward(\n",
       "                (ff): Sequential(\n",
       "                  (0): GLU(\n",
       "                    (act): GELU(approximate='none')\n",
       "                    (proj): Linear(in_features=120, out_features=960, bias=True)\n",
       "                  )\n",
       "                  (1): Dropout(p=0.4, inplace=False)\n",
       "                  (2): Linear(in_features=480, out_features=120, bias=True)\n",
       "                )\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (168): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): Attention(\n",
       "                (to_q): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_k): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_v): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (attend): Attend(\n",
       "                  (attn_dropout): Dropout(p=0.4, inplace=False)\n",
       "                )\n",
       "                (to_out): Linear(in_features=128, out_features=120, bias=False)\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (169): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): FeedForward(\n",
       "                (ff): Sequential(\n",
       "                  (0): GLU(\n",
       "                    (act): GELU(approximate='none')\n",
       "                    (proj): Linear(in_features=120, out_features=960, bias=True)\n",
       "                  )\n",
       "                  (1): Dropout(p=0.4, inplace=False)\n",
       "                  (2): Linear(in_features=480, out_features=120, bias=True)\n",
       "                )\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (170): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): Attention(\n",
       "                (to_q): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_k): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_v): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (attend): Attend(\n",
       "                  (attn_dropout): Dropout(p=0.4, inplace=False)\n",
       "                )\n",
       "                (to_out): Linear(in_features=128, out_features=120, bias=False)\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (171): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): FeedForward(\n",
       "                (ff): Sequential(\n",
       "                  (0): GLU(\n",
       "                    (act): GELU(approximate='none')\n",
       "                    (proj): Linear(in_features=120, out_features=960, bias=True)\n",
       "                  )\n",
       "                  (1): Dropout(p=0.4, inplace=False)\n",
       "                  (2): Linear(in_features=480, out_features=120, bias=True)\n",
       "                )\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (172): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): Attention(\n",
       "                (to_q): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_k): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_v): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (attend): Attend(\n",
       "                  (attn_dropout): Dropout(p=0.4, inplace=False)\n",
       "                )\n",
       "                (to_out): Linear(in_features=128, out_features=120, bias=False)\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (173): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): FeedForward(\n",
       "                (ff): Sequential(\n",
       "                  (0): GLU(\n",
       "                    (act): GELU(approximate='none')\n",
       "                    (proj): Linear(in_features=120, out_features=960, bias=True)\n",
       "                  )\n",
       "                  (1): Dropout(p=0.4, inplace=False)\n",
       "                  (2): Linear(in_features=480, out_features=120, bias=True)\n",
       "                )\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (174): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): Attention(\n",
       "                (to_q): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_k): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_v): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (attend): Attend(\n",
       "                  (attn_dropout): Dropout(p=0.4, inplace=False)\n",
       "                )\n",
       "                (to_out): Linear(in_features=128, out_features=120, bias=False)\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (175): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): FeedForward(\n",
       "                (ff): Sequential(\n",
       "                  (0): GLU(\n",
       "                    (act): GELU(approximate='none')\n",
       "                    (proj): Linear(in_features=120, out_features=960, bias=True)\n",
       "                  )\n",
       "                  (1): Dropout(p=0.4, inplace=False)\n",
       "                  (2): Linear(in_features=480, out_features=120, bias=True)\n",
       "                )\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (176): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): Attention(\n",
       "                (to_q): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_k): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_v): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (attend): Attend(\n",
       "                  (attn_dropout): Dropout(p=0.4, inplace=False)\n",
       "                )\n",
       "                (to_out): Linear(in_features=128, out_features=120, bias=False)\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (177): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): FeedForward(\n",
       "                (ff): Sequential(\n",
       "                  (0): GLU(\n",
       "                    (act): GELU(approximate='none')\n",
       "                    (proj): Linear(in_features=120, out_features=960, bias=True)\n",
       "                  )\n",
       "                  (1): Dropout(p=0.4, inplace=False)\n",
       "                  (2): Linear(in_features=480, out_features=120, bias=True)\n",
       "                )\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (178): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): Attention(\n",
       "                (to_q): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_k): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_v): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (attend): Attend(\n",
       "                  (attn_dropout): Dropout(p=0.4, inplace=False)\n",
       "                )\n",
       "                (to_out): Linear(in_features=128, out_features=120, bias=False)\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (179): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): FeedForward(\n",
       "                (ff): Sequential(\n",
       "                  (0): GLU(\n",
       "                    (act): GELU(approximate='none')\n",
       "                    (proj): Linear(in_features=120, out_features=960, bias=True)\n",
       "                  )\n",
       "                  (1): Dropout(p=0.4, inplace=False)\n",
       "                  (2): Linear(in_features=480, out_features=120, bias=True)\n",
       "                )\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (180): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): Attention(\n",
       "                (to_q): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_k): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_v): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (attend): Attend(\n",
       "                  (attn_dropout): Dropout(p=0.4, inplace=False)\n",
       "                )\n",
       "                (to_out): Linear(in_features=128, out_features=120, bias=False)\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (181): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): FeedForward(\n",
       "                (ff): Sequential(\n",
       "                  (0): GLU(\n",
       "                    (act): GELU(approximate='none')\n",
       "                    (proj): Linear(in_features=120, out_features=960, bias=True)\n",
       "                  )\n",
       "                  (1): Dropout(p=0.4, inplace=False)\n",
       "                  (2): Linear(in_features=480, out_features=120, bias=True)\n",
       "                )\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (182): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): Attention(\n",
       "                (to_q): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_k): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_v): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (attend): Attend(\n",
       "                  (attn_dropout): Dropout(p=0.4, inplace=False)\n",
       "                )\n",
       "                (to_out): Linear(in_features=128, out_features=120, bias=False)\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (183): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): FeedForward(\n",
       "                (ff): Sequential(\n",
       "                  (0): GLU(\n",
       "                    (act): GELU(approximate='none')\n",
       "                    (proj): Linear(in_features=120, out_features=960, bias=True)\n",
       "                  )\n",
       "                  (1): Dropout(p=0.4, inplace=False)\n",
       "                  (2): Linear(in_features=480, out_features=120, bias=True)\n",
       "                )\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (184): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): Attention(\n",
       "                (to_q): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_k): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_v): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (attend): Attend(\n",
       "                  (attn_dropout): Dropout(p=0.4, inplace=False)\n",
       "                )\n",
       "                (to_out): Linear(in_features=128, out_features=120, bias=False)\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (185): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): FeedForward(\n",
       "                (ff): Sequential(\n",
       "                  (0): GLU(\n",
       "                    (act): GELU(approximate='none')\n",
       "                    (proj): Linear(in_features=120, out_features=960, bias=True)\n",
       "                  )\n",
       "                  (1): Dropout(p=0.4, inplace=False)\n",
       "                  (2): Linear(in_features=480, out_features=120, bias=True)\n",
       "                )\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (186): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): Attention(\n",
       "                (to_q): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_k): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_v): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (attend): Attend(\n",
       "                  (attn_dropout): Dropout(p=0.4, inplace=False)\n",
       "                )\n",
       "                (to_out): Linear(in_features=128, out_features=120, bias=False)\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (187): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): FeedForward(\n",
       "                (ff): Sequential(\n",
       "                  (0): GLU(\n",
       "                    (act): GELU(approximate='none')\n",
       "                    (proj): Linear(in_features=120, out_features=960, bias=True)\n",
       "                  )\n",
       "                  (1): Dropout(p=0.4, inplace=False)\n",
       "                  (2): Linear(in_features=480, out_features=120, bias=True)\n",
       "                )\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (188): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): Attention(\n",
       "                (to_q): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_k): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_v): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (attend): Attend(\n",
       "                  (attn_dropout): Dropout(p=0.4, inplace=False)\n",
       "                )\n",
       "                (to_out): Linear(in_features=128, out_features=120, bias=False)\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (189): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): FeedForward(\n",
       "                (ff): Sequential(\n",
       "                  (0): GLU(\n",
       "                    (act): GELU(approximate='none')\n",
       "                    (proj): Linear(in_features=120, out_features=960, bias=True)\n",
       "                  )\n",
       "                  (1): Dropout(p=0.4, inplace=False)\n",
       "                  (2): Linear(in_features=480, out_features=120, bias=True)\n",
       "                )\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (190): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): Attention(\n",
       "                (to_q): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_k): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_v): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (attend): Attend(\n",
       "                  (attn_dropout): Dropout(p=0.4, inplace=False)\n",
       "                )\n",
       "                (to_out): Linear(in_features=128, out_features=120, bias=False)\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (191): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): FeedForward(\n",
       "                (ff): Sequential(\n",
       "                  (0): GLU(\n",
       "                    (act): GELU(approximate='none')\n",
       "                    (proj): Linear(in_features=120, out_features=960, bias=True)\n",
       "                  )\n",
       "                  (1): Dropout(p=0.4, inplace=False)\n",
       "                  (2): Linear(in_features=480, out_features=120, bias=True)\n",
       "                )\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (192): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): Attention(\n",
       "                (to_q): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_k): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_v): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (attend): Attend(\n",
       "                  (attn_dropout): Dropout(p=0.4, inplace=False)\n",
       "                )\n",
       "                (to_out): Linear(in_features=128, out_features=120, bias=False)\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (193): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): FeedForward(\n",
       "                (ff): Sequential(\n",
       "                  (0): GLU(\n",
       "                    (act): GELU(approximate='none')\n",
       "                    (proj): Linear(in_features=120, out_features=960, bias=True)\n",
       "                  )\n",
       "                  (1): Dropout(p=0.4, inplace=False)\n",
       "                  (2): Linear(in_features=480, out_features=120, bias=True)\n",
       "                )\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (194): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): Attention(\n",
       "                (to_q): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_k): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_v): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (attend): Attend(\n",
       "                  (attn_dropout): Dropout(p=0.4, inplace=False)\n",
       "                )\n",
       "                (to_out): Linear(in_features=128, out_features=120, bias=False)\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (195): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): FeedForward(\n",
       "                (ff): Sequential(\n",
       "                  (0): GLU(\n",
       "                    (act): GELU(approximate='none')\n",
       "                    (proj): Linear(in_features=120, out_features=960, bias=True)\n",
       "                  )\n",
       "                  (1): Dropout(p=0.4, inplace=False)\n",
       "                  (2): Linear(in_features=480, out_features=120, bias=True)\n",
       "                )\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (196): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): Attention(\n",
       "                (to_q): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_k): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_v): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (attend): Attend(\n",
       "                  (attn_dropout): Dropout(p=0.4, inplace=False)\n",
       "                )\n",
       "                (to_out): Linear(in_features=128, out_features=120, bias=False)\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (197): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): FeedForward(\n",
       "                (ff): Sequential(\n",
       "                  (0): GLU(\n",
       "                    (act): GELU(approximate='none')\n",
       "                    (proj): Linear(in_features=120, out_features=960, bias=True)\n",
       "                  )\n",
       "                  (1): Dropout(p=0.4, inplace=False)\n",
       "                  (2): Linear(in_features=480, out_features=120, bias=True)\n",
       "                )\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (198): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): Attention(\n",
       "                (to_q): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_k): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_v): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (attend): Attend(\n",
       "                  (attn_dropout): Dropout(p=0.4, inplace=False)\n",
       "                )\n",
       "                (to_out): Linear(in_features=128, out_features=120, bias=False)\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (199): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): FeedForward(\n",
       "                (ff): Sequential(\n",
       "                  (0): GLU(\n",
       "                    (act): GELU(approximate='none')\n",
       "                    (proj): Linear(in_features=120, out_features=960, bias=True)\n",
       "                  )\n",
       "                  (1): Dropout(p=0.4, inplace=False)\n",
       "                  (2): Linear(in_features=480, out_features=120, bias=True)\n",
       "                )\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (200): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): Attention(\n",
       "                (to_q): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_k): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_v): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (attend): Attend(\n",
       "                  (attn_dropout): Dropout(p=0.4, inplace=False)\n",
       "                )\n",
       "                (to_out): Linear(in_features=128, out_features=120, bias=False)\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (201): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): FeedForward(\n",
       "                (ff): Sequential(\n",
       "                  (0): GLU(\n",
       "                    (act): GELU(approximate='none')\n",
       "                    (proj): Linear(in_features=120, out_features=960, bias=True)\n",
       "                  )\n",
       "                  (1): Dropout(p=0.4, inplace=False)\n",
       "                  (2): Linear(in_features=480, out_features=120, bias=True)\n",
       "                )\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (202): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): Attention(\n",
       "                (to_q): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_k): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_v): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (attend): Attend(\n",
       "                  (attn_dropout): Dropout(p=0.4, inplace=False)\n",
       "                )\n",
       "                (to_out): Linear(in_features=128, out_features=120, bias=False)\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (203): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): FeedForward(\n",
       "                (ff): Sequential(\n",
       "                  (0): GLU(\n",
       "                    (act): GELU(approximate='none')\n",
       "                    (proj): Linear(in_features=120, out_features=960, bias=True)\n",
       "                  )\n",
       "                  (1): Dropout(p=0.4, inplace=False)\n",
       "                  (2): Linear(in_features=480, out_features=120, bias=True)\n",
       "                )\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (204): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): Attention(\n",
       "                (to_q): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_k): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_v): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (attend): Attend(\n",
       "                  (attn_dropout): Dropout(p=0.4, inplace=False)\n",
       "                )\n",
       "                (to_out): Linear(in_features=128, out_features=120, bias=False)\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (205): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): FeedForward(\n",
       "                (ff): Sequential(\n",
       "                  (0): GLU(\n",
       "                    (act): GELU(approximate='none')\n",
       "                    (proj): Linear(in_features=120, out_features=960, bias=True)\n",
       "                  )\n",
       "                  (1): Dropout(p=0.4, inplace=False)\n",
       "                  (2): Linear(in_features=480, out_features=120, bias=True)\n",
       "                )\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (206): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): Attention(\n",
       "                (to_q): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_k): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_v): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (attend): Attend(\n",
       "                  (attn_dropout): Dropout(p=0.4, inplace=False)\n",
       "                )\n",
       "                (to_out): Linear(in_features=128, out_features=120, bias=False)\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (207): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): FeedForward(\n",
       "                (ff): Sequential(\n",
       "                  (0): GLU(\n",
       "                    (act): GELU(approximate='none')\n",
       "                    (proj): Linear(in_features=120, out_features=960, bias=True)\n",
       "                  )\n",
       "                  (1): Dropout(p=0.4, inplace=False)\n",
       "                  (2): Linear(in_features=480, out_features=120, bias=True)\n",
       "                )\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (208): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): Attention(\n",
       "                (to_q): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_k): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_v): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (attend): Attend(\n",
       "                  (attn_dropout): Dropout(p=0.4, inplace=False)\n",
       "                )\n",
       "                (to_out): Linear(in_features=128, out_features=120, bias=False)\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (209): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): FeedForward(\n",
       "                (ff): Sequential(\n",
       "                  (0): GLU(\n",
       "                    (act): GELU(approximate='none')\n",
       "                    (proj): Linear(in_features=120, out_features=960, bias=True)\n",
       "                  )\n",
       "                  (1): Dropout(p=0.4, inplace=False)\n",
       "                  (2): Linear(in_features=480, out_features=120, bias=True)\n",
       "                )\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (210): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): Attention(\n",
       "                (to_q): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_k): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_v): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (attend): Attend(\n",
       "                  (attn_dropout): Dropout(p=0.4, inplace=False)\n",
       "                )\n",
       "                (to_out): Linear(in_features=128, out_features=120, bias=False)\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (211): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): FeedForward(\n",
       "                (ff): Sequential(\n",
       "                  (0): GLU(\n",
       "                    (act): GELU(approximate='none')\n",
       "                    (proj): Linear(in_features=120, out_features=960, bias=True)\n",
       "                  )\n",
       "                  (1): Dropout(p=0.4, inplace=False)\n",
       "                  (2): Linear(in_features=480, out_features=120, bias=True)\n",
       "                )\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (212): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): Attention(\n",
       "                (to_q): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_k): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_v): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (attend): Attend(\n",
       "                  (attn_dropout): Dropout(p=0.4, inplace=False)\n",
       "                )\n",
       "                (to_out): Linear(in_features=128, out_features=120, bias=False)\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (213): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): FeedForward(\n",
       "                (ff): Sequential(\n",
       "                  (0): GLU(\n",
       "                    (act): GELU(approximate='none')\n",
       "                    (proj): Linear(in_features=120, out_features=960, bias=True)\n",
       "                  )\n",
       "                  (1): Dropout(p=0.4, inplace=False)\n",
       "                  (2): Linear(in_features=480, out_features=120, bias=True)\n",
       "                )\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (214): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): Attention(\n",
       "                (to_q): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_k): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_v): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (attend): Attend(\n",
       "                  (attn_dropout): Dropout(p=0.4, inplace=False)\n",
       "                )\n",
       "                (to_out): Linear(in_features=128, out_features=120, bias=False)\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (215): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): FeedForward(\n",
       "                (ff): Sequential(\n",
       "                  (0): GLU(\n",
       "                    (act): GELU(approximate='none')\n",
       "                    (proj): Linear(in_features=120, out_features=960, bias=True)\n",
       "                  )\n",
       "                  (1): Dropout(p=0.4, inplace=False)\n",
       "                  (2): Linear(in_features=480, out_features=120, bias=True)\n",
       "                )\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (216): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): Attention(\n",
       "                (to_q): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_k): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_v): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (attend): Attend(\n",
       "                  (attn_dropout): Dropout(p=0.4, inplace=False)\n",
       "                )\n",
       "                (to_out): Linear(in_features=128, out_features=120, bias=False)\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (217): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): FeedForward(\n",
       "                (ff): Sequential(\n",
       "                  (0): GLU(\n",
       "                    (act): GELU(approximate='none')\n",
       "                    (proj): Linear(in_features=120, out_features=960, bias=True)\n",
       "                  )\n",
       "                  (1): Dropout(p=0.4, inplace=False)\n",
       "                  (2): Linear(in_features=480, out_features=120, bias=True)\n",
       "                )\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (218): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): Attention(\n",
       "                (to_q): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_k): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_v): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (attend): Attend(\n",
       "                  (attn_dropout): Dropout(p=0.4, inplace=False)\n",
       "                )\n",
       "                (to_out): Linear(in_features=128, out_features=120, bias=False)\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (219): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): FeedForward(\n",
       "                (ff): Sequential(\n",
       "                  (0): GLU(\n",
       "                    (act): GELU(approximate='none')\n",
       "                    (proj): Linear(in_features=120, out_features=960, bias=True)\n",
       "                  )\n",
       "                  (1): Dropout(p=0.4, inplace=False)\n",
       "                  (2): Linear(in_features=480, out_features=120, bias=True)\n",
       "                )\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (220): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): Attention(\n",
       "                (to_q): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_k): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_v): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (attend): Attend(\n",
       "                  (attn_dropout): Dropout(p=0.4, inplace=False)\n",
       "                )\n",
       "                (to_out): Linear(in_features=128, out_features=120, bias=False)\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (221): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): FeedForward(\n",
       "                (ff): Sequential(\n",
       "                  (0): GLU(\n",
       "                    (act): GELU(approximate='none')\n",
       "                    (proj): Linear(in_features=120, out_features=960, bias=True)\n",
       "                  )\n",
       "                  (1): Dropout(p=0.4, inplace=False)\n",
       "                  (2): Linear(in_features=480, out_features=120, bias=True)\n",
       "                )\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (222): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): Attention(\n",
       "                (to_q): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_k): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_v): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (attend): Attend(\n",
       "                  (attn_dropout): Dropout(p=0.4, inplace=False)\n",
       "                )\n",
       "                (to_out): Linear(in_features=128, out_features=120, bias=False)\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (223): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): FeedForward(\n",
       "                (ff): Sequential(\n",
       "                  (0): GLU(\n",
       "                    (act): GELU(approximate='none')\n",
       "                    (proj): Linear(in_features=120, out_features=960, bias=True)\n",
       "                  )\n",
       "                  (1): Dropout(p=0.4, inplace=False)\n",
       "                  (2): Linear(in_features=480, out_features=120, bias=True)\n",
       "                )\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (224): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): Attention(\n",
       "                (to_q): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_k): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_v): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (attend): Attend(\n",
       "                  (attn_dropout): Dropout(p=0.4, inplace=False)\n",
       "                )\n",
       "                (to_out): Linear(in_features=128, out_features=120, bias=False)\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (225): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): FeedForward(\n",
       "                (ff): Sequential(\n",
       "                  (0): GLU(\n",
       "                    (act): GELU(approximate='none')\n",
       "                    (proj): Linear(in_features=120, out_features=960, bias=True)\n",
       "                  )\n",
       "                  (1): Dropout(p=0.4, inplace=False)\n",
       "                  (2): Linear(in_features=480, out_features=120, bias=True)\n",
       "                )\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (226): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): Attention(\n",
       "                (to_q): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_k): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_v): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (attend): Attend(\n",
       "                  (attn_dropout): Dropout(p=0.4, inplace=False)\n",
       "                )\n",
       "                (to_out): Linear(in_features=128, out_features=120, bias=False)\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (227): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): FeedForward(\n",
       "                (ff): Sequential(\n",
       "                  (0): GLU(\n",
       "                    (act): GELU(approximate='none')\n",
       "                    (proj): Linear(in_features=120, out_features=960, bias=True)\n",
       "                  )\n",
       "                  (1): Dropout(p=0.4, inplace=False)\n",
       "                  (2): Linear(in_features=480, out_features=120, bias=True)\n",
       "                )\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (228): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): Attention(\n",
       "                (to_q): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_k): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_v): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (attend): Attend(\n",
       "                  (attn_dropout): Dropout(p=0.4, inplace=False)\n",
       "                )\n",
       "                (to_out): Linear(in_features=128, out_features=120, bias=False)\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (229): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): FeedForward(\n",
       "                (ff): Sequential(\n",
       "                  (0): GLU(\n",
       "                    (act): GELU(approximate='none')\n",
       "                    (proj): Linear(in_features=120, out_features=960, bias=True)\n",
       "                  )\n",
       "                  (1): Dropout(p=0.4, inplace=False)\n",
       "                  (2): Linear(in_features=480, out_features=120, bias=True)\n",
       "                )\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (230): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): Attention(\n",
       "                (to_q): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_k): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_v): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (attend): Attend(\n",
       "                  (attn_dropout): Dropout(p=0.4, inplace=False)\n",
       "                )\n",
       "                (to_out): Linear(in_features=128, out_features=120, bias=False)\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (231): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): FeedForward(\n",
       "                (ff): Sequential(\n",
       "                  (0): GLU(\n",
       "                    (act): GELU(approximate='none')\n",
       "                    (proj): Linear(in_features=120, out_features=960, bias=True)\n",
       "                  )\n",
       "                  (1): Dropout(p=0.4, inplace=False)\n",
       "                  (2): Linear(in_features=480, out_features=120, bias=True)\n",
       "                )\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (232): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): Attention(\n",
       "                (to_q): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_k): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_v): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (attend): Attend(\n",
       "                  (attn_dropout): Dropout(p=0.4, inplace=False)\n",
       "                )\n",
       "                (to_out): Linear(in_features=128, out_features=120, bias=False)\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (233): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): FeedForward(\n",
       "                (ff): Sequential(\n",
       "                  (0): GLU(\n",
       "                    (act): GELU(approximate='none')\n",
       "                    (proj): Linear(in_features=120, out_features=960, bias=True)\n",
       "                  )\n",
       "                  (1): Dropout(p=0.4, inplace=False)\n",
       "                  (2): Linear(in_features=480, out_features=120, bias=True)\n",
       "                )\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (234): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): Attention(\n",
       "                (to_q): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_k): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_v): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (attend): Attend(\n",
       "                  (attn_dropout): Dropout(p=0.4, inplace=False)\n",
       "                )\n",
       "                (to_out): Linear(in_features=128, out_features=120, bias=False)\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (235): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): FeedForward(\n",
       "                (ff): Sequential(\n",
       "                  (0): GLU(\n",
       "                    (act): GELU(approximate='none')\n",
       "                    (proj): Linear(in_features=120, out_features=960, bias=True)\n",
       "                  )\n",
       "                  (1): Dropout(p=0.4, inplace=False)\n",
       "                  (2): Linear(in_features=480, out_features=120, bias=True)\n",
       "                )\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (236): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): Attention(\n",
       "                (to_q): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_k): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_v): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (attend): Attend(\n",
       "                  (attn_dropout): Dropout(p=0.4, inplace=False)\n",
       "                )\n",
       "                (to_out): Linear(in_features=128, out_features=120, bias=False)\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (237): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): FeedForward(\n",
       "                (ff): Sequential(\n",
       "                  (0): GLU(\n",
       "                    (act): GELU(approximate='none')\n",
       "                    (proj): Linear(in_features=120, out_features=960, bias=True)\n",
       "                  )\n",
       "                  (1): Dropout(p=0.4, inplace=False)\n",
       "                  (2): Linear(in_features=480, out_features=120, bias=True)\n",
       "                )\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (238): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): Attention(\n",
       "                (to_q): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_k): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_v): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (attend): Attend(\n",
       "                  (attn_dropout): Dropout(p=0.4, inplace=False)\n",
       "                )\n",
       "                (to_out): Linear(in_features=128, out_features=120, bias=False)\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (239): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): FeedForward(\n",
       "                (ff): Sequential(\n",
       "                  (0): GLU(\n",
       "                    (act): GELU(approximate='none')\n",
       "                    (proj): Linear(in_features=120, out_features=960, bias=True)\n",
       "                  )\n",
       "                  (1): Dropout(p=0.4, inplace=False)\n",
       "                  (2): Linear(in_features=480, out_features=120, bias=True)\n",
       "                )\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (240): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): Attention(\n",
       "                (to_q): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_k): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_v): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (attend): Attend(\n",
       "                  (attn_dropout): Dropout(p=0.4, inplace=False)\n",
       "                )\n",
       "                (to_out): Linear(in_features=128, out_features=120, bias=False)\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (241): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): FeedForward(\n",
       "                (ff): Sequential(\n",
       "                  (0): GLU(\n",
       "                    (act): GELU(approximate='none')\n",
       "                    (proj): Linear(in_features=120, out_features=960, bias=True)\n",
       "                  )\n",
       "                  (1): Dropout(p=0.4, inplace=False)\n",
       "                  (2): Linear(in_features=480, out_features=120, bias=True)\n",
       "                )\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (242): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): Attention(\n",
       "                (to_q): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_k): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_v): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (attend): Attend(\n",
       "                  (attn_dropout): Dropout(p=0.4, inplace=False)\n",
       "                )\n",
       "                (to_out): Linear(in_features=128, out_features=120, bias=False)\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (243): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): FeedForward(\n",
       "                (ff): Sequential(\n",
       "                  (0): GLU(\n",
       "                    (act): GELU(approximate='none')\n",
       "                    (proj): Linear(in_features=120, out_features=960, bias=True)\n",
       "                  )\n",
       "                  (1): Dropout(p=0.4, inplace=False)\n",
       "                  (2): Linear(in_features=480, out_features=120, bias=True)\n",
       "                )\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (244): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): Attention(\n",
       "                (to_q): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_k): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_v): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (attend): Attend(\n",
       "                  (attn_dropout): Dropout(p=0.4, inplace=False)\n",
       "                )\n",
       "                (to_out): Linear(in_features=128, out_features=120, bias=False)\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (245): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): FeedForward(\n",
       "                (ff): Sequential(\n",
       "                  (0): GLU(\n",
       "                    (act): GELU(approximate='none')\n",
       "                    (proj): Linear(in_features=120, out_features=960, bias=True)\n",
       "                  )\n",
       "                  (1): Dropout(p=0.4, inplace=False)\n",
       "                  (2): Linear(in_features=480, out_features=120, bias=True)\n",
       "                )\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (246): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): Attention(\n",
       "                (to_q): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_k): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_v): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (attend): Attend(\n",
       "                  (attn_dropout): Dropout(p=0.4, inplace=False)\n",
       "                )\n",
       "                (to_out): Linear(in_features=128, out_features=120, bias=False)\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (247): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): FeedForward(\n",
       "                (ff): Sequential(\n",
       "                  (0): GLU(\n",
       "                    (act): GELU(approximate='none')\n",
       "                    (proj): Linear(in_features=120, out_features=960, bias=True)\n",
       "                  )\n",
       "                  (1): Dropout(p=0.4, inplace=False)\n",
       "                  (2): Linear(in_features=480, out_features=120, bias=True)\n",
       "                )\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (248): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): Attention(\n",
       "                (to_q): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_k): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_v): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (attend): Attend(\n",
       "                  (attn_dropout): Dropout(p=0.4, inplace=False)\n",
       "                )\n",
       "                (to_out): Linear(in_features=128, out_features=120, bias=False)\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (249): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): FeedForward(\n",
       "                (ff): Sequential(\n",
       "                  (0): GLU(\n",
       "                    (act): GELU(approximate='none')\n",
       "                    (proj): Linear(in_features=120, out_features=960, bias=True)\n",
       "                  )\n",
       "                  (1): Dropout(p=0.4, inplace=False)\n",
       "                  (2): Linear(in_features=480, out_features=120, bias=True)\n",
       "                )\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (250): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): Attention(\n",
       "                (to_q): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_k): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_v): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (attend): Attend(\n",
       "                  (attn_dropout): Dropout(p=0.4, inplace=False)\n",
       "                )\n",
       "                (to_out): Linear(in_features=128, out_features=120, bias=False)\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (251): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): FeedForward(\n",
       "                (ff): Sequential(\n",
       "                  (0): GLU(\n",
       "                    (act): GELU(approximate='none')\n",
       "                    (proj): Linear(in_features=120, out_features=960, bias=True)\n",
       "                  )\n",
       "                  (1): Dropout(p=0.4, inplace=False)\n",
       "                  (2): Linear(in_features=480, out_features=120, bias=True)\n",
       "                )\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (252): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): Attention(\n",
       "                (to_q): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_k): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_v): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (attend): Attend(\n",
       "                  (attn_dropout): Dropout(p=0.4, inplace=False)\n",
       "                )\n",
       "                (to_out): Linear(in_features=128, out_features=120, bias=False)\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (253): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): FeedForward(\n",
       "                (ff): Sequential(\n",
       "                  (0): GLU(\n",
       "                    (act): GELU(approximate='none')\n",
       "                    (proj): Linear(in_features=120, out_features=960, bias=True)\n",
       "                  )\n",
       "                  (1): Dropout(p=0.4, inplace=False)\n",
       "                  (2): Linear(in_features=480, out_features=120, bias=True)\n",
       "                )\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (254): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): Attention(\n",
       "                (to_q): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_k): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_v): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (attend): Attend(\n",
       "                  (attn_dropout): Dropout(p=0.4, inplace=False)\n",
       "                )\n",
       "                (to_out): Linear(in_features=128, out_features=120, bias=False)\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (255): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): FeedForward(\n",
       "                (ff): Sequential(\n",
       "                  (0): GLU(\n",
       "                    (act): GELU(approximate='none')\n",
       "                    (proj): Linear(in_features=120, out_features=960, bias=True)\n",
       "                  )\n",
       "                  (1): Dropout(p=0.4, inplace=False)\n",
       "                  (2): Linear(in_features=480, out_features=120, bias=True)\n",
       "                )\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (256): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): Attention(\n",
       "                (to_q): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_k): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_v): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (attend): Attend(\n",
       "                  (attn_dropout): Dropout(p=0.4, inplace=False)\n",
       "                )\n",
       "                (to_out): Linear(in_features=128, out_features=120, bias=False)\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (257): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): FeedForward(\n",
       "                (ff): Sequential(\n",
       "                  (0): GLU(\n",
       "                    (act): GELU(approximate='none')\n",
       "                    (proj): Linear(in_features=120, out_features=960, bias=True)\n",
       "                  )\n",
       "                  (1): Dropout(p=0.4, inplace=False)\n",
       "                  (2): Linear(in_features=480, out_features=120, bias=True)\n",
       "                )\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (258): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): Attention(\n",
       "                (to_q): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_k): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_v): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (attend): Attend(\n",
       "                  (attn_dropout): Dropout(p=0.4, inplace=False)\n",
       "                )\n",
       "                (to_out): Linear(in_features=128, out_features=120, bias=False)\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (259): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): FeedForward(\n",
       "                (ff): Sequential(\n",
       "                  (0): GLU(\n",
       "                    (act): GELU(approximate='none')\n",
       "                    (proj): Linear(in_features=120, out_features=960, bias=True)\n",
       "                  )\n",
       "                  (1): Dropout(p=0.4, inplace=False)\n",
       "                  (2): Linear(in_features=480, out_features=120, bias=True)\n",
       "                )\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (260): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): Attention(\n",
       "                (to_q): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_k): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_v): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (attend): Attend(\n",
       "                  (attn_dropout): Dropout(p=0.4, inplace=False)\n",
       "                )\n",
       "                (to_out): Linear(in_features=128, out_features=120, bias=False)\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (261): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): FeedForward(\n",
       "                (ff): Sequential(\n",
       "                  (0): GLU(\n",
       "                    (act): GELU(approximate='none')\n",
       "                    (proj): Linear(in_features=120, out_features=960, bias=True)\n",
       "                  )\n",
       "                  (1): Dropout(p=0.4, inplace=False)\n",
       "                  (2): Linear(in_features=480, out_features=120, bias=True)\n",
       "                )\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (262): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): Attention(\n",
       "                (to_q): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_k): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_v): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (attend): Attend(\n",
       "                  (attn_dropout): Dropout(p=0.4, inplace=False)\n",
       "                )\n",
       "                (to_out): Linear(in_features=128, out_features=120, bias=False)\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (263): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): FeedForward(\n",
       "                (ff): Sequential(\n",
       "                  (0): GLU(\n",
       "                    (act): GELU(approximate='none')\n",
       "                    (proj): Linear(in_features=120, out_features=960, bias=True)\n",
       "                  )\n",
       "                  (1): Dropout(p=0.4, inplace=False)\n",
       "                  (2): Linear(in_features=480, out_features=120, bias=True)\n",
       "                )\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (264): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): Attention(\n",
       "                (to_q): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_k): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_v): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (attend): Attend(\n",
       "                  (attn_dropout): Dropout(p=0.4, inplace=False)\n",
       "                )\n",
       "                (to_out): Linear(in_features=128, out_features=120, bias=False)\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (265): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): FeedForward(\n",
       "                (ff): Sequential(\n",
       "                  (0): GLU(\n",
       "                    (act): GELU(approximate='none')\n",
       "                    (proj): Linear(in_features=120, out_features=960, bias=True)\n",
       "                  )\n",
       "                  (1): Dropout(p=0.4, inplace=False)\n",
       "                  (2): Linear(in_features=480, out_features=120, bias=True)\n",
       "                )\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (266): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): Attention(\n",
       "                (to_q): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_k): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_v): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (attend): Attend(\n",
       "                  (attn_dropout): Dropout(p=0.4, inplace=False)\n",
       "                )\n",
       "                (to_out): Linear(in_features=128, out_features=120, bias=False)\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (267): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): FeedForward(\n",
       "                (ff): Sequential(\n",
       "                  (0): GLU(\n",
       "                    (act): GELU(approximate='none')\n",
       "                    (proj): Linear(in_features=120, out_features=960, bias=True)\n",
       "                  )\n",
       "                  (1): Dropout(p=0.4, inplace=False)\n",
       "                  (2): Linear(in_features=480, out_features=120, bias=True)\n",
       "                )\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (268): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): Attention(\n",
       "                (to_q): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_k): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_v): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (attend): Attend(\n",
       "                  (attn_dropout): Dropout(p=0.4, inplace=False)\n",
       "                )\n",
       "                (to_out): Linear(in_features=128, out_features=120, bias=False)\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (269): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): FeedForward(\n",
       "                (ff): Sequential(\n",
       "                  (0): GLU(\n",
       "                    (act): GELU(approximate='none')\n",
       "                    (proj): Linear(in_features=120, out_features=960, bias=True)\n",
       "                  )\n",
       "                  (1): Dropout(p=0.4, inplace=False)\n",
       "                  (2): Linear(in_features=480, out_features=120, bias=True)\n",
       "                )\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (270): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): Attention(\n",
       "                (to_q): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_k): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_v): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (attend): Attend(\n",
       "                  (attn_dropout): Dropout(p=0.4, inplace=False)\n",
       "                )\n",
       "                (to_out): Linear(in_features=128, out_features=120, bias=False)\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (271): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): FeedForward(\n",
       "                (ff): Sequential(\n",
       "                  (0): GLU(\n",
       "                    (act): GELU(approximate='none')\n",
       "                    (proj): Linear(in_features=120, out_features=960, bias=True)\n",
       "                  )\n",
       "                  (1): Dropout(p=0.4, inplace=False)\n",
       "                  (2): Linear(in_features=480, out_features=120, bias=True)\n",
       "                )\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (272): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): Attention(\n",
       "                (to_q): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_k): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_v): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (attend): Attend(\n",
       "                  (attn_dropout): Dropout(p=0.4, inplace=False)\n",
       "                )\n",
       "                (to_out): Linear(in_features=128, out_features=120, bias=False)\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (273): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): FeedForward(\n",
       "                (ff): Sequential(\n",
       "                  (0): GLU(\n",
       "                    (act): GELU(approximate='none')\n",
       "                    (proj): Linear(in_features=120, out_features=960, bias=True)\n",
       "                  )\n",
       "                  (1): Dropout(p=0.4, inplace=False)\n",
       "                  (2): Linear(in_features=480, out_features=120, bias=True)\n",
       "                )\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (274): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): Attention(\n",
       "                (to_q): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_k): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_v): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (attend): Attend(\n",
       "                  (attn_dropout): Dropout(p=0.4, inplace=False)\n",
       "                )\n",
       "                (to_out): Linear(in_features=128, out_features=120, bias=False)\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (275): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): FeedForward(\n",
       "                (ff): Sequential(\n",
       "                  (0): GLU(\n",
       "                    (act): GELU(approximate='none')\n",
       "                    (proj): Linear(in_features=120, out_features=960, bias=True)\n",
       "                  )\n",
       "                  (1): Dropout(p=0.4, inplace=False)\n",
       "                  (2): Linear(in_features=480, out_features=120, bias=True)\n",
       "                )\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (276): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): Attention(\n",
       "                (to_q): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_k): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_v): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (attend): Attend(\n",
       "                  (attn_dropout): Dropout(p=0.4, inplace=False)\n",
       "                )\n",
       "                (to_out): Linear(in_features=128, out_features=120, bias=False)\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (277): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): FeedForward(\n",
       "                (ff): Sequential(\n",
       "                  (0): GLU(\n",
       "                    (act): GELU(approximate='none')\n",
       "                    (proj): Linear(in_features=120, out_features=960, bias=True)\n",
       "                  )\n",
       "                  (1): Dropout(p=0.4, inplace=False)\n",
       "                  (2): Linear(in_features=480, out_features=120, bias=True)\n",
       "                )\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (278): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): Attention(\n",
       "                (to_q): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_k): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_v): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (attend): Attend(\n",
       "                  (attn_dropout): Dropout(p=0.4, inplace=False)\n",
       "                )\n",
       "                (to_out): Linear(in_features=128, out_features=120, bias=False)\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (279): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): FeedForward(\n",
       "                (ff): Sequential(\n",
       "                  (0): GLU(\n",
       "                    (act): GELU(approximate='none')\n",
       "                    (proj): Linear(in_features=120, out_features=960, bias=True)\n",
       "                  )\n",
       "                  (1): Dropout(p=0.4, inplace=False)\n",
       "                  (2): Linear(in_features=480, out_features=120, bias=True)\n",
       "                )\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (280): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): Attention(\n",
       "                (to_q): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_k): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_v): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (attend): Attend(\n",
       "                  (attn_dropout): Dropout(p=0.4, inplace=False)\n",
       "                )\n",
       "                (to_out): Linear(in_features=128, out_features=120, bias=False)\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (281): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): FeedForward(\n",
       "                (ff): Sequential(\n",
       "                  (0): GLU(\n",
       "                    (act): GELU(approximate='none')\n",
       "                    (proj): Linear(in_features=120, out_features=960, bias=True)\n",
       "                  )\n",
       "                  (1): Dropout(p=0.4, inplace=False)\n",
       "                  (2): Linear(in_features=480, out_features=120, bias=True)\n",
       "                )\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (282): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): Attention(\n",
       "                (to_q): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_k): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_v): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (attend): Attend(\n",
       "                  (attn_dropout): Dropout(p=0.4, inplace=False)\n",
       "                )\n",
       "                (to_out): Linear(in_features=128, out_features=120, bias=False)\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (283): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): FeedForward(\n",
       "                (ff): Sequential(\n",
       "                  (0): GLU(\n",
       "                    (act): GELU(approximate='none')\n",
       "                    (proj): Linear(in_features=120, out_features=960, bias=True)\n",
       "                  )\n",
       "                  (1): Dropout(p=0.4, inplace=False)\n",
       "                  (2): Linear(in_features=480, out_features=120, bias=True)\n",
       "                )\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (284): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): Attention(\n",
       "                (to_q): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_k): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_v): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (attend): Attend(\n",
       "                  (attn_dropout): Dropout(p=0.4, inplace=False)\n",
       "                )\n",
       "                (to_out): Linear(in_features=128, out_features=120, bias=False)\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (285): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): FeedForward(\n",
       "                (ff): Sequential(\n",
       "                  (0): GLU(\n",
       "                    (act): GELU(approximate='none')\n",
       "                    (proj): Linear(in_features=120, out_features=960, bias=True)\n",
       "                  )\n",
       "                  (1): Dropout(p=0.4, inplace=False)\n",
       "                  (2): Linear(in_features=480, out_features=120, bias=True)\n",
       "                )\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (286): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): Attention(\n",
       "                (to_q): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_k): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_v): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (attend): Attend(\n",
       "                  (attn_dropout): Dropout(p=0.4, inplace=False)\n",
       "                )\n",
       "                (to_out): Linear(in_features=128, out_features=120, bias=False)\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (287): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): FeedForward(\n",
       "                (ff): Sequential(\n",
       "                  (0): GLU(\n",
       "                    (act): GELU(approximate='none')\n",
       "                    (proj): Linear(in_features=120, out_features=960, bias=True)\n",
       "                  )\n",
       "                  (1): Dropout(p=0.4, inplace=False)\n",
       "                  (2): Linear(in_features=480, out_features=120, bias=True)\n",
       "                )\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (288): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): Attention(\n",
       "                (to_q): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_k): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_v): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (attend): Attend(\n",
       "                  (attn_dropout): Dropout(p=0.4, inplace=False)\n",
       "                )\n",
       "                (to_out): Linear(in_features=128, out_features=120, bias=False)\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (289): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): FeedForward(\n",
       "                (ff): Sequential(\n",
       "                  (0): GLU(\n",
       "                    (act): GELU(approximate='none')\n",
       "                    (proj): Linear(in_features=120, out_features=960, bias=True)\n",
       "                  )\n",
       "                  (1): Dropout(p=0.4, inplace=False)\n",
       "                  (2): Linear(in_features=480, out_features=120, bias=True)\n",
       "                )\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (290): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): Attention(\n",
       "                (to_q): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_k): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_v): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (attend): Attend(\n",
       "                  (attn_dropout): Dropout(p=0.4, inplace=False)\n",
       "                )\n",
       "                (to_out): Linear(in_features=128, out_features=120, bias=False)\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (291): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): FeedForward(\n",
       "                (ff): Sequential(\n",
       "                  (0): GLU(\n",
       "                    (act): GELU(approximate='none')\n",
       "                    (proj): Linear(in_features=120, out_features=960, bias=True)\n",
       "                  )\n",
       "                  (1): Dropout(p=0.4, inplace=False)\n",
       "                  (2): Linear(in_features=480, out_features=120, bias=True)\n",
       "                )\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (292): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): Attention(\n",
       "                (to_q): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_k): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_v): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (attend): Attend(\n",
       "                  (attn_dropout): Dropout(p=0.4, inplace=False)\n",
       "                )\n",
       "                (to_out): Linear(in_features=128, out_features=120, bias=False)\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (293): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): FeedForward(\n",
       "                (ff): Sequential(\n",
       "                  (0): GLU(\n",
       "                    (act): GELU(approximate='none')\n",
       "                    (proj): Linear(in_features=120, out_features=960, bias=True)\n",
       "                  )\n",
       "                  (1): Dropout(p=0.4, inplace=False)\n",
       "                  (2): Linear(in_features=480, out_features=120, bias=True)\n",
       "                )\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (294): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): Attention(\n",
       "                (to_q): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_k): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_v): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (attend): Attend(\n",
       "                  (attn_dropout): Dropout(p=0.4, inplace=False)\n",
       "                )\n",
       "                (to_out): Linear(in_features=128, out_features=120, bias=False)\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (295): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): FeedForward(\n",
       "                (ff): Sequential(\n",
       "                  (0): GLU(\n",
       "                    (act): GELU(approximate='none')\n",
       "                    (proj): Linear(in_features=120, out_features=960, bias=True)\n",
       "                  )\n",
       "                  (1): Dropout(p=0.4, inplace=False)\n",
       "                  (2): Linear(in_features=480, out_features=120, bias=True)\n",
       "                )\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (296): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): Attention(\n",
       "                (to_q): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_k): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_v): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (attend): Attend(\n",
       "                  (attn_dropout): Dropout(p=0.4, inplace=False)\n",
       "                )\n",
       "                (to_out): Linear(in_features=128, out_features=120, bias=False)\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (297): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): FeedForward(\n",
       "                (ff): Sequential(\n",
       "                  (0): GLU(\n",
       "                    (act): GELU(approximate='none')\n",
       "                    (proj): Linear(in_features=120, out_features=960, bias=True)\n",
       "                  )\n",
       "                  (1): Dropout(p=0.4, inplace=False)\n",
       "                  (2): Linear(in_features=480, out_features=120, bias=True)\n",
       "                )\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (298): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): Attention(\n",
       "                (to_q): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_k): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_v): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (attend): Attend(\n",
       "                  (attn_dropout): Dropout(p=0.4, inplace=False)\n",
       "                )\n",
       "                (to_out): Linear(in_features=128, out_features=120, bias=False)\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (299): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): FeedForward(\n",
       "                (ff): Sequential(\n",
       "                  (0): GLU(\n",
       "                    (act): GELU(approximate='none')\n",
       "                    (proj): Linear(in_features=120, out_features=960, bias=True)\n",
       "                  )\n",
       "                  (1): Dropout(p=0.4, inplace=False)\n",
       "                  (2): Linear(in_features=480, out_features=120, bias=True)\n",
       "                )\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (300): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): Attention(\n",
       "                (to_q): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_k): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_v): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (attend): Attend(\n",
       "                  (attn_dropout): Dropout(p=0.4, inplace=False)\n",
       "                )\n",
       "                (to_out): Linear(in_features=128, out_features=120, bias=False)\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (301): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): FeedForward(\n",
       "                (ff): Sequential(\n",
       "                  (0): GLU(\n",
       "                    (act): GELU(approximate='none')\n",
       "                    (proj): Linear(in_features=120, out_features=960, bias=True)\n",
       "                  )\n",
       "                  (1): Dropout(p=0.4, inplace=False)\n",
       "                  (2): Linear(in_features=480, out_features=120, bias=True)\n",
       "                )\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (302): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): Attention(\n",
       "                (to_q): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_k): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_v): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (attend): Attend(\n",
       "                  (attn_dropout): Dropout(p=0.4, inplace=False)\n",
       "                )\n",
       "                (to_out): Linear(in_features=128, out_features=120, bias=False)\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (303): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): FeedForward(\n",
       "                (ff): Sequential(\n",
       "                  (0): GLU(\n",
       "                    (act): GELU(approximate='none')\n",
       "                    (proj): Linear(in_features=120, out_features=960, bias=True)\n",
       "                  )\n",
       "                  (1): Dropout(p=0.4, inplace=False)\n",
       "                  (2): Linear(in_features=480, out_features=120, bias=True)\n",
       "                )\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (304): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): Attention(\n",
       "                (to_q): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_k): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_v): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (attend): Attend(\n",
       "                  (attn_dropout): Dropout(p=0.4, inplace=False)\n",
       "                )\n",
       "                (to_out): Linear(in_features=128, out_features=120, bias=False)\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (305): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): FeedForward(\n",
       "                (ff): Sequential(\n",
       "                  (0): GLU(\n",
       "                    (act): GELU(approximate='none')\n",
       "                    (proj): Linear(in_features=120, out_features=960, bias=True)\n",
       "                  )\n",
       "                  (1): Dropout(p=0.4, inplace=False)\n",
       "                  (2): Linear(in_features=480, out_features=120, bias=True)\n",
       "                )\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (306): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): Attention(\n",
       "                (to_q): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_k): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_v): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (attend): Attend(\n",
       "                  (attn_dropout): Dropout(p=0.4, inplace=False)\n",
       "                )\n",
       "                (to_out): Linear(in_features=128, out_features=120, bias=False)\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (307): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): FeedForward(\n",
       "                (ff): Sequential(\n",
       "                  (0): GLU(\n",
       "                    (act): GELU(approximate='none')\n",
       "                    (proj): Linear(in_features=120, out_features=960, bias=True)\n",
       "                  )\n",
       "                  (1): Dropout(p=0.4, inplace=False)\n",
       "                  (2): Linear(in_features=480, out_features=120, bias=True)\n",
       "                )\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (308): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): Attention(\n",
       "                (to_q): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_k): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_v): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (attend): Attend(\n",
       "                  (attn_dropout): Dropout(p=0.4, inplace=False)\n",
       "                )\n",
       "                (to_out): Linear(in_features=128, out_features=120, bias=False)\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (309): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): FeedForward(\n",
       "                (ff): Sequential(\n",
       "                  (0): GLU(\n",
       "                    (act): GELU(approximate='none')\n",
       "                    (proj): Linear(in_features=120, out_features=960, bias=True)\n",
       "                  )\n",
       "                  (1): Dropout(p=0.4, inplace=False)\n",
       "                  (2): Linear(in_features=480, out_features=120, bias=True)\n",
       "                )\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (310): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): Attention(\n",
       "                (to_q): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_k): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_v): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (attend): Attend(\n",
       "                  (attn_dropout): Dropout(p=0.4, inplace=False)\n",
       "                )\n",
       "                (to_out): Linear(in_features=128, out_features=120, bias=False)\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (311): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): FeedForward(\n",
       "                (ff): Sequential(\n",
       "                  (0): GLU(\n",
       "                    (act): GELU(approximate='none')\n",
       "                    (proj): Linear(in_features=120, out_features=960, bias=True)\n",
       "                  )\n",
       "                  (1): Dropout(p=0.4, inplace=False)\n",
       "                  (2): Linear(in_features=480, out_features=120, bias=True)\n",
       "                )\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (312): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): Attention(\n",
       "                (to_q): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_k): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_v): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (attend): Attend(\n",
       "                  (attn_dropout): Dropout(p=0.4, inplace=False)\n",
       "                )\n",
       "                (to_out): Linear(in_features=128, out_features=120, bias=False)\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (313): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): FeedForward(\n",
       "                (ff): Sequential(\n",
       "                  (0): GLU(\n",
       "                    (act): GELU(approximate='none')\n",
       "                    (proj): Linear(in_features=120, out_features=960, bias=True)\n",
       "                  )\n",
       "                  (1): Dropout(p=0.4, inplace=False)\n",
       "                  (2): Linear(in_features=480, out_features=120, bias=True)\n",
       "                )\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (314): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): Attention(\n",
       "                (to_q): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_k): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_v): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (attend): Attend(\n",
       "                  (attn_dropout): Dropout(p=0.4, inplace=False)\n",
       "                )\n",
       "                (to_out): Linear(in_features=128, out_features=120, bias=False)\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (315): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): FeedForward(\n",
       "                (ff): Sequential(\n",
       "                  (0): GLU(\n",
       "                    (act): GELU(approximate='none')\n",
       "                    (proj): Linear(in_features=120, out_features=960, bias=True)\n",
       "                  )\n",
       "                  (1): Dropout(p=0.4, inplace=False)\n",
       "                  (2): Linear(in_features=480, out_features=120, bias=True)\n",
       "                )\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (316): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): Attention(\n",
       "                (to_q): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_k): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_v): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (attend): Attend(\n",
       "                  (attn_dropout): Dropout(p=0.4, inplace=False)\n",
       "                )\n",
       "                (to_out): Linear(in_features=128, out_features=120, bias=False)\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (317): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): FeedForward(\n",
       "                (ff): Sequential(\n",
       "                  (0): GLU(\n",
       "                    (act): GELU(approximate='none')\n",
       "                    (proj): Linear(in_features=120, out_features=960, bias=True)\n",
       "                  )\n",
       "                  (1): Dropout(p=0.4, inplace=False)\n",
       "                  (2): Linear(in_features=480, out_features=120, bias=True)\n",
       "                )\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (318): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): Attention(\n",
       "                (to_q): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_k): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_v): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (attend): Attend(\n",
       "                  (attn_dropout): Dropout(p=0.4, inplace=False)\n",
       "                )\n",
       "                (to_out): Linear(in_features=128, out_features=120, bias=False)\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (319): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): FeedForward(\n",
       "                (ff): Sequential(\n",
       "                  (0): GLU(\n",
       "                    (act): GELU(approximate='none')\n",
       "                    (proj): Linear(in_features=120, out_features=960, bias=True)\n",
       "                  )\n",
       "                  (1): Dropout(p=0.4, inplace=False)\n",
       "                  (2): Linear(in_features=480, out_features=120, bias=True)\n",
       "                )\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (320): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): Attention(\n",
       "                (to_q): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_k): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_v): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (attend): Attend(\n",
       "                  (attn_dropout): Dropout(p=0.4, inplace=False)\n",
       "                )\n",
       "                (to_out): Linear(in_features=128, out_features=120, bias=False)\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (321): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): FeedForward(\n",
       "                (ff): Sequential(\n",
       "                  (0): GLU(\n",
       "                    (act): GELU(approximate='none')\n",
       "                    (proj): Linear(in_features=120, out_features=960, bias=True)\n",
       "                  )\n",
       "                  (1): Dropout(p=0.4, inplace=False)\n",
       "                  (2): Linear(in_features=480, out_features=120, bias=True)\n",
       "                )\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (322): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): Attention(\n",
       "                (to_q): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_k): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_v): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (attend): Attend(\n",
       "                  (attn_dropout): Dropout(p=0.4, inplace=False)\n",
       "                )\n",
       "                (to_out): Linear(in_features=128, out_features=120, bias=False)\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (323): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): FeedForward(\n",
       "                (ff): Sequential(\n",
       "                  (0): GLU(\n",
       "                    (act): GELU(approximate='none')\n",
       "                    (proj): Linear(in_features=120, out_features=960, bias=True)\n",
       "                  )\n",
       "                  (1): Dropout(p=0.4, inplace=False)\n",
       "                  (2): Linear(in_features=480, out_features=120, bias=True)\n",
       "                )\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (324): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): Attention(\n",
       "                (to_q): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_k): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_v): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (attend): Attend(\n",
       "                  (attn_dropout): Dropout(p=0.4, inplace=False)\n",
       "                )\n",
       "                (to_out): Linear(in_features=128, out_features=120, bias=False)\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (325): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): FeedForward(\n",
       "                (ff): Sequential(\n",
       "                  (0): GLU(\n",
       "                    (act): GELU(approximate='none')\n",
       "                    (proj): Linear(in_features=120, out_features=960, bias=True)\n",
       "                  )\n",
       "                  (1): Dropout(p=0.4, inplace=False)\n",
       "                  (2): Linear(in_features=480, out_features=120, bias=True)\n",
       "                )\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (326): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): Attention(\n",
       "                (to_q): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_k): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_v): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (attend): Attend(\n",
       "                  (attn_dropout): Dropout(p=0.4, inplace=False)\n",
       "                )\n",
       "                (to_out): Linear(in_features=128, out_features=120, bias=False)\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (327): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): FeedForward(\n",
       "                (ff): Sequential(\n",
       "                  (0): GLU(\n",
       "                    (act): GELU(approximate='none')\n",
       "                    (proj): Linear(in_features=120, out_features=960, bias=True)\n",
       "                  )\n",
       "                  (1): Dropout(p=0.4, inplace=False)\n",
       "                  (2): Linear(in_features=480, out_features=120, bias=True)\n",
       "                )\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (328): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): Attention(\n",
       "                (to_q): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_k): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_v): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (attend): Attend(\n",
       "                  (attn_dropout): Dropout(p=0.4, inplace=False)\n",
       "                )\n",
       "                (to_out): Linear(in_features=128, out_features=120, bias=False)\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (329): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): FeedForward(\n",
       "                (ff): Sequential(\n",
       "                  (0): GLU(\n",
       "                    (act): GELU(approximate='none')\n",
       "                    (proj): Linear(in_features=120, out_features=960, bias=True)\n",
       "                  )\n",
       "                  (1): Dropout(p=0.4, inplace=False)\n",
       "                  (2): Linear(in_features=480, out_features=120, bias=True)\n",
       "                )\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (330): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): Attention(\n",
       "                (to_q): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_k): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_v): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (attend): Attend(\n",
       "                  (attn_dropout): Dropout(p=0.4, inplace=False)\n",
       "                )\n",
       "                (to_out): Linear(in_features=128, out_features=120, bias=False)\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (331): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): FeedForward(\n",
       "                (ff): Sequential(\n",
       "                  (0): GLU(\n",
       "                    (act): GELU(approximate='none')\n",
       "                    (proj): Linear(in_features=120, out_features=960, bias=True)\n",
       "                  )\n",
       "                  (1): Dropout(p=0.4, inplace=False)\n",
       "                  (2): Linear(in_features=480, out_features=120, bias=True)\n",
       "                )\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (332): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): Attention(\n",
       "                (to_q): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_k): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_v): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (attend): Attend(\n",
       "                  (attn_dropout): Dropout(p=0.4, inplace=False)\n",
       "                )\n",
       "                (to_out): Linear(in_features=128, out_features=120, bias=False)\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (333): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): FeedForward(\n",
       "                (ff): Sequential(\n",
       "                  (0): GLU(\n",
       "                    (act): GELU(approximate='none')\n",
       "                    (proj): Linear(in_features=120, out_features=960, bias=True)\n",
       "                  )\n",
       "                  (1): Dropout(p=0.4, inplace=False)\n",
       "                  (2): Linear(in_features=480, out_features=120, bias=True)\n",
       "                )\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (334): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): Attention(\n",
       "                (to_q): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_k): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_v): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (attend): Attend(\n",
       "                  (attn_dropout): Dropout(p=0.4, inplace=False)\n",
       "                )\n",
       "                (to_out): Linear(in_features=128, out_features=120, bias=False)\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (335): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): FeedForward(\n",
       "                (ff): Sequential(\n",
       "                  (0): GLU(\n",
       "                    (act): GELU(approximate='none')\n",
       "                    (proj): Linear(in_features=120, out_features=960, bias=True)\n",
       "                  )\n",
       "                  (1): Dropout(p=0.4, inplace=False)\n",
       "                  (2): Linear(in_features=480, out_features=120, bias=True)\n",
       "                )\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (336): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): Attention(\n",
       "                (to_q): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_k): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_v): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (attend): Attend(\n",
       "                  (attn_dropout): Dropout(p=0.4, inplace=False)\n",
       "                )\n",
       "                (to_out): Linear(in_features=128, out_features=120, bias=False)\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (337): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): FeedForward(\n",
       "                (ff): Sequential(\n",
       "                  (0): GLU(\n",
       "                    (act): GELU(approximate='none')\n",
       "                    (proj): Linear(in_features=120, out_features=960, bias=True)\n",
       "                  )\n",
       "                  (1): Dropout(p=0.4, inplace=False)\n",
       "                  (2): Linear(in_features=480, out_features=120, bias=True)\n",
       "                )\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (338): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): Attention(\n",
       "                (to_q): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_k): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_v): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (attend): Attend(\n",
       "                  (attn_dropout): Dropout(p=0.4, inplace=False)\n",
       "                )\n",
       "                (to_out): Linear(in_features=128, out_features=120, bias=False)\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (339): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): FeedForward(\n",
       "                (ff): Sequential(\n",
       "                  (0): GLU(\n",
       "                    (act): GELU(approximate='none')\n",
       "                    (proj): Linear(in_features=120, out_features=960, bias=True)\n",
       "                  )\n",
       "                  (1): Dropout(p=0.4, inplace=False)\n",
       "                  (2): Linear(in_features=480, out_features=120, bias=True)\n",
       "                )\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (340): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): Attention(\n",
       "                (to_q): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_k): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_v): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (attend): Attend(\n",
       "                  (attn_dropout): Dropout(p=0.4, inplace=False)\n",
       "                )\n",
       "                (to_out): Linear(in_features=128, out_features=120, bias=False)\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (341): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): FeedForward(\n",
       "                (ff): Sequential(\n",
       "                  (0): GLU(\n",
       "                    (act): GELU(approximate='none')\n",
       "                    (proj): Linear(in_features=120, out_features=960, bias=True)\n",
       "                  )\n",
       "                  (1): Dropout(p=0.4, inplace=False)\n",
       "                  (2): Linear(in_features=480, out_features=120, bias=True)\n",
       "                )\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (342): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): Attention(\n",
       "                (to_q): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_k): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_v): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (attend): Attend(\n",
       "                  (attn_dropout): Dropout(p=0.4, inplace=False)\n",
       "                )\n",
       "                (to_out): Linear(in_features=128, out_features=120, bias=False)\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (343): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): FeedForward(\n",
       "                (ff): Sequential(\n",
       "                  (0): GLU(\n",
       "                    (act): GELU(approximate='none')\n",
       "                    (proj): Linear(in_features=120, out_features=960, bias=True)\n",
       "                  )\n",
       "                  (1): Dropout(p=0.4, inplace=False)\n",
       "                  (2): Linear(in_features=480, out_features=120, bias=True)\n",
       "                )\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (344): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): Attention(\n",
       "                (to_q): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_k): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_v): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (attend): Attend(\n",
       "                  (attn_dropout): Dropout(p=0.4, inplace=False)\n",
       "                )\n",
       "                (to_out): Linear(in_features=128, out_features=120, bias=False)\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (345): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): FeedForward(\n",
       "                (ff): Sequential(\n",
       "                  (0): GLU(\n",
       "                    (act): GELU(approximate='none')\n",
       "                    (proj): Linear(in_features=120, out_features=960, bias=True)\n",
       "                  )\n",
       "                  (1): Dropout(p=0.4, inplace=False)\n",
       "                  (2): Linear(in_features=480, out_features=120, bias=True)\n",
       "                )\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (346): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): Attention(\n",
       "                (to_q): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_k): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_v): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (attend): Attend(\n",
       "                  (attn_dropout): Dropout(p=0.4, inplace=False)\n",
       "                )\n",
       "                (to_out): Linear(in_features=128, out_features=120, bias=False)\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (347): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): FeedForward(\n",
       "                (ff): Sequential(\n",
       "                  (0): GLU(\n",
       "                    (act): GELU(approximate='none')\n",
       "                    (proj): Linear(in_features=120, out_features=960, bias=True)\n",
       "                  )\n",
       "                  (1): Dropout(p=0.4, inplace=False)\n",
       "                  (2): Linear(in_features=480, out_features=120, bias=True)\n",
       "                )\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (348): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): Attention(\n",
       "                (to_q): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_k): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_v): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (attend): Attend(\n",
       "                  (attn_dropout): Dropout(p=0.4, inplace=False)\n",
       "                )\n",
       "                (to_out): Linear(in_features=128, out_features=120, bias=False)\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (349): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): FeedForward(\n",
       "                (ff): Sequential(\n",
       "                  (0): GLU(\n",
       "                    (act): GELU(approximate='none')\n",
       "                    (proj): Linear(in_features=120, out_features=960, bias=True)\n",
       "                  )\n",
       "                  (1): Dropout(p=0.4, inplace=False)\n",
       "                  (2): Linear(in_features=480, out_features=120, bias=True)\n",
       "                )\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (350): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): Attention(\n",
       "                (to_q): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_k): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_v): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (attend): Attend(\n",
       "                  (attn_dropout): Dropout(p=0.4, inplace=False)\n",
       "                )\n",
       "                (to_out): Linear(in_features=128, out_features=120, bias=False)\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (351): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): FeedForward(\n",
       "                (ff): Sequential(\n",
       "                  (0): GLU(\n",
       "                    (act): GELU(approximate='none')\n",
       "                    (proj): Linear(in_features=120, out_features=960, bias=True)\n",
       "                  )\n",
       "                  (1): Dropout(p=0.4, inplace=False)\n",
       "                  (2): Linear(in_features=480, out_features=120, bias=True)\n",
       "                )\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (352): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): Attention(\n",
       "                (to_q): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_k): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_v): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (attend): Attend(\n",
       "                  (attn_dropout): Dropout(p=0.4, inplace=False)\n",
       "                )\n",
       "                (to_out): Linear(in_features=128, out_features=120, bias=False)\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (353): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): FeedForward(\n",
       "                (ff): Sequential(\n",
       "                  (0): GLU(\n",
       "                    (act): GELU(approximate='none')\n",
       "                    (proj): Linear(in_features=120, out_features=960, bias=True)\n",
       "                  )\n",
       "                  (1): Dropout(p=0.4, inplace=False)\n",
       "                  (2): Linear(in_features=480, out_features=120, bias=True)\n",
       "                )\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (354): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): Attention(\n",
       "                (to_q): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_k): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_v): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (attend): Attend(\n",
       "                  (attn_dropout): Dropout(p=0.4, inplace=False)\n",
       "                )\n",
       "                (to_out): Linear(in_features=128, out_features=120, bias=False)\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (355): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): FeedForward(\n",
       "                (ff): Sequential(\n",
       "                  (0): GLU(\n",
       "                    (act): GELU(approximate='none')\n",
       "                    (proj): Linear(in_features=120, out_features=960, bias=True)\n",
       "                  )\n",
       "                  (1): Dropout(p=0.4, inplace=False)\n",
       "                  (2): Linear(in_features=480, out_features=120, bias=True)\n",
       "                )\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (356): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): Attention(\n",
       "                (to_q): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_k): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_v): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (attend): Attend(\n",
       "                  (attn_dropout): Dropout(p=0.4, inplace=False)\n",
       "                )\n",
       "                (to_out): Linear(in_features=128, out_features=120, bias=False)\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (357): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): FeedForward(\n",
       "                (ff): Sequential(\n",
       "                  (0): GLU(\n",
       "                    (act): GELU(approximate='none')\n",
       "                    (proj): Linear(in_features=120, out_features=960, bias=True)\n",
       "                  )\n",
       "                  (1): Dropout(p=0.4, inplace=False)\n",
       "                  (2): Linear(in_features=480, out_features=120, bias=True)\n",
       "                )\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (358): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): Attention(\n",
       "                (to_q): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_k): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_v): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (attend): Attend(\n",
       "                  (attn_dropout): Dropout(p=0.4, inplace=False)\n",
       "                )\n",
       "                (to_out): Linear(in_features=128, out_features=120, bias=False)\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (359): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): FeedForward(\n",
       "                (ff): Sequential(\n",
       "                  (0): GLU(\n",
       "                    (act): GELU(approximate='none')\n",
       "                    (proj): Linear(in_features=120, out_features=960, bias=True)\n",
       "                  )\n",
       "                  (1): Dropout(p=0.4, inplace=False)\n",
       "                  (2): Linear(in_features=480, out_features=120, bias=True)\n",
       "                )\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (360): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): Attention(\n",
       "                (to_q): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_k): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_v): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (attend): Attend(\n",
       "                  (attn_dropout): Dropout(p=0.4, inplace=False)\n",
       "                )\n",
       "                (to_out): Linear(in_features=128, out_features=120, bias=False)\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (361): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): FeedForward(\n",
       "                (ff): Sequential(\n",
       "                  (0): GLU(\n",
       "                    (act): GELU(approximate='none')\n",
       "                    (proj): Linear(in_features=120, out_features=960, bias=True)\n",
       "                  )\n",
       "                  (1): Dropout(p=0.4, inplace=False)\n",
       "                  (2): Linear(in_features=480, out_features=120, bias=True)\n",
       "                )\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (362): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): Attention(\n",
       "                (to_q): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_k): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_v): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (attend): Attend(\n",
       "                  (attn_dropout): Dropout(p=0.4, inplace=False)\n",
       "                )\n",
       "                (to_out): Linear(in_features=128, out_features=120, bias=False)\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (363): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): FeedForward(\n",
       "                (ff): Sequential(\n",
       "                  (0): GLU(\n",
       "                    (act): GELU(approximate='none')\n",
       "                    (proj): Linear(in_features=120, out_features=960, bias=True)\n",
       "                  )\n",
       "                  (1): Dropout(p=0.4, inplace=False)\n",
       "                  (2): Linear(in_features=480, out_features=120, bias=True)\n",
       "                )\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (364): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): Attention(\n",
       "                (to_q): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_k): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_v): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (attend): Attend(\n",
       "                  (attn_dropout): Dropout(p=0.4, inplace=False)\n",
       "                )\n",
       "                (to_out): Linear(in_features=128, out_features=120, bias=False)\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (365): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): FeedForward(\n",
       "                (ff): Sequential(\n",
       "                  (0): GLU(\n",
       "                    (act): GELU(approximate='none')\n",
       "                    (proj): Linear(in_features=120, out_features=960, bias=True)\n",
       "                  )\n",
       "                  (1): Dropout(p=0.4, inplace=False)\n",
       "                  (2): Linear(in_features=480, out_features=120, bias=True)\n",
       "                )\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (366): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): Attention(\n",
       "                (to_q): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_k): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_v): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (attend): Attend(\n",
       "                  (attn_dropout): Dropout(p=0.4, inplace=False)\n",
       "                )\n",
       "                (to_out): Linear(in_features=128, out_features=120, bias=False)\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (367): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): FeedForward(\n",
       "                (ff): Sequential(\n",
       "                  (0): GLU(\n",
       "                    (act): GELU(approximate='none')\n",
       "                    (proj): Linear(in_features=120, out_features=960, bias=True)\n",
       "                  )\n",
       "                  (1): Dropout(p=0.4, inplace=False)\n",
       "                  (2): Linear(in_features=480, out_features=120, bias=True)\n",
       "                )\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (368): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): Attention(\n",
       "                (to_q): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_k): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_v): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (attend): Attend(\n",
       "                  (attn_dropout): Dropout(p=0.4, inplace=False)\n",
       "                )\n",
       "                (to_out): Linear(in_features=128, out_features=120, bias=False)\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (369): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): FeedForward(\n",
       "                (ff): Sequential(\n",
       "                  (0): GLU(\n",
       "                    (act): GELU(approximate='none')\n",
       "                    (proj): Linear(in_features=120, out_features=960, bias=True)\n",
       "                  )\n",
       "                  (1): Dropout(p=0.4, inplace=False)\n",
       "                  (2): Linear(in_features=480, out_features=120, bias=True)\n",
       "                )\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (370): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): Attention(\n",
       "                (to_q): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_k): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_v): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (attend): Attend(\n",
       "                  (attn_dropout): Dropout(p=0.4, inplace=False)\n",
       "                )\n",
       "                (to_out): Linear(in_features=128, out_features=120, bias=False)\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (371): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): FeedForward(\n",
       "                (ff): Sequential(\n",
       "                  (0): GLU(\n",
       "                    (act): GELU(approximate='none')\n",
       "                    (proj): Linear(in_features=120, out_features=960, bias=True)\n",
       "                  )\n",
       "                  (1): Dropout(p=0.4, inplace=False)\n",
       "                  (2): Linear(in_features=480, out_features=120, bias=True)\n",
       "                )\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (372): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): Attention(\n",
       "                (to_q): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_k): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_v): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (attend): Attend(\n",
       "                  (attn_dropout): Dropout(p=0.4, inplace=False)\n",
       "                )\n",
       "                (to_out): Linear(in_features=128, out_features=120, bias=False)\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (373): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): FeedForward(\n",
       "                (ff): Sequential(\n",
       "                  (0): GLU(\n",
       "                    (act): GELU(approximate='none')\n",
       "                    (proj): Linear(in_features=120, out_features=960, bias=True)\n",
       "                  )\n",
       "                  (1): Dropout(p=0.4, inplace=False)\n",
       "                  (2): Linear(in_features=480, out_features=120, bias=True)\n",
       "                )\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (374): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): Attention(\n",
       "                (to_q): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_k): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_v): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (attend): Attend(\n",
       "                  (attn_dropout): Dropout(p=0.4, inplace=False)\n",
       "                )\n",
       "                (to_out): Linear(in_features=128, out_features=120, bias=False)\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (375): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): FeedForward(\n",
       "                (ff): Sequential(\n",
       "                  (0): GLU(\n",
       "                    (act): GELU(approximate='none')\n",
       "                    (proj): Linear(in_features=120, out_features=960, bias=True)\n",
       "                  )\n",
       "                  (1): Dropout(p=0.4, inplace=False)\n",
       "                  (2): Linear(in_features=480, out_features=120, bias=True)\n",
       "                )\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (376): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): Attention(\n",
       "                (to_q): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_k): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_v): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (attend): Attend(\n",
       "                  (attn_dropout): Dropout(p=0.4, inplace=False)\n",
       "                )\n",
       "                (to_out): Linear(in_features=128, out_features=120, bias=False)\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (377): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): FeedForward(\n",
       "                (ff): Sequential(\n",
       "                  (0): GLU(\n",
       "                    (act): GELU(approximate='none')\n",
       "                    (proj): Linear(in_features=120, out_features=960, bias=True)\n",
       "                  )\n",
       "                  (1): Dropout(p=0.4, inplace=False)\n",
       "                  (2): Linear(in_features=480, out_features=120, bias=True)\n",
       "                )\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (378): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): Attention(\n",
       "                (to_q): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_k): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_v): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (attend): Attend(\n",
       "                  (attn_dropout): Dropout(p=0.4, inplace=False)\n",
       "                )\n",
       "                (to_out): Linear(in_features=128, out_features=120, bias=False)\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (379): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): FeedForward(\n",
       "                (ff): Sequential(\n",
       "                  (0): GLU(\n",
       "                    (act): GELU(approximate='none')\n",
       "                    (proj): Linear(in_features=120, out_features=960, bias=True)\n",
       "                  )\n",
       "                  (1): Dropout(p=0.4, inplace=False)\n",
       "                  (2): Linear(in_features=480, out_features=120, bias=True)\n",
       "                )\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (380): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): Attention(\n",
       "                (to_q): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_k): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_v): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (attend): Attend(\n",
       "                  (attn_dropout): Dropout(p=0.4, inplace=False)\n",
       "                )\n",
       "                (to_out): Linear(in_features=128, out_features=120, bias=False)\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (381): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): FeedForward(\n",
       "                (ff): Sequential(\n",
       "                  (0): GLU(\n",
       "                    (act): GELU(approximate='none')\n",
       "                    (proj): Linear(in_features=120, out_features=960, bias=True)\n",
       "                  )\n",
       "                  (1): Dropout(p=0.4, inplace=False)\n",
       "                  (2): Linear(in_features=480, out_features=120, bias=True)\n",
       "                )\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (382): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): Attention(\n",
       "                (to_q): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_k): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_v): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (attend): Attend(\n",
       "                  (attn_dropout): Dropout(p=0.4, inplace=False)\n",
       "                )\n",
       "                (to_out): Linear(in_features=128, out_features=120, bias=False)\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (383): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): FeedForward(\n",
       "                (ff): Sequential(\n",
       "                  (0): GLU(\n",
       "                    (act): GELU(approximate='none')\n",
       "                    (proj): Linear(in_features=120, out_features=960, bias=True)\n",
       "                  )\n",
       "                  (1): Dropout(p=0.4, inplace=False)\n",
       "                  (2): Linear(in_features=480, out_features=120, bias=True)\n",
       "                )\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (384): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): Attention(\n",
       "                (to_q): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_k): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_v): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (attend): Attend(\n",
       "                  (attn_dropout): Dropout(p=0.4, inplace=False)\n",
       "                )\n",
       "                (to_out): Linear(in_features=128, out_features=120, bias=False)\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (385): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): FeedForward(\n",
       "                (ff): Sequential(\n",
       "                  (0): GLU(\n",
       "                    (act): GELU(approximate='none')\n",
       "                    (proj): Linear(in_features=120, out_features=960, bias=True)\n",
       "                  )\n",
       "                  (1): Dropout(p=0.4, inplace=False)\n",
       "                  (2): Linear(in_features=480, out_features=120, bias=True)\n",
       "                )\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (386): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): Attention(\n",
       "                (to_q): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_k): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_v): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (attend): Attend(\n",
       "                  (attn_dropout): Dropout(p=0.4, inplace=False)\n",
       "                )\n",
       "                (to_out): Linear(in_features=128, out_features=120, bias=False)\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (387): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): FeedForward(\n",
       "                (ff): Sequential(\n",
       "                  (0): GLU(\n",
       "                    (act): GELU(approximate='none')\n",
       "                    (proj): Linear(in_features=120, out_features=960, bias=True)\n",
       "                  )\n",
       "                  (1): Dropout(p=0.4, inplace=False)\n",
       "                  (2): Linear(in_features=480, out_features=120, bias=True)\n",
       "                )\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (388): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): Attention(\n",
       "                (to_q): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_k): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_v): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (attend): Attend(\n",
       "                  (attn_dropout): Dropout(p=0.4, inplace=False)\n",
       "                )\n",
       "                (to_out): Linear(in_features=128, out_features=120, bias=False)\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (389): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): FeedForward(\n",
       "                (ff): Sequential(\n",
       "                  (0): GLU(\n",
       "                    (act): GELU(approximate='none')\n",
       "                    (proj): Linear(in_features=120, out_features=960, bias=True)\n",
       "                  )\n",
       "                  (1): Dropout(p=0.4, inplace=False)\n",
       "                  (2): Linear(in_features=480, out_features=120, bias=True)\n",
       "                )\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (390): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): Attention(\n",
       "                (to_q): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_k): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_v): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (attend): Attend(\n",
       "                  (attn_dropout): Dropout(p=0.4, inplace=False)\n",
       "                )\n",
       "                (to_out): Linear(in_features=128, out_features=120, bias=False)\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (391): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): FeedForward(\n",
       "                (ff): Sequential(\n",
       "                  (0): GLU(\n",
       "                    (act): GELU(approximate='none')\n",
       "                    (proj): Linear(in_features=120, out_features=960, bias=True)\n",
       "                  )\n",
       "                  (1): Dropout(p=0.4, inplace=False)\n",
       "                  (2): Linear(in_features=480, out_features=120, bias=True)\n",
       "                )\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (392): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): Attention(\n",
       "                (to_q): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_k): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_v): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (attend): Attend(\n",
       "                  (attn_dropout): Dropout(p=0.4, inplace=False)\n",
       "                )\n",
       "                (to_out): Linear(in_features=128, out_features=120, bias=False)\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (393): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): FeedForward(\n",
       "                (ff): Sequential(\n",
       "                  (0): GLU(\n",
       "                    (act): GELU(approximate='none')\n",
       "                    (proj): Linear(in_features=120, out_features=960, bias=True)\n",
       "                  )\n",
       "                  (1): Dropout(p=0.4, inplace=False)\n",
       "                  (2): Linear(in_features=480, out_features=120, bias=True)\n",
       "                )\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (394): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): Attention(\n",
       "                (to_q): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_k): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_v): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (attend): Attend(\n",
       "                  (attn_dropout): Dropout(p=0.4, inplace=False)\n",
       "                )\n",
       "                (to_out): Linear(in_features=128, out_features=120, bias=False)\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (395): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): FeedForward(\n",
       "                (ff): Sequential(\n",
       "                  (0): GLU(\n",
       "                    (act): GELU(approximate='none')\n",
       "                    (proj): Linear(in_features=120, out_features=960, bias=True)\n",
       "                  )\n",
       "                  (1): Dropout(p=0.4, inplace=False)\n",
       "                  (2): Linear(in_features=480, out_features=120, bias=True)\n",
       "                )\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (396): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): Attention(\n",
       "                (to_q): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_k): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_v): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (attend): Attend(\n",
       "                  (attn_dropout): Dropout(p=0.4, inplace=False)\n",
       "                )\n",
       "                (to_out): Linear(in_features=128, out_features=120, bias=False)\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (397): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): FeedForward(\n",
       "                (ff): Sequential(\n",
       "                  (0): GLU(\n",
       "                    (act): GELU(approximate='none')\n",
       "                    (proj): Linear(in_features=120, out_features=960, bias=True)\n",
       "                  )\n",
       "                  (1): Dropout(p=0.4, inplace=False)\n",
       "                  (2): Linear(in_features=480, out_features=120, bias=True)\n",
       "                )\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (398): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): Attention(\n",
       "                (to_q): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_k): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_v): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (attend): Attend(\n",
       "                  (attn_dropout): Dropout(p=0.4, inplace=False)\n",
       "                )\n",
       "                (to_out): Linear(in_features=128, out_features=120, bias=False)\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (399): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): FeedForward(\n",
       "                (ff): Sequential(\n",
       "                  (0): GLU(\n",
       "                    (act): GELU(approximate='none')\n",
       "                    (proj): Linear(in_features=120, out_features=960, bias=True)\n",
       "                  )\n",
       "                  (1): Dropout(p=0.4, inplace=False)\n",
       "                  (2): Linear(in_features=480, out_features=120, bias=True)\n",
       "                )\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (400): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): Attention(\n",
       "                (to_q): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_k): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_v): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (attend): Attend(\n",
       "                  (attn_dropout): Dropout(p=0.4, inplace=False)\n",
       "                )\n",
       "                (to_out): Linear(in_features=128, out_features=120, bias=False)\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (401): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): FeedForward(\n",
       "                (ff): Sequential(\n",
       "                  (0): GLU(\n",
       "                    (act): GELU(approximate='none')\n",
       "                    (proj): Linear(in_features=120, out_features=960, bias=True)\n",
       "                  )\n",
       "                  (1): Dropout(p=0.4, inplace=False)\n",
       "                  (2): Linear(in_features=480, out_features=120, bias=True)\n",
       "                )\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (402): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): Attention(\n",
       "                (to_q): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_k): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_v): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (attend): Attend(\n",
       "                  (attn_dropout): Dropout(p=0.4, inplace=False)\n",
       "                )\n",
       "                (to_out): Linear(in_features=128, out_features=120, bias=False)\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (403): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): FeedForward(\n",
       "                (ff): Sequential(\n",
       "                  (0): GLU(\n",
       "                    (act): GELU(approximate='none')\n",
       "                    (proj): Linear(in_features=120, out_features=960, bias=True)\n",
       "                  )\n",
       "                  (1): Dropout(p=0.4, inplace=False)\n",
       "                  (2): Linear(in_features=480, out_features=120, bias=True)\n",
       "                )\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (404): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): Attention(\n",
       "                (to_q): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_k): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_v): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (attend): Attend(\n",
       "                  (attn_dropout): Dropout(p=0.4, inplace=False)\n",
       "                )\n",
       "                (to_out): Linear(in_features=128, out_features=120, bias=False)\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (405): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): FeedForward(\n",
       "                (ff): Sequential(\n",
       "                  (0): GLU(\n",
       "                    (act): GELU(approximate='none')\n",
       "                    (proj): Linear(in_features=120, out_features=960, bias=True)\n",
       "                  )\n",
       "                  (1): Dropout(p=0.4, inplace=False)\n",
       "                  (2): Linear(in_features=480, out_features=120, bias=True)\n",
       "                )\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (406): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): Attention(\n",
       "                (to_q): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_k): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_v): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (attend): Attend(\n",
       "                  (attn_dropout): Dropout(p=0.4, inplace=False)\n",
       "                )\n",
       "                (to_out): Linear(in_features=128, out_features=120, bias=False)\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (407): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): FeedForward(\n",
       "                (ff): Sequential(\n",
       "                  (0): GLU(\n",
       "                    (act): GELU(approximate='none')\n",
       "                    (proj): Linear(in_features=120, out_features=960, bias=True)\n",
       "                  )\n",
       "                  (1): Dropout(p=0.4, inplace=False)\n",
       "                  (2): Linear(in_features=480, out_features=120, bias=True)\n",
       "                )\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (408): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): Attention(\n",
       "                (to_q): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_k): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_v): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (attend): Attend(\n",
       "                  (attn_dropout): Dropout(p=0.4, inplace=False)\n",
       "                )\n",
       "                (to_out): Linear(in_features=128, out_features=120, bias=False)\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (409): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): FeedForward(\n",
       "                (ff): Sequential(\n",
       "                  (0): GLU(\n",
       "                    (act): GELU(approximate='none')\n",
       "                    (proj): Linear(in_features=120, out_features=960, bias=True)\n",
       "                  )\n",
       "                  (1): Dropout(p=0.4, inplace=False)\n",
       "                  (2): Linear(in_features=480, out_features=120, bias=True)\n",
       "                )\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (410): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): Attention(\n",
       "                (to_q): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_k): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_v): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (attend): Attend(\n",
       "                  (attn_dropout): Dropout(p=0.4, inplace=False)\n",
       "                )\n",
       "                (to_out): Linear(in_features=128, out_features=120, bias=False)\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (411): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): FeedForward(\n",
       "                (ff): Sequential(\n",
       "                  (0): GLU(\n",
       "                    (act): GELU(approximate='none')\n",
       "                    (proj): Linear(in_features=120, out_features=960, bias=True)\n",
       "                  )\n",
       "                  (1): Dropout(p=0.4, inplace=False)\n",
       "                  (2): Linear(in_features=480, out_features=120, bias=True)\n",
       "                )\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (412): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): Attention(\n",
       "                (to_q): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_k): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_v): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (attend): Attend(\n",
       "                  (attn_dropout): Dropout(p=0.4, inplace=False)\n",
       "                )\n",
       "                (to_out): Linear(in_features=128, out_features=120, bias=False)\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (413): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): FeedForward(\n",
       "                (ff): Sequential(\n",
       "                  (0): GLU(\n",
       "                    (act): GELU(approximate='none')\n",
       "                    (proj): Linear(in_features=120, out_features=960, bias=True)\n",
       "                  )\n",
       "                  (1): Dropout(p=0.4, inplace=False)\n",
       "                  (2): Linear(in_features=480, out_features=120, bias=True)\n",
       "                )\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (414): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): Attention(\n",
       "                (to_q): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_k): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_v): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (attend): Attend(\n",
       "                  (attn_dropout): Dropout(p=0.4, inplace=False)\n",
       "                )\n",
       "                (to_out): Linear(in_features=128, out_features=120, bias=False)\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (415): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): FeedForward(\n",
       "                (ff): Sequential(\n",
       "                  (0): GLU(\n",
       "                    (act): GELU(approximate='none')\n",
       "                    (proj): Linear(in_features=120, out_features=960, bias=True)\n",
       "                  )\n",
       "                  (1): Dropout(p=0.4, inplace=False)\n",
       "                  (2): Linear(in_features=480, out_features=120, bias=True)\n",
       "                )\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (416): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): Attention(\n",
       "                (to_q): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_k): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_v): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (attend): Attend(\n",
       "                  (attn_dropout): Dropout(p=0.4, inplace=False)\n",
       "                )\n",
       "                (to_out): Linear(in_features=128, out_features=120, bias=False)\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (417): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): FeedForward(\n",
       "                (ff): Sequential(\n",
       "                  (0): GLU(\n",
       "                    (act): GELU(approximate='none')\n",
       "                    (proj): Linear(in_features=120, out_features=960, bias=True)\n",
       "                  )\n",
       "                  (1): Dropout(p=0.4, inplace=False)\n",
       "                  (2): Linear(in_features=480, out_features=120, bias=True)\n",
       "                )\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (418): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): Attention(\n",
       "                (to_q): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_k): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_v): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (attend): Attend(\n",
       "                  (attn_dropout): Dropout(p=0.4, inplace=False)\n",
       "                )\n",
       "                (to_out): Linear(in_features=128, out_features=120, bias=False)\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (419): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): FeedForward(\n",
       "                (ff): Sequential(\n",
       "                  (0): GLU(\n",
       "                    (act): GELU(approximate='none')\n",
       "                    (proj): Linear(in_features=120, out_features=960, bias=True)\n",
       "                  )\n",
       "                  (1): Dropout(p=0.4, inplace=False)\n",
       "                  (2): Linear(in_features=480, out_features=120, bias=True)\n",
       "                )\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (420): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): Attention(\n",
       "                (to_q): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_k): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_v): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (attend): Attend(\n",
       "                  (attn_dropout): Dropout(p=0.4, inplace=False)\n",
       "                )\n",
       "                (to_out): Linear(in_features=128, out_features=120, bias=False)\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (421): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): FeedForward(\n",
       "                (ff): Sequential(\n",
       "                  (0): GLU(\n",
       "                    (act): GELU(approximate='none')\n",
       "                    (proj): Linear(in_features=120, out_features=960, bias=True)\n",
       "                  )\n",
       "                  (1): Dropout(p=0.4, inplace=False)\n",
       "                  (2): Linear(in_features=480, out_features=120, bias=True)\n",
       "                )\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (422): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): Attention(\n",
       "                (to_q): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_k): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_v): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (attend): Attend(\n",
       "                  (attn_dropout): Dropout(p=0.4, inplace=False)\n",
       "                )\n",
       "                (to_out): Linear(in_features=128, out_features=120, bias=False)\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (423): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): FeedForward(\n",
       "                (ff): Sequential(\n",
       "                  (0): GLU(\n",
       "                    (act): GELU(approximate='none')\n",
       "                    (proj): Linear(in_features=120, out_features=960, bias=True)\n",
       "                  )\n",
       "                  (1): Dropout(p=0.4, inplace=False)\n",
       "                  (2): Linear(in_features=480, out_features=120, bias=True)\n",
       "                )\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (424): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): Attention(\n",
       "                (to_q): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_k): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_v): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (attend): Attend(\n",
       "                  (attn_dropout): Dropout(p=0.4, inplace=False)\n",
       "                )\n",
       "                (to_out): Linear(in_features=128, out_features=120, bias=False)\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (425): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): FeedForward(\n",
       "                (ff): Sequential(\n",
       "                  (0): GLU(\n",
       "                    (act): GELU(approximate='none')\n",
       "                    (proj): Linear(in_features=120, out_features=960, bias=True)\n",
       "                  )\n",
       "                  (1): Dropout(p=0.4, inplace=False)\n",
       "                  (2): Linear(in_features=480, out_features=120, bias=True)\n",
       "                )\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (426): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): Attention(\n",
       "                (to_q): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_k): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_v): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (attend): Attend(\n",
       "                  (attn_dropout): Dropout(p=0.4, inplace=False)\n",
       "                )\n",
       "                (to_out): Linear(in_features=128, out_features=120, bias=False)\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (427): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): FeedForward(\n",
       "                (ff): Sequential(\n",
       "                  (0): GLU(\n",
       "                    (act): GELU(approximate='none')\n",
       "                    (proj): Linear(in_features=120, out_features=960, bias=True)\n",
       "                  )\n",
       "                  (1): Dropout(p=0.4, inplace=False)\n",
       "                  (2): Linear(in_features=480, out_features=120, bias=True)\n",
       "                )\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (428): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): Attention(\n",
       "                (to_q): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_k): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_v): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (attend): Attend(\n",
       "                  (attn_dropout): Dropout(p=0.4, inplace=False)\n",
       "                )\n",
       "                (to_out): Linear(in_features=128, out_features=120, bias=False)\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (429): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): FeedForward(\n",
       "                (ff): Sequential(\n",
       "                  (0): GLU(\n",
       "                    (act): GELU(approximate='none')\n",
       "                    (proj): Linear(in_features=120, out_features=960, bias=True)\n",
       "                  )\n",
       "                  (1): Dropout(p=0.4, inplace=False)\n",
       "                  (2): Linear(in_features=480, out_features=120, bias=True)\n",
       "                )\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (430): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): Attention(\n",
       "                (to_q): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_k): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_v): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (attend): Attend(\n",
       "                  (attn_dropout): Dropout(p=0.4, inplace=False)\n",
       "                )\n",
       "                (to_out): Linear(in_features=128, out_features=120, bias=False)\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (431): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): FeedForward(\n",
       "                (ff): Sequential(\n",
       "                  (0): GLU(\n",
       "                    (act): GELU(approximate='none')\n",
       "                    (proj): Linear(in_features=120, out_features=960, bias=True)\n",
       "                  )\n",
       "                  (1): Dropout(p=0.4, inplace=False)\n",
       "                  (2): Linear(in_features=480, out_features=120, bias=True)\n",
       "                )\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (432): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): Attention(\n",
       "                (to_q): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_k): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_v): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (attend): Attend(\n",
       "                  (attn_dropout): Dropout(p=0.4, inplace=False)\n",
       "                )\n",
       "                (to_out): Linear(in_features=128, out_features=120, bias=False)\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (433): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): FeedForward(\n",
       "                (ff): Sequential(\n",
       "                  (0): GLU(\n",
       "                    (act): GELU(approximate='none')\n",
       "                    (proj): Linear(in_features=120, out_features=960, bias=True)\n",
       "                  )\n",
       "                  (1): Dropout(p=0.4, inplace=False)\n",
       "                  (2): Linear(in_features=480, out_features=120, bias=True)\n",
       "                )\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (434): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): Attention(\n",
       "                (to_q): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_k): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_v): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (attend): Attend(\n",
       "                  (attn_dropout): Dropout(p=0.4, inplace=False)\n",
       "                )\n",
       "                (to_out): Linear(in_features=128, out_features=120, bias=False)\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (435): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): FeedForward(\n",
       "                (ff): Sequential(\n",
       "                  (0): GLU(\n",
       "                    (act): GELU(approximate='none')\n",
       "                    (proj): Linear(in_features=120, out_features=960, bias=True)\n",
       "                  )\n",
       "                  (1): Dropout(p=0.4, inplace=False)\n",
       "                  (2): Linear(in_features=480, out_features=120, bias=True)\n",
       "                )\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (436): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): Attention(\n",
       "                (to_q): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_k): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_v): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (attend): Attend(\n",
       "                  (attn_dropout): Dropout(p=0.4, inplace=False)\n",
       "                )\n",
       "                (to_out): Linear(in_features=128, out_features=120, bias=False)\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (437): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): FeedForward(\n",
       "                (ff): Sequential(\n",
       "                  (0): GLU(\n",
       "                    (act): GELU(approximate='none')\n",
       "                    (proj): Linear(in_features=120, out_features=960, bias=True)\n",
       "                  )\n",
       "                  (1): Dropout(p=0.4, inplace=False)\n",
       "                  (2): Linear(in_features=480, out_features=120, bias=True)\n",
       "                )\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (438): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): Attention(\n",
       "                (to_q): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_k): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_v): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (attend): Attend(\n",
       "                  (attn_dropout): Dropout(p=0.4, inplace=False)\n",
       "                )\n",
       "                (to_out): Linear(in_features=128, out_features=120, bias=False)\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (439): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): FeedForward(\n",
       "                (ff): Sequential(\n",
       "                  (0): GLU(\n",
       "                    (act): GELU(approximate='none')\n",
       "                    (proj): Linear(in_features=120, out_features=960, bias=True)\n",
       "                  )\n",
       "                  (1): Dropout(p=0.4, inplace=False)\n",
       "                  (2): Linear(in_features=480, out_features=120, bias=True)\n",
       "                )\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (440): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): Attention(\n",
       "                (to_q): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_k): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_v): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (attend): Attend(\n",
       "                  (attn_dropout): Dropout(p=0.4, inplace=False)\n",
       "                )\n",
       "                (to_out): Linear(in_features=128, out_features=120, bias=False)\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (441): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): FeedForward(\n",
       "                (ff): Sequential(\n",
       "                  (0): GLU(\n",
       "                    (act): GELU(approximate='none')\n",
       "                    (proj): Linear(in_features=120, out_features=960, bias=True)\n",
       "                  )\n",
       "                  (1): Dropout(p=0.4, inplace=False)\n",
       "                  (2): Linear(in_features=480, out_features=120, bias=True)\n",
       "                )\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (442): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): Attention(\n",
       "                (to_q): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_k): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_v): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (attend): Attend(\n",
       "                  (attn_dropout): Dropout(p=0.4, inplace=False)\n",
       "                )\n",
       "                (to_out): Linear(in_features=128, out_features=120, bias=False)\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (443): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): FeedForward(\n",
       "                (ff): Sequential(\n",
       "                  (0): GLU(\n",
       "                    (act): GELU(approximate='none')\n",
       "                    (proj): Linear(in_features=120, out_features=960, bias=True)\n",
       "                  )\n",
       "                  (1): Dropout(p=0.4, inplace=False)\n",
       "                  (2): Linear(in_features=480, out_features=120, bias=True)\n",
       "                )\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (444): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): Attention(\n",
       "                (to_q): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_k): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_v): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (attend): Attend(\n",
       "                  (attn_dropout): Dropout(p=0.4, inplace=False)\n",
       "                )\n",
       "                (to_out): Linear(in_features=128, out_features=120, bias=False)\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (445): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): FeedForward(\n",
       "                (ff): Sequential(\n",
       "                  (0): GLU(\n",
       "                    (act): GELU(approximate='none')\n",
       "                    (proj): Linear(in_features=120, out_features=960, bias=True)\n",
       "                  )\n",
       "                  (1): Dropout(p=0.4, inplace=False)\n",
       "                  (2): Linear(in_features=480, out_features=120, bias=True)\n",
       "                )\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (446): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): Attention(\n",
       "                (to_q): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_k): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_v): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (attend): Attend(\n",
       "                  (attn_dropout): Dropout(p=0.4, inplace=False)\n",
       "                )\n",
       "                (to_out): Linear(in_features=128, out_features=120, bias=False)\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (447): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): FeedForward(\n",
       "                (ff): Sequential(\n",
       "                  (0): GLU(\n",
       "                    (act): GELU(approximate='none')\n",
       "                    (proj): Linear(in_features=120, out_features=960, bias=True)\n",
       "                  )\n",
       "                  (1): Dropout(p=0.4, inplace=False)\n",
       "                  (2): Linear(in_features=480, out_features=120, bias=True)\n",
       "                )\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (448): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): Attention(\n",
       "                (to_q): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_k): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_v): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (attend): Attend(\n",
       "                  (attn_dropout): Dropout(p=0.4, inplace=False)\n",
       "                )\n",
       "                (to_out): Linear(in_features=128, out_features=120, bias=False)\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (449): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): FeedForward(\n",
       "                (ff): Sequential(\n",
       "                  (0): GLU(\n",
       "                    (act): GELU(approximate='none')\n",
       "                    (proj): Linear(in_features=120, out_features=960, bias=True)\n",
       "                  )\n",
       "                  (1): Dropout(p=0.4, inplace=False)\n",
       "                  (2): Linear(in_features=480, out_features=120, bias=True)\n",
       "                )\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (450): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): Attention(\n",
       "                (to_q): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_k): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_v): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (attend): Attend(\n",
       "                  (attn_dropout): Dropout(p=0.4, inplace=False)\n",
       "                )\n",
       "                (to_out): Linear(in_features=128, out_features=120, bias=False)\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (451): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): FeedForward(\n",
       "                (ff): Sequential(\n",
       "                  (0): GLU(\n",
       "                    (act): GELU(approximate='none')\n",
       "                    (proj): Linear(in_features=120, out_features=960, bias=True)\n",
       "                  )\n",
       "                  (1): Dropout(p=0.4, inplace=False)\n",
       "                  (2): Linear(in_features=480, out_features=120, bias=True)\n",
       "                )\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (452): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): Attention(\n",
       "                (to_q): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_k): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_v): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (attend): Attend(\n",
       "                  (attn_dropout): Dropout(p=0.4, inplace=False)\n",
       "                )\n",
       "                (to_out): Linear(in_features=128, out_features=120, bias=False)\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (453): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): FeedForward(\n",
       "                (ff): Sequential(\n",
       "                  (0): GLU(\n",
       "                    (act): GELU(approximate='none')\n",
       "                    (proj): Linear(in_features=120, out_features=960, bias=True)\n",
       "                  )\n",
       "                  (1): Dropout(p=0.4, inplace=False)\n",
       "                  (2): Linear(in_features=480, out_features=120, bias=True)\n",
       "                )\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (454): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): Attention(\n",
       "                (to_q): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_k): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_v): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (attend): Attend(\n",
       "                  (attn_dropout): Dropout(p=0.4, inplace=False)\n",
       "                )\n",
       "                (to_out): Linear(in_features=128, out_features=120, bias=False)\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (455): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): FeedForward(\n",
       "                (ff): Sequential(\n",
       "                  (0): GLU(\n",
       "                    (act): GELU(approximate='none')\n",
       "                    (proj): Linear(in_features=120, out_features=960, bias=True)\n",
       "                  )\n",
       "                  (1): Dropout(p=0.4, inplace=False)\n",
       "                  (2): Linear(in_features=480, out_features=120, bias=True)\n",
       "                )\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (456): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): Attention(\n",
       "                (to_q): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_k): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_v): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (attend): Attend(\n",
       "                  (attn_dropout): Dropout(p=0.4, inplace=False)\n",
       "                )\n",
       "                (to_out): Linear(in_features=128, out_features=120, bias=False)\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (457): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): FeedForward(\n",
       "                (ff): Sequential(\n",
       "                  (0): GLU(\n",
       "                    (act): GELU(approximate='none')\n",
       "                    (proj): Linear(in_features=120, out_features=960, bias=True)\n",
       "                  )\n",
       "                  (1): Dropout(p=0.4, inplace=False)\n",
       "                  (2): Linear(in_features=480, out_features=120, bias=True)\n",
       "                )\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (458): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): Attention(\n",
       "                (to_q): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_k): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_v): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (attend): Attend(\n",
       "                  (attn_dropout): Dropout(p=0.4, inplace=False)\n",
       "                )\n",
       "                (to_out): Linear(in_features=128, out_features=120, bias=False)\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (459): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): FeedForward(\n",
       "                (ff): Sequential(\n",
       "                  (0): GLU(\n",
       "                    (act): GELU(approximate='none')\n",
       "                    (proj): Linear(in_features=120, out_features=960, bias=True)\n",
       "                  )\n",
       "                  (1): Dropout(p=0.4, inplace=False)\n",
       "                  (2): Linear(in_features=480, out_features=120, bias=True)\n",
       "                )\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (460): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): Attention(\n",
       "                (to_q): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_k): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_v): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (attend): Attend(\n",
       "                  (attn_dropout): Dropout(p=0.4, inplace=False)\n",
       "                )\n",
       "                (to_out): Linear(in_features=128, out_features=120, bias=False)\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (461): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): FeedForward(\n",
       "                (ff): Sequential(\n",
       "                  (0): GLU(\n",
       "                    (act): GELU(approximate='none')\n",
       "                    (proj): Linear(in_features=120, out_features=960, bias=True)\n",
       "                  )\n",
       "                  (1): Dropout(p=0.4, inplace=False)\n",
       "                  (2): Linear(in_features=480, out_features=120, bias=True)\n",
       "                )\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (462): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): Attention(\n",
       "                (to_q): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_k): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_v): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (attend): Attend(\n",
       "                  (attn_dropout): Dropout(p=0.4, inplace=False)\n",
       "                )\n",
       "                (to_out): Linear(in_features=128, out_features=120, bias=False)\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (463): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): FeedForward(\n",
       "                (ff): Sequential(\n",
       "                  (0): GLU(\n",
       "                    (act): GELU(approximate='none')\n",
       "                    (proj): Linear(in_features=120, out_features=960, bias=True)\n",
       "                  )\n",
       "                  (1): Dropout(p=0.4, inplace=False)\n",
       "                  (2): Linear(in_features=480, out_features=120, bias=True)\n",
       "                )\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (464): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): Attention(\n",
       "                (to_q): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_k): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_v): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (attend): Attend(\n",
       "                  (attn_dropout): Dropout(p=0.4, inplace=False)\n",
       "                )\n",
       "                (to_out): Linear(in_features=128, out_features=120, bias=False)\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (465): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): FeedForward(\n",
       "                (ff): Sequential(\n",
       "                  (0): GLU(\n",
       "                    (act): GELU(approximate='none')\n",
       "                    (proj): Linear(in_features=120, out_features=960, bias=True)\n",
       "                  )\n",
       "                  (1): Dropout(p=0.4, inplace=False)\n",
       "                  (2): Linear(in_features=480, out_features=120, bias=True)\n",
       "                )\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (466): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): Attention(\n",
       "                (to_q): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_k): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_v): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (attend): Attend(\n",
       "                  (attn_dropout): Dropout(p=0.4, inplace=False)\n",
       "                )\n",
       "                (to_out): Linear(in_features=128, out_features=120, bias=False)\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (467): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): FeedForward(\n",
       "                (ff): Sequential(\n",
       "                  (0): GLU(\n",
       "                    (act): GELU(approximate='none')\n",
       "                    (proj): Linear(in_features=120, out_features=960, bias=True)\n",
       "                  )\n",
       "                  (1): Dropout(p=0.4, inplace=False)\n",
       "                  (2): Linear(in_features=480, out_features=120, bias=True)\n",
       "                )\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (468): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): Attention(\n",
       "                (to_q): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_k): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_v): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (attend): Attend(\n",
       "                  (attn_dropout): Dropout(p=0.4, inplace=False)\n",
       "                )\n",
       "                (to_out): Linear(in_features=128, out_features=120, bias=False)\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (469): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): FeedForward(\n",
       "                (ff): Sequential(\n",
       "                  (0): GLU(\n",
       "                    (act): GELU(approximate='none')\n",
       "                    (proj): Linear(in_features=120, out_features=960, bias=True)\n",
       "                  )\n",
       "                  (1): Dropout(p=0.4, inplace=False)\n",
       "                  (2): Linear(in_features=480, out_features=120, bias=True)\n",
       "                )\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (470): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): Attention(\n",
       "                (to_q): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_k): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_v): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (attend): Attend(\n",
       "                  (attn_dropout): Dropout(p=0.4, inplace=False)\n",
       "                )\n",
       "                (to_out): Linear(in_features=128, out_features=120, bias=False)\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (471): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): FeedForward(\n",
       "                (ff): Sequential(\n",
       "                  (0): GLU(\n",
       "                    (act): GELU(approximate='none')\n",
       "                    (proj): Linear(in_features=120, out_features=960, bias=True)\n",
       "                  )\n",
       "                  (1): Dropout(p=0.4, inplace=False)\n",
       "                  (2): Linear(in_features=480, out_features=120, bias=True)\n",
       "                )\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (472): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): Attention(\n",
       "                (to_q): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_k): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_v): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (attend): Attend(\n",
       "                  (attn_dropout): Dropout(p=0.4, inplace=False)\n",
       "                )\n",
       "                (to_out): Linear(in_features=128, out_features=120, bias=False)\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (473): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): FeedForward(\n",
       "                (ff): Sequential(\n",
       "                  (0): GLU(\n",
       "                    (act): GELU(approximate='none')\n",
       "                    (proj): Linear(in_features=120, out_features=960, bias=True)\n",
       "                  )\n",
       "                  (1): Dropout(p=0.4, inplace=False)\n",
       "                  (2): Linear(in_features=480, out_features=120, bias=True)\n",
       "                )\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (474): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): Attention(\n",
       "                (to_q): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_k): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_v): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (attend): Attend(\n",
       "                  (attn_dropout): Dropout(p=0.4, inplace=False)\n",
       "                )\n",
       "                (to_out): Linear(in_features=128, out_features=120, bias=False)\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (475): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): FeedForward(\n",
       "                (ff): Sequential(\n",
       "                  (0): GLU(\n",
       "                    (act): GELU(approximate='none')\n",
       "                    (proj): Linear(in_features=120, out_features=960, bias=True)\n",
       "                  )\n",
       "                  (1): Dropout(p=0.4, inplace=False)\n",
       "                  (2): Linear(in_features=480, out_features=120, bias=True)\n",
       "                )\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (476): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): Attention(\n",
       "                (to_q): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_k): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_v): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (attend): Attend(\n",
       "                  (attn_dropout): Dropout(p=0.4, inplace=False)\n",
       "                )\n",
       "                (to_out): Linear(in_features=128, out_features=120, bias=False)\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (477): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): FeedForward(\n",
       "                (ff): Sequential(\n",
       "                  (0): GLU(\n",
       "                    (act): GELU(approximate='none')\n",
       "                    (proj): Linear(in_features=120, out_features=960, bias=True)\n",
       "                  )\n",
       "                  (1): Dropout(p=0.4, inplace=False)\n",
       "                  (2): Linear(in_features=480, out_features=120, bias=True)\n",
       "                )\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (478): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): Attention(\n",
       "                (to_q): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_k): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_v): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (attend): Attend(\n",
       "                  (attn_dropout): Dropout(p=0.4, inplace=False)\n",
       "                )\n",
       "                (to_out): Linear(in_features=128, out_features=120, bias=False)\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (479): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): FeedForward(\n",
       "                (ff): Sequential(\n",
       "                  (0): GLU(\n",
       "                    (act): GELU(approximate='none')\n",
       "                    (proj): Linear(in_features=120, out_features=960, bias=True)\n",
       "                  )\n",
       "                  (1): Dropout(p=0.4, inplace=False)\n",
       "                  (2): Linear(in_features=480, out_features=120, bias=True)\n",
       "                )\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (480): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): Attention(\n",
       "                (to_q): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_k): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_v): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (attend): Attend(\n",
       "                  (attn_dropout): Dropout(p=0.4, inplace=False)\n",
       "                )\n",
       "                (to_out): Linear(in_features=128, out_features=120, bias=False)\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (481): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): FeedForward(\n",
       "                (ff): Sequential(\n",
       "                  (0): GLU(\n",
       "                    (act): GELU(approximate='none')\n",
       "                    (proj): Linear(in_features=120, out_features=960, bias=True)\n",
       "                  )\n",
       "                  (1): Dropout(p=0.4, inplace=False)\n",
       "                  (2): Linear(in_features=480, out_features=120, bias=True)\n",
       "                )\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (482): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): Attention(\n",
       "                (to_q): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_k): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_v): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (attend): Attend(\n",
       "                  (attn_dropout): Dropout(p=0.4, inplace=False)\n",
       "                )\n",
       "                (to_out): Linear(in_features=128, out_features=120, bias=False)\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (483): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): FeedForward(\n",
       "                (ff): Sequential(\n",
       "                  (0): GLU(\n",
       "                    (act): GELU(approximate='none')\n",
       "                    (proj): Linear(in_features=120, out_features=960, bias=True)\n",
       "                  )\n",
       "                  (1): Dropout(p=0.4, inplace=False)\n",
       "                  (2): Linear(in_features=480, out_features=120, bias=True)\n",
       "                )\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (484): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): Attention(\n",
       "                (to_q): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_k): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_v): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (attend): Attend(\n",
       "                  (attn_dropout): Dropout(p=0.4, inplace=False)\n",
       "                )\n",
       "                (to_out): Linear(in_features=128, out_features=120, bias=False)\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (485): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): FeedForward(\n",
       "                (ff): Sequential(\n",
       "                  (0): GLU(\n",
       "                    (act): GELU(approximate='none')\n",
       "                    (proj): Linear(in_features=120, out_features=960, bias=True)\n",
       "                  )\n",
       "                  (1): Dropout(p=0.4, inplace=False)\n",
       "                  (2): Linear(in_features=480, out_features=120, bias=True)\n",
       "                )\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (486): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): Attention(\n",
       "                (to_q): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_k): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_v): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (attend): Attend(\n",
       "                  (attn_dropout): Dropout(p=0.4, inplace=False)\n",
       "                )\n",
       "                (to_out): Linear(in_features=128, out_features=120, bias=False)\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (487): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): FeedForward(\n",
       "                (ff): Sequential(\n",
       "                  (0): GLU(\n",
       "                    (act): GELU(approximate='none')\n",
       "                    (proj): Linear(in_features=120, out_features=960, bias=True)\n",
       "                  )\n",
       "                  (1): Dropout(p=0.4, inplace=False)\n",
       "                  (2): Linear(in_features=480, out_features=120, bias=True)\n",
       "                )\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (488): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): Attention(\n",
       "                (to_q): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_k): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_v): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (attend): Attend(\n",
       "                  (attn_dropout): Dropout(p=0.4, inplace=False)\n",
       "                )\n",
       "                (to_out): Linear(in_features=128, out_features=120, bias=False)\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (489): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): FeedForward(\n",
       "                (ff): Sequential(\n",
       "                  (0): GLU(\n",
       "                    (act): GELU(approximate='none')\n",
       "                    (proj): Linear(in_features=120, out_features=960, bias=True)\n",
       "                  )\n",
       "                  (1): Dropout(p=0.4, inplace=False)\n",
       "                  (2): Linear(in_features=480, out_features=120, bias=True)\n",
       "                )\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (490): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): Attention(\n",
       "                (to_q): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_k): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_v): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (attend): Attend(\n",
       "                  (attn_dropout): Dropout(p=0.4, inplace=False)\n",
       "                )\n",
       "                (to_out): Linear(in_features=128, out_features=120, bias=False)\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (491): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): FeedForward(\n",
       "                (ff): Sequential(\n",
       "                  (0): GLU(\n",
       "                    (act): GELU(approximate='none')\n",
       "                    (proj): Linear(in_features=120, out_features=960, bias=True)\n",
       "                  )\n",
       "                  (1): Dropout(p=0.4, inplace=False)\n",
       "                  (2): Linear(in_features=480, out_features=120, bias=True)\n",
       "                )\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (492): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): Attention(\n",
       "                (to_q): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_k): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_v): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (attend): Attend(\n",
       "                  (attn_dropout): Dropout(p=0.4, inplace=False)\n",
       "                )\n",
       "                (to_out): Linear(in_features=128, out_features=120, bias=False)\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (493): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): FeedForward(\n",
       "                (ff): Sequential(\n",
       "                  (0): GLU(\n",
       "                    (act): GELU(approximate='none')\n",
       "                    (proj): Linear(in_features=120, out_features=960, bias=True)\n",
       "                  )\n",
       "                  (1): Dropout(p=0.4, inplace=False)\n",
       "                  (2): Linear(in_features=480, out_features=120, bias=True)\n",
       "                )\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (494): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): Attention(\n",
       "                (to_q): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_k): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_v): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (attend): Attend(\n",
       "                  (attn_dropout): Dropout(p=0.4, inplace=False)\n",
       "                )\n",
       "                (to_out): Linear(in_features=128, out_features=120, bias=False)\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (495): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): FeedForward(\n",
       "                (ff): Sequential(\n",
       "                  (0): GLU(\n",
       "                    (act): GELU(approximate='none')\n",
       "                    (proj): Linear(in_features=120, out_features=960, bias=True)\n",
       "                  )\n",
       "                  (1): Dropout(p=0.4, inplace=False)\n",
       "                  (2): Linear(in_features=480, out_features=120, bias=True)\n",
       "                )\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (496): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): Attention(\n",
       "                (to_q): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_k): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_v): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (attend): Attend(\n",
       "                  (attn_dropout): Dropout(p=0.4, inplace=False)\n",
       "                )\n",
       "                (to_out): Linear(in_features=128, out_features=120, bias=False)\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (497): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): FeedForward(\n",
       "                (ff): Sequential(\n",
       "                  (0): GLU(\n",
       "                    (act): GELU(approximate='none')\n",
       "                    (proj): Linear(in_features=120, out_features=960, bias=True)\n",
       "                  )\n",
       "                  (1): Dropout(p=0.4, inplace=False)\n",
       "                  (2): Linear(in_features=480, out_features=120, bias=True)\n",
       "                )\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (498): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): Attention(\n",
       "                (to_q): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_k): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (to_v): Linear(in_features=120, out_features=128, bias=False)\n",
       "                (attend): Attend(\n",
       "                  (attn_dropout): Dropout(p=0.4, inplace=False)\n",
       "                )\n",
       "                (to_out): Linear(in_features=128, out_features=120, bias=False)\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "            (499): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): SimpleRMSNorm()\n",
       "                (1-2): 2 x None\n",
       "              )\n",
       "              (1): FeedForward(\n",
       "                (ff): Sequential(\n",
       "                  (0): GLU(\n",
       "                    (act): GELU(approximate='none')\n",
       "                    (proj): Linear(in_features=120, out_features=960, bias=True)\n",
       "                  )\n",
       "                  (1): Dropout(p=0.4, inplace=False)\n",
       "                  (2): Linear(in_features=480, out_features=120, bias=True)\n",
       "                )\n",
       "              )\n",
       "              (2): Residual()\n",
       "            )\n",
       "          )\n",
       "          (rotary_pos_emb): RotaryEmbedding()\n",
       "          (final_norm): SimpleRMSNorm()\n",
       "        )\n",
       "        (to_logits): Linear(in_features=120, out_features=12, bias=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (linear): Linear(in_features=120, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "d8f322f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg['num_tokens'] = dna_dataset.tokenizer.vocab_size\n",
    "cfg['max_seq_len'] = dna_dataset.tokenizer.model_max_length\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "76555502",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 1971, 1])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dna_dataset.X[:10].unsqueeze(-1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "2ebe3800",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = model(dna_dataset.X[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "5919a10d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([513695, 1971, 1])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dna_dataset.X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "dd54e6ee",
   "metadata": {},
   "outputs": [
    {
     "ename": "PicklingError",
     "evalue": "Can't pickle <class 'aptamer_transformer.dataset.XGBoostDataset'>: it's not the same object as aptamer_transformer.dataset.XGBoostDataset",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPicklingError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[70], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43msave_data_set_as_pickle\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdna_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcfg\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/glade/work/mlsample/aptamer_transformer/aptamer_transformer/data_utils.py:445\u001b[0m, in \u001b[0;36msave_data_set_as_pickle\u001b[0;34m(dna_dataset, cfg)\u001b[0m\n\u001b[1;32m    442\u001b[0m     filepath \u001b[38;5;241m=\u001b[39m dataset_class\u001b[38;5;241m.\u001b[39mfile_path_to_pickled_dataset(cfg)\n\u001b[1;32m    444\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(filepath, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwb\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m--> 445\u001b[0m         \u001b[43mpickle\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdump\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdna_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpickle\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mHIGHEST_PROTOCOL\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    447\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    448\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mPicklingError\u001b[0m: Can't pickle <class 'aptamer_transformer.dataset.XGBoostDataset'>: it's not the same object as aptamer_transformer.dataset.XGBoostDataset"
     ]
    }
   ],
   "source": [
    "save_data_set_as_pickle(dna_dataset, cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f28fc4d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.00117157, 0.00126148, 0.00163361, ..., 0.        , 0.        ,\n",
       "       0.0004682 ], dtype=float32)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importance = model.feature_importances_\n",
    "\n",
    "importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "360cd0a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.093049\n",
      "MAE: 0.070006\n",
      "MSE: 0.008658\n",
      "MAPE: inf%\n",
      "Explained Variance Score: 0.237908\n",
      "Median Absolute Error: 0.052792\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/glade/derecho/scratch/mlsample/tmp/ipykernel_15438/2329638207.py:22: RuntimeWarning: divide by zero encountered in divide\n",
      "  mape = np.mean(np.abs((y_test - y_pred) / y_test)) * 100\n"
     ]
    }
   ],
   "source": [
    "# Make predictions\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "\n",
    "\n",
    "# RMSE\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "print(\"RMSE: %f\" % rmse)\n",
    "\n",
    "# MAE\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "print(\"MAE: %f\" % mae)\n",
    "\n",
    "\n",
    "# MSE\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(\"MSE: %f\" % mse)\n",
    "\n",
    "# MAPE - Mean Absolute Percentage Error\n",
    "mape = np.mean(np.abs((y_test - y_pred) / y_test)) * 100\n",
    "print(\"MAPE: %f%%\" % mape)\n",
    "\n",
    "# Explained Variance Score\n",
    "explained_variance = explained_variance_score(y_test, y_pred)\n",
    "print(\"Explained Variance Score: %f\" % explained_variance)\n",
    "\n",
    "# Median Absolute Error\n",
    "median_ae = median_absolute_error(y_test, y_pred)\n",
    "print(\"Median Absolute Error: %f\" % median_ae)\n",
    "\n",
    "\n",
    "# feature_names = [\"Sequence\"] + [\"dot_bracket\"] + ['energy'] + ['structure_matrix']\n",
    "# # Feature Importance\n",
    "# importance = model.feature_importances_\n",
    "# # Assuming you have feature names in a list 'feature_names'\n",
    "# for i, v in enumerate(importance):\n",
    "#     print('Feature: %s, Score: %.5f' % (feature_names[i], v))\n",
    "\n",
    "# # Cross-Validation Scores\n",
    "# cv_scores = cross_val_score(model, X, y, cv=5)\n",
    "# print(\"Cross-Validation Scores: \", cv_scores)\n",
    "\n",
    "# # Learning Curves\n",
    "# train_sizes, train_scores, validation_scores = learning_curve(model, X, y, train_sizes=np.linspace(0.1, 1.0, 5))\n",
    "# plt.plot(train_sizes, np.mean(train_scores, axis=1), 'o-', color=\"r\", label=\"Training score\")\n",
    "# plt.plot(train_sizes, np.mean(validation_scores, axis=1), 'o-', color=\"g\", label=\"Cross-validation score\")\n",
    "# plt.title(\"Learning Curve\")\n",
    "# plt.xlabel(\"Training Set Size\")\n",
    "# plt.ylabel(\"Score\")\n",
    "# plt.legend(loc=\"best\")\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "43c74d98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.        , 0.00258813, 0.00136215, ..., 0.        , 0.        ,\n",
       "       0.00183746], dtype=float32)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a94c2090",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "e6dd2988",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(376828,)"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(df_filtered['energy']).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "9ca69661",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Intel MKL ERROR: Parameter 6 was incorrect on entry to DGELSD.\n"
     ]
    },
    {
     "ename": "LinAlgError",
     "evalue": "SVD did not converge in Linear Least Squares",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mLinAlgError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[180], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m x \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(df_filtered[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmean\u001b[39m\u001b[38;5;124m'\u001b[39m])[::\u001b[38;5;241m500\u001b[39m]\n\u001b[1;32m      2\u001b[0m y \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(df_filtered[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124menergy\u001b[39m\u001b[38;5;124m'\u001b[39m])[::\u001b[38;5;241m500\u001b[39m]\n\u001b[0;32m----> 4\u001b[0m reg \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpolyfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m z \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mpoly1d(reg)\n",
      "File \u001b[0;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36mpolyfit\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[0;32m/glade/work/mlsample/conda-envs/guess/lib/python3.10/site-packages/numpy/lib/polynomial.py:668\u001b[0m, in \u001b[0;36mpolyfit\u001b[0;34m(x, y, deg, rcond, full, w, cov)\u001b[0m\n\u001b[1;32m    666\u001b[0m scale \u001b[38;5;241m=\u001b[39m NX\u001b[38;5;241m.\u001b[39msqrt((lhs\u001b[38;5;241m*\u001b[39mlhs)\u001b[38;5;241m.\u001b[39msum(axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m))\n\u001b[1;32m    667\u001b[0m lhs \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m=\u001b[39m scale\n\u001b[0;32m--> 668\u001b[0m c, resids, rank, s \u001b[38;5;241m=\u001b[39m \u001b[43mlstsq\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlhs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrhs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrcond\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    669\u001b[0m c \u001b[38;5;241m=\u001b[39m (c\u001b[38;5;241m.\u001b[39mT\u001b[38;5;241m/\u001b[39mscale)\u001b[38;5;241m.\u001b[39mT  \u001b[38;5;66;03m# broadcast scale coefficients\u001b[39;00m\n\u001b[1;32m    671\u001b[0m \u001b[38;5;66;03m# warn on rank reduction, which indicates an ill conditioned matrix\u001b[39;00m\n",
      "File \u001b[0;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36mlstsq\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[0;32m/glade/work/mlsample/conda-envs/guess/lib/python3.10/site-packages/numpy/linalg/linalg.py:2300\u001b[0m, in \u001b[0;36mlstsq\u001b[0;34m(a, b, rcond)\u001b[0m\n\u001b[1;32m   2297\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n_rhs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m   2298\u001b[0m     \u001b[38;5;66;03m# lapack can't handle n_rhs = 0 - so allocate the array one larger in that axis\u001b[39;00m\n\u001b[1;32m   2299\u001b[0m     b \u001b[38;5;241m=\u001b[39m zeros(b\u001b[38;5;241m.\u001b[39mshape[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m] \u001b[38;5;241m+\u001b[39m (m, n_rhs \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m), dtype\u001b[38;5;241m=\u001b[39mb\u001b[38;5;241m.\u001b[39mdtype)\n\u001b[0;32m-> 2300\u001b[0m x, resids, rank, s \u001b[38;5;241m=\u001b[39m \u001b[43mgufunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrcond\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextobj\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2301\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m   2302\u001b[0m     x[\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "File \u001b[0;32m/glade/work/mlsample/conda-envs/guess/lib/python3.10/site-packages/numpy/linalg/linalg.py:101\u001b[0m, in \u001b[0;36m_raise_linalgerror_lstsq\u001b[0;34m(err, flag)\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_raise_linalgerror_lstsq\u001b[39m(err, flag):\n\u001b[0;32m--> 101\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m LinAlgError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSVD did not converge in Linear Least Squares\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mLinAlgError\u001b[0m: SVD did not converge in Linear Least Squares"
     ]
    }
   ],
   "source": [
    "x = np.array(df_filtered['mean'])[::500]\n",
    "y = np.array(df_filtered['energy'])[::500]\n",
    "\n",
    "reg = np.polyfit(x, y, 1)\n",
    "\n",
    "z = np.poly1d(reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "181e26c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "poly1d([ 3.27167726e+06, -1.43817845e+07,  2.78642752e+07, -3.12970935e+07,\n",
       "        2.25377900e+07, -1.08569844e+07,  3.53785929e+06, -7.68941268e+05,\n",
       "        1.06552808e+05, -8.49288582e+03,  2.96431392e+02])"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4673d90f",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[33], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mplt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mplot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mo\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/glade/work/mlsample/conda-envs/guess/lib/python3.10/site-packages/matplotlib/pyplot.py:3575\u001b[0m, in \u001b[0;36mplot\u001b[0;34m(scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3567\u001b[0m \u001b[38;5;129m@_copy_docstring_and_deprecators\u001b[39m(Axes\u001b[38;5;241m.\u001b[39mplot)\n\u001b[1;32m   3568\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mplot\u001b[39m(\n\u001b[1;32m   3569\u001b[0m     \u001b[38;5;241m*\u001b[39margs: \u001b[38;5;28mfloat\u001b[39m \u001b[38;5;241m|\u001b[39m ArrayLike \u001b[38;5;241m|\u001b[39m \u001b[38;5;28mstr\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3573\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m   3574\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mlist\u001b[39m[Line2D]:\n\u001b[0;32m-> 3575\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgca\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mplot\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3576\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3577\u001b[0m \u001b[43m        \u001b[49m\u001b[43mscalex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mscalex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3578\u001b[0m \u001b[43m        \u001b[49m\u001b[43mscaley\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mscaley\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3579\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdata\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m}\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3580\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3581\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/glade/work/mlsample/conda-envs/guess/lib/python3.10/site-packages/matplotlib/axes/_axes.py:1721\u001b[0m, in \u001b[0;36mAxes.plot\u001b[0;34m(self, scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1478\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1479\u001b[0m \u001b[38;5;124;03mPlot y versus x as lines and/or markers.\u001b[39;00m\n\u001b[1;32m   1480\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1718\u001b[0m \u001b[38;5;124;03m(``'green'``) or hex strings (``'#008000'``).\u001b[39;00m\n\u001b[1;32m   1719\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1720\u001b[0m kwargs \u001b[38;5;241m=\u001b[39m cbook\u001b[38;5;241m.\u001b[39mnormalize_kwargs(kwargs, mlines\u001b[38;5;241m.\u001b[39mLine2D)\n\u001b[0;32m-> 1721\u001b[0m lines \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_lines(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, data\u001b[38;5;241m=\u001b[39mdata, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)]\n\u001b[1;32m   1722\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m line \u001b[38;5;129;01min\u001b[39;00m lines:\n\u001b[1;32m   1723\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madd_line(line)\n",
      "File \u001b[0;32m/glade/work/mlsample/conda-envs/guess/lib/python3.10/site-packages/matplotlib/axes/_base.py:303\u001b[0m, in \u001b[0;36m_process_plot_var_args.__call__\u001b[0;34m(self, axes, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m    301\u001b[0m     this \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m args[\u001b[38;5;241m0\u001b[39m],\n\u001b[1;32m    302\u001b[0m     args \u001b[38;5;241m=\u001b[39m args[\u001b[38;5;241m1\u001b[39m:]\n\u001b[0;32m--> 303\u001b[0m \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_plot_args\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    304\u001b[0m \u001b[43m    \u001b[49m\u001b[43maxes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mthis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mambiguous_fmt_datakey\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mambiguous_fmt_datakey\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/glade/work/mlsample/conda-envs/guess/lib/python3.10/site-packages/matplotlib/axes/_base.py:539\u001b[0m, in \u001b[0;36m_process_plot_var_args._plot_args\u001b[0;34m(self, axes, tup, kwargs, return_kwargs, ambiguous_fmt_datakey)\u001b[0m\n\u001b[1;32m    537\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(result)\n\u001b[1;32m    538\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 539\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [l[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m l \u001b[38;5;129;01min\u001b[39;00m result]\n",
      "File \u001b[0;32m/glade/work/mlsample/conda-envs/guess/lib/python3.10/site-packages/matplotlib/axes/_base.py:539\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    537\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(result)\n\u001b[1;32m    538\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 539\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [l[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m l \u001b[38;5;129;01min\u001b[39;00m result]\n",
      "File \u001b[0;32m/glade/work/mlsample/conda-envs/guess/lib/python3.10/site-packages/matplotlib/axes/_base.py:532\u001b[0m, in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    529\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    530\u001b[0m     labels \u001b[38;5;241m=\u001b[39m [label] \u001b[38;5;241m*\u001b[39m n_datasets\n\u001b[0;32m--> 532\u001b[0m result \u001b[38;5;241m=\u001b[39m (\u001b[43mmake_artist\u001b[49m\u001b[43m(\u001b[49m\u001b[43maxes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mj\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m%\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mncx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mj\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m%\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mncy\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkw\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    533\u001b[0m \u001b[43m                      \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlabel\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    534\u001b[0m           \u001b[38;5;28;01mfor\u001b[39;00m j, label \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(labels))\n\u001b[1;32m    536\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m return_kwargs:\n\u001b[1;32m    537\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(result)\n",
      "File \u001b[0;32m/glade/work/mlsample/conda-envs/guess/lib/python3.10/site-packages/matplotlib/axes/_base.py:346\u001b[0m, in \u001b[0;36m_process_plot_var_args._makeline\u001b[0;34m(self, axes, x, y, kw, kwargs)\u001b[0m\n\u001b[1;32m    344\u001b[0m default_dict \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getdefaults(\u001b[38;5;28mset\u001b[39m(), kw)\n\u001b[1;32m    345\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_setdefaults(default_dict, kw)\n\u001b[0;32m--> 346\u001b[0m seg \u001b[38;5;241m=\u001b[39m \u001b[43mmlines\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mLine2D\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    347\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m seg, kw\n",
      "File \u001b[0;32m/glade/work/mlsample/conda-envs/guess/lib/python3.10/site-packages/matplotlib/lines.py:426\u001b[0m, in \u001b[0;36mLine2D.__init__\u001b[0;34m(self, xdata, ydata, linewidth, linestyle, color, gapcolor, marker, markersize, markeredgewidth, markeredgecolor, markerfacecolor, markerfacecoloralt, fillstyle, antialiased, dash_capstyle, solid_capstyle, dash_joinstyle, solid_joinstyle, pickradius, drawstyle, markevery, **kwargs)\u001b[0m\n\u001b[1;32m    423\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_subslice \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    424\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_x_filled \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m  \u001b[38;5;66;03m# used in subslicing; only x is needed\u001b[39;00m\n\u001b[0;32m--> 426\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mset_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mxdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mydata\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/glade/work/mlsample/conda-envs/guess/lib/python3.10/site-packages/matplotlib/lines.py:660\u001b[0m, in \u001b[0;36mLine2D.set_data\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    657\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    658\u001b[0m     x, y \u001b[38;5;241m=\u001b[39m args\n\u001b[0;32m--> 660\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mset_xdata\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    661\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mset_ydata(y)\n",
      "File \u001b[0;32m/glade/work/mlsample/conda-envs/guess/lib/python3.10/site-packages/matplotlib/lines.py:1287\u001b[0m, in \u001b[0;36mLine2D.set_xdata\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m   1281\u001b[0m     _api\u001b[38;5;241m.\u001b[39mwarn_deprecated(\n\u001b[1;32m   1282\u001b[0m         since\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m3.7\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1283\u001b[0m         message\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSetting data with a non sequence type \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1284\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mis deprecated since \u001b[39m\u001b[38;5;132;01m%(since)s\u001b[39;00m\u001b[38;5;124m and will be \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1285\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mremove \u001b[39m\u001b[38;5;132;01m%(removal)s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1286\u001b[0m     x \u001b[38;5;241m=\u001b[39m [x, ]\n\u001b[0;32m-> 1287\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_xorig \u001b[38;5;241m=\u001b[39m \u001b[43mcopy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1288\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_invalidx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m   1289\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstale \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m/glade/work/mlsample/conda-envs/guess/lib/python3.10/copy.py:84\u001b[0m, in \u001b[0;36mcopy\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m     82\u001b[0m copier \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mcls\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__copy__\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m     83\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m copier \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m---> 84\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcopier\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     86\u001b[0m reductor \u001b[38;5;241m=\u001b[39m dispatch_table\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;28mcls\u001b[39m)\n\u001b[1;32m     87\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m reductor \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(X_train, y_train, 'o')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "8d165db0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[<Axes: title={'center': 'mean'}>]], dtype=object)"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_filtered.hist(column='mean', bins=70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "0d0ba551",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BarContainer object of 4 artists>"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "nucleotide_counts = {'A': 0, 'T': 0, 'C': 0, 'G': 0}\n",
    "\n",
    "# Function to count nucleotides in a sequence\n",
    "def count_nucleotides(sequence):\n",
    "    for nucleotide in nucleotide_counts.keys():\n",
    "        nucleotide_counts[nucleotide] += sequence.count(nucleotide)\n",
    "\n",
    "# Apply the function to each sequence\n",
    "df_filtered['Sequence'].apply(count_nucleotides)\n",
    "\n",
    "# Now nucleotide_counts contains the total count for each nucleotide\n",
    "plt.bar(nucleotide_counts.keys(), nucleotide_counts.values())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "298a6659",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/nupack_strucutre_data/mfe.pickle', 'rb') as f:\n",
    "    mfe = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4033704a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the model and optimizer here as you did during training\n",
    "device = torch.device(\"cuda:0\")  \n",
    "cfg.update({\n",
    "    'device': device,\n",
    "})\n",
    "\n",
    "model = get_model(cfg).to(device)\n",
    "# optimizer = optim.Adam(model.parameters(), lr=cfg['learning_rate'])\n",
    "\n",
    "# # Load the checkpoint\n",
    "# checkpoint = torch.load(cfg['checkpoint_path'])  # Replace X with the epoch number\n",
    "\n",
    "# # Restore the model and optimizer states\n",
    "# model.load_state_dict(checkpoint['model_state_dict'])\n",
    "# optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "\n",
    "# # Move the model to evaluation mode if you are doing inference\n",
    "# model.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "04b462c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 512])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits, embed, tgt = model(df.Sequence[:2].tolist(), df.Sequence[:2].tolist())\n",
    "\n",
    "embed[:,0,:].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d8c8ff4-c119-4ce9-ac51-b317671f30fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = load_and_preprocess_enrichment_data(cfg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "34c40474",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_hdf('../data/saved_h5/dna_dataset_classification.h5', 'df')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b09fd2dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "dna_dataset = DNAEncoderDataSet(df, cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2587d8c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "73d41b15",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data.pickle', 'wb') as f:\n",
    "    # Pickle the 'data' dictionary using the highest protocol available.\n",
    "    pickle.dump(dna_dataset, f, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "68c4ee2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data.pickle', 'rb') as f:\n",
    "    # The protocol version used is detected automatically, so we do not\n",
    "    # have to specify it.\n",
    "    data = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "44618deb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., -inf, -inf,  ..., -inf, -inf, -inf],\n",
       "        [0., 0., -inf,  ..., -inf, -inf, -inf],\n",
       "        [0., 0., 0.,  ..., -inf, -inf, -inf],\n",
       "        ...,\n",
       "        [0., 0., 0.,  ..., 0., -inf, -inf],\n",
       "        [0., 0., 0.,  ..., 0., 0., -inf],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask = torch.full([max_seq_len, max_seq_len], float('-inf'))\n",
    "mask = torch.triu(mask, diagonal=1)\n",
    "\n",
    "mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8049584",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "N = 20  # Replace with your value of N\n",
    "\n",
    "# Regular expression pattern to match more than N consecutive 'G's\n",
    "pattern = f'C{{{N},}}'\n",
    "\n",
    "# Filter sequences with more than N consecutive 'G's\n",
    "sequences_with_consecutive_Gs = df[df['Sequence'].str.contains(pattern)]\n",
    "\n",
    "print(len(sequences_with_consecutive_Gs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b0a8df7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tokenizers import Tokenizer\n",
    "from tokenizers.models import BPE\n",
    "from tokenizers.trainers import BpeTrainer\n",
    "from tokenizers.pre_tokenizers import Whitespace\n",
    "from tokenizers.processors import TemplateProcessing\n",
    "from transformers import PreTrainedTokenizerFast\n",
    "from transformers import DataCollatorForLanguageModeling\n",
    "\n",
    "tokenizer = Tokenizer(BPE(unk_token=\"N\"), )\n",
    "tokenizer.pre_tokenizer = Whitespace()\n",
    "tokenizer.mask_token = \"[MASK]\"\n",
    "tokenizer.cls_token = \"[CLS]\"\n",
    "tokenizer.pad_token = \"[PAD]\"\n",
    "tokenizer.unknown_token = \"N\"\n",
    "tokenizer.model_max_length = 42\n",
    "tokenizer.enable_padding(pad_id=0, pad_token=\"[PAD]\")\n",
    "tokenizer.post_processor = TemplateProcessing(\n",
    "    single=\"[CLS] $A\",\n",
    "    special_tokens=[(\"[PAD]\",0), (\"N\", 1), (\"[CLS]\", 2), (\"[MASK]\", 3)]\n",
    ")\n",
    "\n",
    "trainer = BpeTrainer(\n",
    "    vocab_size=8,\n",
    "    special_tokens=[\"[PAD]\", \"N\", \"[CLS]\", \"[MASK]\"],\n",
    ")\n",
    "\n",
    "temp_df = df.Sequence.apply(lambda x:\" \".join(x))\n",
    "tokenizer.train_from_iterator(temp_df.values, trainer=trainer)\n",
    "\n",
    "fast_tokenizer = PreTrainedTokenizerFast(tokenizer_object=tokenizer, model_max_length=42, cls_token=\"[CLS]\", unk_token=\"N\", pad_token=\"[PAD]\", mask_token=\"[MASK]\", return_special_tokens_mask=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6e70350",
   "metadata": {},
   "outputs": [],
   "source": [
    "fast_tokenizer.save_pretrained('../data/AptamerBERT_tokenizer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "edfcb825",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PreTrainedTokenizerFast(name_or_path='../data/AptamerBERT_tokenizer', vocab_size=8, model_max_length=42, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'unk_token': 'N', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]'}, clean_up_tokenization_spaces=True),  added_tokens_decoder={\n",
       "\t0: AddedToken(\"[PAD]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t1: AddedToken(\"N\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t2: AddedToken(\"[CLS]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t3: AddedToken(\"[MASK]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, DataCollatorForLanguageModeling\n",
    "tokenizer = AutoTokenizer.from_pretrained('../data/AptamerBERT_tokenizer')\n",
    "data_collator = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm_probability=0.15)\n",
    "tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f847b032",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.model_max_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "81ea595d",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_df = df.Sequence.apply(lambda x:\" \".join(x))\n",
    "\n",
    "batched_data = temp_df.values.tolist()[:1000]\n",
    "tokenized_batch = tokenizer(batched_data, padding=True, )\n",
    "\n",
    "masked_data = data_collator(tokenized_batch.input_ids)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c0a1bfa2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[False, False, False,  ..., False, False, False],\n",
       "        [False, False, False,  ..., False, False,  True],\n",
       "        [False, False, False,  ..., False, False,  True],\n",
       "        ...,\n",
       "        [False, False, False,  ..., False, False,  True],\n",
       "        [False, False, False,  ..., False, False,  True],\n",
       "        [False, False, False,  ..., False, False, False]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "~torch.Tensor(tokenized_batch['attention_mask']).bool()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "428a4471",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "cfg['device'] = device\n",
    "\n",
    "model = x_transformer_encoder= TransformerWrapper(\n",
    "    num_tokens = 8,\n",
    "    max_seq_len = 42,\n",
    "    num_memory_tokens = cfg['num_memory_tokens'],\n",
    "    l2norm_embed = cfg['l2norm_embed'],\n",
    "    attn_layers = Encoder(\n",
    "        dim = cfg['d_model'],\n",
    "        depth = cfg['num_layers'],\n",
    "        heads = cfg['nhead'],\n",
    "        layer_dropout = cfg['dropout_rate'],   # stochastic depth - dropout entire layer\n",
    "        attn_dropout = cfg['dropout_rate'],    # dropout post-attention\n",
    "        ff_dropout = cfg['dropout_rate'],       # feedforward dropout,\n",
    "        attn_flash = cfg['attn_flash'],\n",
    "        attn_num_mem_kv = cfg['attn_num_mem_kv'],\n",
    "        use_scalenorm = cfg['use_scalenorm'],\n",
    "        use_simple_rmsnorm = cfg['use_simple_rmsnorm'],\n",
    "        ff_glu = cfg['ff_glu'],\n",
    "        ff_swish = cfg['ff_swish'],\n",
    "        ff_no_bias = cfg['ff_no_bias'],\n",
    "        attn_talking_heads = cfg['attn_talking_heads']\n",
    "    )\n",
    ").to(device)\n",
    "\n",
    "\n",
    "\n",
    "src = masked_data['input_ids'].to(device)\n",
    "src_mask = torch.Tensor(tokenized_batch.attention_mask).bool().to(device)\n",
    "\n",
    "trg = masked_data['labels'].to(device)\n",
    "\n",
    "\n",
    "out = model(src, mask=src_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a4ade01",
   "metadata": {},
   "outputs": [],
   "source": [
    "F.cross_entropy(out.movedim(2,1), trg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "effbeb45",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "cfg['device'] = device\n",
    "\n",
    "model = XTransformer(\n",
    "    dim = cfg['d_model'],\n",
    "    enc_num_tokens = 8,\n",
    "    enc_depth = cfg['num_layers'],\n",
    "    enc_heads = 8,\n",
    "    enc_max_seq_len = 42,\n",
    "    dec_num_tokens = 8,\n",
    "    dec_depth = cfg['num_layers'],\n",
    "    dec_heads = 8,\n",
    "    dec_max_seq_len = 42,\n",
    "    tie_token_emb = True      # tie embeddings of encoder and decoder\n",
    ").to(device)\n",
    "\n",
    "\n",
    "\n",
    "src = masked_data['input_ids'].to(device)\n",
    "src_mask = torch.Tensor(tokenized_batch.attention_mask).bool().to(device)\n",
    "\n",
    "trg = torch.Tensor(tokenized_batch.input_ids).long().to(device)\n",
    "\n",
    "\n",
    "out = model(src, trg, mask=src_mask)\n",
    "\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b695c9dc-6af0-4a85-8296-d428711cf9fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.hist(column='Normalized_Frequency', bins=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c5aebec-f857-4c13-b58e-4a1f8dbd3362",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "npl-2023b",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
